{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f178cfef-2782-4a77-b4f8-7d372a7c61f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 16:57:38.716483: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-15 16:57:38.776618: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import os\n",
    "from util import get_model_paths_and_config, upload2bs\n",
    "from config import Config\n",
    "from components.data_preparation.data_ingestion import process_whatsapp_chat\n",
    "from components.fine_tunning.trainer import finetune_gemma\n",
    "from components.fine_tunning.conversion_function import convert_checkpoints\n",
    "from numba import cuda\n",
    "from google.cloud import aiplatform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d508aa69-1810-4fc2-9a3d-735e55e4ccf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_paths_and_config = get_model_paths_and_config(Config.MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69027026-fb4f-4de3-9e5c-84f7ec881d29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('input_data/andrehpereh', 'able-analyst-416817-chatbot-v1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.TRAIN_DATA_DIR, Config.BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b737395-4d42-4a7e-becf-9fbc07a2580d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Bucket: able-analyst-416817-chatbot-v1>\n",
      "input_data/andrehpereh\n",
      "<google.api_core.page_iterator.HTTPIterator object at 0x7f1dac862560>\n",
      "input_data/andrehpereh/\n",
      "\n",
      "input_data/andrehpereh/WhatsApp Chat with Anki.txt\n",
      "WhatsApp Chat with Anki.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Anki.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Ilse Flatmate.txt\n",
      "WhatsApp Chat with Ilse Flatmate.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Ilse Flatmate.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Michael.txt\n",
      "WhatsApp Chat with Michael.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Michael.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Mike Haarlem.txt\n",
      "WhatsApp Chat with Mike Haarlem.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Mike Haarlem.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Rosa Rosa Rosa.txt\n",
      "WhatsApp Chat with Rosa Rosa Rosa.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Rosa Rosa Rosa.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Ruben Ewald Puijker.txt\n",
      "WhatsApp Chat with Ruben Ewald Puijker.txt\n",
      "input_data/andrehpereh/WhatsApp Chat with Ruben Ewald Puijker.txt\n"
     ]
    }
   ],
   "source": [
    "data = process_whatsapp_chat(Config.BUCKET_NAME, Config.TRAIN_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04ebef-6bad-4c2d-aced-34083491afce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67913c94-353d-43f3-8026-827aafdbbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_weights_path = finetune_gemma(data=data[:50], model_paths=model_paths_and_config, model_name=Config.MODEL_NAME, rank_lora=Config.SEQUENCE_LENGTH, sequence_length=Config.SEQUENCE_LENGTH, epochs=Config.EPOCHS, batch_size=Config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d2d38-4f7b-4eca-bf72-31027d060ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cuda.get_current_device()\n",
    "cuda.select_device(device.id)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c2ed7-d7fc-4c1b-a73f-e44940701a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = convert_checkpoints(\n",
    "    weights_file=finetuned_weights_path,\n",
    "    size=model_paths_and_config['model_size'],\n",
    "    output_dir=model_paths_and_config['huggingface_model_dir'],\n",
    "    vocab_path=model_paths_and_config['finetuned_vocab_path'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202aae46-9fdc-40f6-9d3e-d4f7cb50278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=model_paths_and_config['huggingface_model_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad8c09-c59c-4424-8165-24e5716740e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = upload2bs(local_directory = output_dir, bucket_name = Config.BUCKET_NAME, destination_subfolder = model_paths_and_config['deployed_model_blob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea5a28-8c3c-44d7-87aa-1952de6c3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=Config.PROJECT_ID, location=Config.REGION, staging_bucket=Config.BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61b32639-f0ac-459a-924b-db590770a837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "VLLM_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240220_0936_RC01\"\n",
    "\n",
    "\n",
    "def get_job_name_with_datetime(prefix: str) -> str:\n",
    "    suffix = datetime.datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "    return f\"{prefix}{suffix}\"\n",
    "\n",
    "\n",
    "def deploy_model_vllm(\n",
    "    model_name: str,\n",
    "    model_uri: str,\n",
    "    service_account: str,\n",
    "    machine_type: str = \"g2-standard-8\",\n",
    "    accelerator_type: str = \"NVIDIA_L4\",\n",
    "    accelerator_count: int = 1,\n",
    "    max_model_len: int = 8192,\n",
    "    dtype: str = \"bfloat16\",\n",
    ") -> tuple[aiplatform.Model, aiplatform.Endpoint]:\n",
    "    # Upload the model to \"Model Registry\"\n",
    "    job_name = get_job_name_with_datetime(model_name)\n",
    "    vllm_args = [\n",
    "        \"--host=0.0.0.0\",\n",
    "        \"--port=7080\",\n",
    "        f\"--tensor-parallel-size={accelerator_count}\",\n",
    "        \"--swap-space=16\",\n",
    "        \"--gpu-memory-utilization=0.95\",\n",
    "        f\"--max-model-len={max_model_len}\",\n",
    "        f\"--dtype={dtype}\",\n",
    "        \"--disable-log-stats\",\n",
    "    ]\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=job_name,\n",
    "        artifact_uri=model_uri,\n",
    "        serving_container_image_uri=VLLM_DOCKER_URI,\n",
    "        serving_container_command=[\"python\", \"-m\", \"vllm.entrypoints.api_server\"],\n",
    "        serving_container_args=vllm_args,\n",
    "        serving_container_ports=[7080],\n",
    "        serving_container_predict_route=\"/generate\",\n",
    "        serving_container_health_route=\"/ping\",\n",
    "    )\n",
    "\n",
    "    # Deploy the model to an endpoint to serve \"Online predictions\"\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-endpoint\")\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        deploy_request_timeout=1800,\n",
    "        service_account=service_account,\n",
    "    )\n",
    "\n",
    "    return model, endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c07dfde0-7192-48af-9730-d3b692cf878a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma_2b_en-vllm'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up artificially since the model was already in a bucket\n",
    "model_paths_and_config['deployed_model_uri'] = 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240314162107'\n",
    "model_paths_and_config['model_name_vllm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "251fc433-3657-434e-a64c-6b351bf143ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/24796876098/locations/us-central1/models/6563293868962349056/operations/1798728489633841152\n",
      "Model created. Resource name: projects/24796876098/locations/us-central1/models/6563293868962349056@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/24796876098/locations/us-central1/models/6563293868962349056@1')\n",
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/24796876098/locations/us-central1/endpoints/2459943961893011456/operations/8683465682488131584\n",
      "Endpoint created. Resource name: projects/24796876098/locations/us-central1/endpoints/2459943961893011456\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/24796876098/locations/us-central1/endpoints/2459943961893011456')\n",
      "Deploying model to Endpoint : projects/24796876098/locations/us-central1/endpoints/2459943961893011456\n",
      "Deploy Endpoint model backing LRO: projects/24796876098/locations/us-central1/endpoints/2459943961893011456/operations/7799071305663250432\n",
      "Endpoint model deployed. Resource name: projects/24796876098/locations/us-central1/endpoints/2459943961893011456\n"
     ]
    }
   ],
   "source": [
    "max_model_len = 2048\n",
    "\n",
    "model, endpoint = deploy_model_vllm(\n",
    "    model_name=model_paths_and_config['model_name_vllm'],\n",
    "    model_uri=model_paths_and_config['deployed_model_uri'],\n",
    "    service_account=Config.SERVICE_ACCOUNT,\n",
    "    machine_type=model_paths_and_config['machine_type'],\n",
    "    accelerator_type=model_paths_and_config['accelerator_type'],\n",
    "    accelerator_count=model_paths_and_config['accelerator_count'],\n",
    "    max_model_len=max_model_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "69dc40ff-d622-423b-8c43-f066e93907e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma-vertexai-chatbot@able-analyst-416817.iam.gserviceaccount.com'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88520f0-174a-4cb7-97c4-41a1fbcaca81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b0e2a926-dac3-4dfd-a184-515685b4b657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f6f329e-9925-42fe-8362-3ca5c97f1cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the plan for tonight?\n",
      "I don’t know, I’m not sure. I’ll let you know when I know.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "What would you like to drink?\n",
      "I’ll take a coffee, please.\n",
      "\n",
      "Andres Perez:\n",
      "I’ll take a coffee, please.\n",
      "\n",
      "Andres Perez:\n",
      "I’ll take a coffee, please.\n",
      "\n",
      "Andres Perez:\n",
      "I’ll take a coffee, please.\n",
      "\n",
      "Andres Perez:\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Are you coming tonight?\n",
      "I’m not sure. I’ll ask my mom.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "TEST_EXAMPLES = [\n",
    "    \"What is the plan for tonight?\",\n",
    "    \"What would you like to drink?\",\n",
    "    \"Are you coming tonight?\"\n",
    "]\n",
    "\n",
    "# Prompt template for the training data and the finetuning tests\n",
    "PROMPT_TEMPLATE = \"Sender:\\n{instruction}\\n\\nAndres Perez:\\n{response}\"\n",
    "\n",
    "TEST_PROMPTS = [\n",
    "    PROMPT_TEMPLATE.format(instruction=example, response=\"\")\n",
    "    for example in TEST_EXAMPLES\n",
    "]\n",
    "\n",
    "def test_vertexai_endpoint(endpoint: aiplatform.Endpoint):\n",
    "    for question, prompt in zip(TEST_EXAMPLES, TEST_PROMPTS):\n",
    "        instance = {\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 56,\n",
    "            \"temperature\": 0.0,\n",
    "            \"top_p\": 1.0,\n",
    "            \"top_k\": 1,\n",
    "            \"raw_response\": True,\n",
    "        }\n",
    "        response = endpoint.predict(instances=[instance])\n",
    "        output = response.predictions[0]\n",
    "        print(f\"{question}\\n{output}\\n{'- '*40}\")\n",
    "\n",
    "\n",
    "test_vertexai_endpoint(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "518bd694-aa5b-45f4-934a-894c33b2bf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = !gcloud config get core/project\n",
    "PROJECT_ID = res[0]\n",
    "SERVICE_ACCOUNT = 'gemma-vertexai-chatbot@able-analyst-416817.iam.gserviceaccount.com'\n",
    "from datetime import datetime\n",
    "CONTAINER_IMAGE_NAME=\"gemma-chatbot\"\n",
    "GCP_REGION='us-central1'\n",
    "IMAGE_NAME=\"gemma-chatbot\"\n",
    "TAG_NAME = 'latest'\n",
    "KAGGLE_USERNAME='andrehpereh1'\n",
    "KAGGLE_KEY='5859e39806d9456749dcbac685f04bc9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60d98f42-6a85-4324-81a7-dd1c6b5bab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CONTAINER_IMAGE_NAME=gemma-chatbot-data-preparation,TAG_NAME=latest\n"
     ]
    }
   ],
   "source": [
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-data-preparation\",\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfd38dea-1f7f-486d-bf3e-1b3a1f69582c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Runs the data_preparation component image. (Development, when tested should be moved to the main cloudbuild in the project folder)\n",
    "# Pay attention to the \".\" after summit. Might need some changes when move to the master pipeline.\n",
    "#!gcloud builds submit . --timeout=15m --config \"components/data_preparation/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n",
    "# DO not forget the tag\n",
    "#!docker run gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest data_ingestion.py --bucket-name 'able-analyst-416817-chatbot-v1' --directory 'input_data/andrehpereh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a0d0f14-b406-4a5a-bc6b-fa4e8da5cc62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9250f9bf-5bf0-4bd2-8f5f-3f10daf9dc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ef60c94-45b0-4cf2-a7d1-cf96b3f6ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CONTAINER_IMAGE_NAME=gemma-chatbot-fine-tunning,_KAGGLE_USERNAME=andrehpereh1,_KAGGLE_KEY=5859e39806d9456749dcbac685f04bc9,TAG_NAME=latest\n",
      "Creating temporary tarball archive of 73 file(s) totalling 1.7 MiB before compression.\n",
      "Uploading tarball of [.] to [gs://able-analyst-416817_cloudbuild/source/1710778619.347698-7c84a8843d2644608120f44613f87572.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/able-analyst-416817/locations/us-central1/builds/4a00094f-dae3-40a4-9747-4c20656d476a].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds;region=us-central1/4a00094f-dae3-40a4-9747-4c20656d476a?project=24796876098 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"4a00094f-dae3-40a4-9747-4c20656d476a\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://able-analyst-416817_cloudbuild/source/1710778619.347698-7c84a8843d2644608120f44613f87572.tgz#1710778620005664\n",
      "Copying gs://able-analyst-416817_cloudbuild/source/1710778619.347698-7c84a8843d2644608120f44613f87572.tgz#1710778620005664...\n",
      "/ [1 files][689.6 KiB/689.6 KiB]                                                \n",
      "Operation completed over 1 objects/689.6 KiB.\n",
      "BUILD\n",
      "Starting Step #0\n",
      "Step #0: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0: Sending build context to Docker daemon  61.95kB\n",
      "Step #0: Step 1/12 : FROM us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121.py310\n",
      "Step #0: latest: Pulling from deeplearning-platform-release/gcr.io/base-cu121.py310\n",
      "Step #0: 96d54c3075c9: Already exists\n",
      "Step #0: 755e535b54a3: Pulling fs layer\n",
      "Step #0: 24ff69e0a1e4: Pulling fs layer\n",
      "Step #0: 76a627ca5e65: Pulling fs layer\n",
      "Step #0: 35817692a87e: Pulling fs layer\n",
      "Step #0: 84b6a42e847a: Pulling fs layer\n",
      "Step #0: 4639b7cd68e5: Pulling fs layer\n",
      "Step #0: a7bc10701a5b: Pulling fs layer\n",
      "Step #0: 7d32a9230f8f: Pulling fs layer\n",
      "Step #0: 8c35a1861813: Pulling fs layer\n",
      "Step #0: e3f63d7242f5: Pulling fs layer\n",
      "Step #0: afa75cca3a04: Pulling fs layer\n",
      "Step #0: c1f9e802b8d1: Pulling fs layer\n",
      "Step #0: c6b53aacfed4: Pulling fs layer\n",
      "Step #0: 4f4fb700ef54: Pulling fs layer\n",
      "Step #0: 10fcf6d9a8b1: Pulling fs layer\n",
      "Step #0: bd5512e53c5d: Pulling fs layer\n",
      "Step #0: 50d7191d66bf: Pulling fs layer\n",
      "Step #0: 180a65867fa7: Pulling fs layer\n",
      "Step #0: 7a1daf630b7f: Pulling fs layer\n",
      "Step #0: 20208c43ea0e: Pulling fs layer\n",
      "Step #0: ea960cf75e3a: Pulling fs layer\n",
      "Step #0: dfc4f5a5a8e5: Pulling fs layer\n",
      "Step #0: 3ebdd0bf63e9: Pulling fs layer\n",
      "Step #0: b19c2d4b7a08: Pulling fs layer\n",
      "Step #0: f9c0f83d4666: Pulling fs layer\n",
      "Step #0: d8cb5f186edc: Pulling fs layer\n",
      "Step #0: 7195b2f69d30: Pulling fs layer\n",
      "Step #0: 84f4ed49af3b: Pulling fs layer\n",
      "Step #0: 754279d31ba2: Pulling fs layer\n",
      "Step #0: e5fd8154ec1e: Pulling fs layer\n",
      "Step #0: 064dd4dfd950: Pulling fs layer\n",
      "Step #0: 7ce4912a0f9a: Pulling fs layer\n",
      "Step #0: 2873af0a7328: Pulling fs layer\n",
      "Step #0: 06676754b8b3: Pulling fs layer\n",
      "Step #0: d625375a5d42: Pulling fs layer\n",
      "Step #0: e7c45501f24b: Pulling fs layer\n",
      "Step #0: b4614282a05d: Pulling fs layer\n",
      "Step #0: 35817692a87e: Waiting\n",
      "Step #0: 84b6a42e847a: Waiting\n",
      "Step #0: 4639b7cd68e5: Waiting\n",
      "Step #0: a7bc10701a5b: Waiting\n",
      "Step #0: 7d32a9230f8f: Waiting\n",
      "Step #0: 8c35a1861813: Waiting\n",
      "Step #0: e3f63d7242f5: Waiting\n",
      "Step #0: afa75cca3a04: Waiting\n",
      "Step #0: c1f9e802b8d1: Waiting\n",
      "Step #0: c6b53aacfed4: Waiting\n",
      "Step #0: 4f4fb700ef54: Waiting\n",
      "Step #0: 10fcf6d9a8b1: Waiting\n",
      "Step #0: bd5512e53c5d: Waiting\n",
      "Step #0: 50d7191d66bf: Waiting\n",
      "Step #0: 180a65867fa7: Waiting\n",
      "Step #0: 7a1daf630b7f: Waiting\n",
      "Step #0: 20208c43ea0e: Waiting\n",
      "Step #0: ea960cf75e3a: Waiting\n",
      "Step #0: dfc4f5a5a8e5: Waiting\n",
      "Step #0: 3ebdd0bf63e9: Waiting\n",
      "Step #0: b19c2d4b7a08: Waiting\n",
      "Step #0: f9c0f83d4666: Waiting\n",
      "Step #0: d8cb5f186edc: Waiting\n",
      "Step #0: 7195b2f69d30: Waiting\n",
      "Step #0: 84f4ed49af3b: Waiting\n",
      "Step #0: 754279d31ba2: Waiting\n",
      "Step #0: e5fd8154ec1e: Waiting\n",
      "Step #0: 064dd4dfd950: Waiting\n",
      "Step #0: 7ce4912a0f9a: Waiting\n",
      "Step #0: 2873af0a7328: Waiting\n",
      "Step #0: 06676754b8b3: Waiting\n",
      "Step #0: d625375a5d42: Waiting\n",
      "Step #0: e7c45501f24b: Waiting\n",
      "Step #0: b4614282a05d: Waiting\n",
      "Step #0: 76a627ca5e65: Download complete\n",
      "Step #0: 755e535b54a3: Download complete\n",
      "Step #0: 35817692a87e: Verifying Checksum\n",
      "Step #0: 35817692a87e: Download complete\n",
      "Step #0: 4639b7cd68e5: Verifying Checksum\n",
      "Step #0: 4639b7cd68e5: Download complete\n",
      "Step #0: a7bc10701a5b: Verifying Checksum\n",
      "Step #0: a7bc10701a5b: Download complete\n",
      "Step #0: 24ff69e0a1e4: Verifying Checksum\n",
      "Step #0: 24ff69e0a1e4: Download complete\n",
      "Step #0: 7d32a9230f8f: Verifying Checksum\n",
      "Step #0: 7d32a9230f8f: Download complete\n",
      "Step #0: e3f63d7242f5: Verifying Checksum\n",
      "Step #0: e3f63d7242f5: Download complete\n",
      "Step #0: 755e535b54a3: Pull complete\n",
      "Step #0: 24ff69e0a1e4: Pull complete\n",
      "Step #0: 76a627ca5e65: Pull complete\n",
      "Step #0: 35817692a87e: Pull complete\n",
      "Step #0: 84b6a42e847a: Verifying Checksum\n",
      "Step #0: 84b6a42e847a: Download complete\n",
      "Step #0: afa75cca3a04: Verifying Checksum\n",
      "Step #0: afa75cca3a04: Download complete\n",
      "Step #0: c6b53aacfed4: Verifying Checksum\n",
      "Step #0: c6b53aacfed4: Download complete\n",
      "Step #0: 4f4fb700ef54: Verifying Checksum\n",
      "Step #0: 4f4fb700ef54: Download complete\n",
      "Step #0: 10fcf6d9a8b1: Verifying Checksum\n",
      "Step #0: 10fcf6d9a8b1: Download complete\n",
      "Step #0: bd5512e53c5d: Verifying Checksum\n",
      "Step #0: bd5512e53c5d: Download complete\n",
      "Step #0: 50d7191d66bf: Verifying Checksum\n",
      "Step #0: 50d7191d66bf: Download complete\n",
      "Step #0: 180a65867fa7: Verifying Checksum\n",
      "Step #0: 180a65867fa7: Download complete\n",
      "Step #0: 7a1daf630b7f: Verifying Checksum\n",
      "Step #0: 7a1daf630b7f: Download complete\n",
      "Step #0: 20208c43ea0e: Verifying Checksum\n",
      "Step #0: 20208c43ea0e: Download complete\n",
      "Step #0: ea960cf75e3a: Verifying Checksum\n",
      "Step #0: ea960cf75e3a: Download complete\n",
      "Step #0: dfc4f5a5a8e5: Verifying Checksum\n",
      "Step #0: dfc4f5a5a8e5: Download complete\n",
      "Step #0: 3ebdd0bf63e9: Verifying Checksum\n",
      "Step #0: 3ebdd0bf63e9: Download complete\n",
      "Step #0: b19c2d4b7a08: Verifying Checksum\n",
      "Step #0: b19c2d4b7a08: Download complete\n",
      "Step #0: f9c0f83d4666: Verifying Checksum\n",
      "Step #0: f9c0f83d4666: Download complete\n",
      "Step #0: d8cb5f186edc: Verifying Checksum\n",
      "Step #0: d8cb5f186edc: Download complete\n",
      "Step #0: 7195b2f69d30: Verifying Checksum\n",
      "Step #0: 7195b2f69d30: Download complete\n",
      "Step #0: 84f4ed49af3b: Verifying Checksum\n",
      "Step #0: 84f4ed49af3b: Download complete\n",
      "Step #0: 8c35a1861813: Verifying Checksum\n",
      "Step #0: 8c35a1861813: Download complete\n",
      "Step #0: 754279d31ba2: Verifying Checksum\n",
      "Step #0: 754279d31ba2: Download complete\n",
      "Step #0: e5fd8154ec1e: Verifying Checksum\n",
      "Step #0: e5fd8154ec1e: Download complete\n",
      "Step #0: 064dd4dfd950: Verifying Checksum\n",
      "Step #0: 064dd4dfd950: Download complete\n",
      "Step #0: 7ce4912a0f9a: Verifying Checksum\n",
      "Step #0: 7ce4912a0f9a: Download complete\n",
      "Step #0: 2873af0a7328: Verifying Checksum\n",
      "Step #0: 2873af0a7328: Download complete\n",
      "Step #0: d625375a5d42: Verifying Checksum\n",
      "Step #0: d625375a5d42: Download complete\n",
      "Step #0: e7c45501f24b: Verifying Checksum\n",
      "Step #0: e7c45501f24b: Download complete\n",
      "Step #0: b4614282a05d: Verifying Checksum\n",
      "Step #0: b4614282a05d: Download complete\n",
      "Step #0: c1f9e802b8d1: Verifying Checksum\n",
      "Step #0: c1f9e802b8d1: Download complete\n",
      "Step #0: 06676754b8b3: Verifying Checksum\n",
      "Step #0: 06676754b8b3: Download complete\n",
      "Step #0: 84b6a42e847a: Pull complete\n",
      "Step #0: 4639b7cd68e5: Pull complete\n",
      "Step #0: a7bc10701a5b: Pull complete\n",
      "Step #0: 7d32a9230f8f: Pull complete\n",
      "Step #0: 8c35a1861813: Pull complete\n",
      "Step #0: e3f63d7242f5: Pull complete\n",
      "Step #0: afa75cca3a04: Pull complete\n",
      "Step #0: c1f9e802b8d1: Pull complete\n",
      "Step #0: c6b53aacfed4: Pull complete\n",
      "Step #0: 4f4fb700ef54: Pull complete\n",
      "Step #0: 10fcf6d9a8b1: Pull complete\n",
      "Step #0: bd5512e53c5d: Pull complete\n",
      "Step #0: 50d7191d66bf: Pull complete\n",
      "Step #0: 180a65867fa7: Pull complete\n",
      "Step #0: 7a1daf630b7f: Pull complete\n",
      "Step #0: 20208c43ea0e: Pull complete\n",
      "Step #0: ea960cf75e3a: Pull complete\n",
      "Step #0: dfc4f5a5a8e5: Pull complete\n",
      "Step #0: 3ebdd0bf63e9: Pull complete\n",
      "Step #0: b19c2d4b7a08: Pull complete\n",
      "Step #0: f9c0f83d4666: Pull complete\n",
      "Step #0: d8cb5f186edc: Pull complete\n",
      "Step #0: 7195b2f69d30: Pull complete\n",
      "Step #0: 84f4ed49af3b: Pull complete\n",
      "Step #0: 754279d31ba2: Pull complete\n",
      "Step #0: e5fd8154ec1e: Pull complete\n",
      "Step #0: 064dd4dfd950: Pull complete\n",
      "Step #0: 7ce4912a0f9a: Pull complete\n",
      "Step #0: 2873af0a7328: Pull complete\n",
      "Step #0: 06676754b8b3: Pull complete\n",
      "Step #0: d625375a5d42: Pull complete\n",
      "Step #0: e7c45501f24b: Pull complete\n",
      "Step #0: b4614282a05d: Pull complete\n",
      "Step #0: Digest: sha256:a0d3c16c924fdda8134fb4a29a3f491208189d99590a04643abb34e72108752a\n",
      "Step #0: Status: Downloaded newer image for us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121.py310:latest\n",
      "Step #0:  ---> f04ebe26fc76\n",
      "Step #0: Step 2/12 : WORKDIR /trainer\n",
      "Step #0:  ---> Running in 76af794301b8\n",
      "Step #0: Removing intermediate container 76af794301b8\n",
      "Step #0:  ---> aa1791eaf9b8\n",
      "Step #0: Step 3/12 : COPY requirements.txt .\n",
      "Step #0:  ---> 3601e9d7decd\n",
      "Step #0: Step 4/12 : RUN pip install -U -r requirements.txt\n",
      "Step #0:  ---> Running in fe09c3da9858\n",
      "Step #0: Collecting keras-nlp==0.8.2 (from -r requirements.txt (line 3))\n",
      "Step #0:   Downloading keras_nlp-0.8.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Step #0: Collecting keras==3.0.5 (from -r requirements.txt (line 4))\n",
      "Step #0:   Downloading keras-3.0.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "Step #0: Collecting transformers==4.38 (from -r requirements.txt (line 7))\n",
      "Step #0:   Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.1/131.1 kB 1.4 MB/s eta 0:00:00\n",
      "Step #0: Collecting fire==0.6.0 (from -r requirements.txt (line 8))\n",
      "Step #0:   Downloading fire-0.6.0.tar.gz (88 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.4/88.4 kB 5.9 MB/s eta 0:00:00\n",
      "Step #0:   Preparing metadata (setup.py): started\n",
      "Step #0:   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #0: Collecting keras-core (from keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
      "Step #0: Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (2.1.0)\n",
      "Step #0: Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (1.25.2)\n",
      "Step #0: Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (23.2)\n",
      "Step #0: Collecting regex (from keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 3.8 MB/s eta 0:00:00\n",
      "Step #0: Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (13.7.1)\n",
      "Step #0: Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (0.1.8)\n",
      "Step #0: Collecting kagglehub (from keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading kagglehub-0.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Step #0: Collecting tensorflow-text (from keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Step #0: Collecting namex (from keras==3.0.5->-r requirements.txt (line 4))\n",
      "Step #0:   Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Step #0: Collecting h5py (from keras==3.0.5->-r requirements.txt (line 4))\n",
      "Step #0:   Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Step #0: Collecting ml-dtypes (from keras==3.0.5->-r requirements.txt (line 4))\n",
      "Step #0:   Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Step #0: Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38->-r requirements.txt (line 7)) (3.13.1)\n",
      "Step #0: Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.38->-r requirements.txt (line 7))\n",
      "Step #0:   Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Step #0: Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38->-r requirements.txt (line 7)) (6.0.1)\n",
      "Step #0: Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38->-r requirements.txt (line 7)) (2.31.0)\n",
      "Step #0: Collecting tokenizers<0.19,>=0.14 (from transformers==4.38->-r requirements.txt (line 7))\n",
      "Step #0:   Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Step #0: Collecting safetensors>=0.4.1 (from transformers==4.38->-r requirements.txt (line 7))\n",
      "Step #0:   Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Step #0: Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38->-r requirements.txt (line 7)) (4.66.2)\n",
      "Step #0: Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire==0.6.0->-r requirements.txt (line 8)) (1.16.0)\n",
      "Step #0: Collecting termcolor (from fire==0.6.0->-r requirements.txt (line 8))\n",
      "Step #0:   Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Step #0: Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38->-r requirements.txt (line 7)) (2024.2.0)\n",
      "Step #0: Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38->-r requirements.txt (line 7)) (4.10.0)\n",
      "Step #0: Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38->-r requirements.txt (line 7)) (3.3.2)\n",
      "Step #0: Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38->-r requirements.txt (line 7)) (3.6)\n",
      "Step #0: Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38->-r requirements.txt (line 7)) (1.26.18)\n",
      "Step #0: Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38->-r requirements.txt (line 7)) (2024.2.2)\n",
      "Step #0: Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp==0.8.2->-r requirements.txt (line 3)) (3.0.0)\n",
      "Step #0: Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp==0.8.2->-r requirements.txt (line 3)) (2.17.2)\n",
      "Step #0: Collecting tensorflow<2.17,>=2.16.1 (from tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Step #0: Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-nlp==0.8.2->-r requirements.txt (line 3)) (0.1.2)\n",
      "Step #0: Collecting astunparse>=1.6.0 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Step #0: Collecting flatbuffers>=23.5.26 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading flatbuffers-24.3.7-py2.py3-none-any.whl.metadata (849 bytes)\n",
      "Step #0: Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Step #0: Collecting google-pasta>=0.1.1 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Step #0: Collecting libclang>=13.0.0 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Step #0: Collecting opt-einsum>=2.3.2 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Step #0: Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (3.20.3)\n",
      "Step #0: Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (69.1.1)\n",
      "Step #0: Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (1.16.0)\n",
      "Step #0: Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (1.62.0)\n",
      "Step #0: Collecting tensorboard<2.17,>=2.16 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Step #0: Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Step #0: Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (0.42.0)\n",
      "Step #0: Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Step #0: Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Step #0: Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #0:   Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Step #0: Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (2.1.5)\n",
      "Step #0: Downloading keras_nlp-0.8.2-py3-none-any.whl (465 kB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 465.3/465.3 kB 6.8 MB/s eta 0:00:00\n",
      "Step #0: Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 10.2 MB/s eta 0:00:00\n",
      "Step #0: Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 17.6 MB/s eta 0:00:00\n",
      "Step #0: Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 346.4/346.4 kB 16.5 MB/s eta 0:00:00\n",
      "Step #0: Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 774.0/774.0 kB 12.0 MB/s eta 0:00:00\n",
      "Step #0: Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 11.1 MB/s eta 0:00:00\n",
      "Step #0: Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 11.4 MB/s eta 0:00:00\n",
      "Step #0: Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 8.5 MB/s eta 0:00:00\n",
      "Step #0: Downloading kagglehub-0.2.0-py3-none-any.whl (33 kB)\n",
      "Step #0: Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 950.8/950.8 kB 5.6 MB/s eta 0:00:00\n",
      "Step #0: Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 6.4 MB/s eta 0:00:00\n",
      "Step #0: Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Step #0: Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 6.7 MB/s eta 0:00:00\n",
      "Step #0: Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Step #0: Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 589.8/589.8 MB 573.6 kB/s eta 0:00:00\n",
      "Step #0: Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Step #0: Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Step #0: Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Step #0: Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 880.1 kB/s eta 0:00:00\n",
      "Step #0: Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.5/24.5 MB 1.7 MB/s eta 0:00:00\n",
      "Step #0: Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 1.7 MB/s eta 0:00:00\n",
      "Step #0: Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 1.5 MB/s eta 0:00:00\n",
      "Step #0: Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 1.1 MB/s eta 0:00:00\n",
      "Step #0: Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.4/105.4 kB 748.6 kB/s eta 0:00:00\n",
      "Step #0: Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 1.0 MB/s eta 0:00:00\n",
      "Step #0: Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Step #0:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.7/226.7 kB 1.1 MB/s eta 0:00:00\n",
      "Step #0: Building wheels for collected packages: fire\n",
      "Step #0:   Building wheel for fire (setup.py): started\n",
      "Step #0:   Building wheel for fire (setup.py): finished with status 'done'\n",
      "Step #0:   Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=3ecac1a073793c618708001c95a678b1a18895bd05fd3a0725ff92a8ce7793af\n",
      "Step #0:   Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
      "Step #0: Successfully built fire\n",
      "Step #0: Installing collected packages: namex, libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, safetensors, regex, opt-einsum, ml-dtypes, markdown, h5py, google-pasta, gast, astunparse, tensorboard, kagglehub, huggingface-hub, fire, tokenizers, keras-core, keras, transformers, tensorflow, tensorflow-text, keras-nlp\n",
      "Step #0: Successfully installed astunparse-1.6.3 fire-0.6.0 flatbuffers-24.3.7 gast-0.5.4 google-pasta-0.2.0 h5py-3.10.0 huggingface-hub-0.21.4 kagglehub-0.2.0 keras-3.0.5 keras-core-0.1.7 keras-nlp-0.8.2 libclang-18.1.1 markdown-3.6 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 regex-2023.12.25 safetensors-0.4.2 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 tensorflow-text-2.16.1 termcolor-2.4.0 tokenizers-0.15.2 transformers-4.38.0 werkzeug-3.0.1\n",
      "Step #0: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Step #0: \u001b[0mRemoving intermediate container fe09c3da9858\n",
      "Step #0:  ---> bfe7a893b8e5\n",
      "Step #0: Step 5/12 : ARG KAGGLE_USERNAME\n",
      "Step #0:  ---> Running in 77a4d1f7bf16\n",
      "Step #0: Removing intermediate container 77a4d1f7bf16\n",
      "Step #0:  ---> c0ce1c588d16\n",
      "Step #0: Step 6/12 : ENV KAGGLE_USERNAME=$KAGGLE_USERNAME\n",
      "Step #0:  ---> Running in b19dedeea485\n",
      "Step #0: Removing intermediate container b19dedeea485\n",
      "Step #0:  ---> b6f6c83c910e\n",
      "Step #0: Step 7/12 : ARG KAGGLE_KEY\n",
      "Step #0:  ---> Running in 56f0576b95a6\n",
      "Step #0: Removing intermediate container 56f0576b95a6\n",
      "Step #0:  ---> 14809f6bb8c6\n",
      "Step #0: Step 8/12 : ENV KAGGLE_KEY=$KAGGLE_KEY\n",
      "Step #0:  ---> Running in ad855eaf2206\n",
      "Step #0: Removing intermediate container ad855eaf2206\n",
      "Step #0:  ---> 4e8d24fc19fd\n",
      "Step #0: Step 9/12 : COPY . /trainer\n",
      "Step #0:  ---> 9aca12a333d7\n",
      "Step #0: Step 10/12 : WORKDIR /trainer\n",
      "Step #0:  ---> Running in 2f4d6170d8d6\n",
      "Step #0: Removing intermediate container 2f4d6170d8d6\n",
      "Step #0:  ---> a89239c07975\n",
      "Step #0: Step 11/12 : RUN ls\n",
      "Step #0:  ---> Running in 01ca3f3c6a77\n",
      "Step #0: Dockerfile\n",
      "Step #0: __pycache__\n",
      "Step #0: cloudbuild.yaml\n",
      "Step #0: conversion_function.py\n",
      "Step #0: export_gemma_to_hf.py\n",
      "Step #0: requirements.txt\n",
      "Step #0: test_container.py\n",
      "Step #0: trainer.py\n",
      "Step #0: Removing intermediate container 01ca3f3c6a77\n",
      "Step #0:  ---> ddb74fb5c3e1\n",
      "Step #0: Step 12/12 : ENTRYPOINT [\"python\"]\n",
      "Step #0:  ---> Running in 8ad0dd4bd2e2\n",
      "Step #0: Removing intermediate container 8ad0dd4bd2e2\n",
      "Step #0:  ---> 5fbbd627129e\n",
      "Step #0: Successfully built 5fbbd627129e\n",
      "Step #0: Successfully tagged gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest\n",
      "Finished Step #0\n",
      "Starting Step #1\n",
      "Step #1: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #1: The push refers to repository [gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning]\n",
      "Step #1: 9c2613b20f3b: Preparing\n",
      "Step #1: 975785eb26a6: Preparing\n",
      "Step #1: 57f59f3df7e0: Preparing\n",
      "Step #1: 27f92e708916: Preparing\n",
      "Step #1: 9deb6fc54da9: Preparing\n",
      "Step #1: 6931085b550f: Preparing\n",
      "Step #1: c230b525aedf: Preparing\n",
      "Step #1: 5f70bf18a086: Preparing\n",
      "Step #1: c57ef954d51d: Preparing\n",
      "Step #1: b831d1fa39bf: Preparing\n",
      "Step #1: 4520767ffc08: Preparing\n",
      "Step #1: 09d837e2554d: Preparing\n",
      "Step #1: 6e3d09f63d7a: Preparing\n",
      "Step #1: d3135376200a: Preparing\n",
      "Step #1: e76fa06cba23: Preparing\n",
      "Step #1: 46b83560dec5: Preparing\n",
      "Step #1: 6931085b550f: Waiting\n",
      "Step #1: 51029eb3efd6: Preparing\n",
      "Step #1: c230b525aedf: Waiting\n",
      "Step #1: 5f70bf18a086: Waiting\n",
      "Step #1: c57ef954d51d: Waiting\n",
      "Step #1: b831d1fa39bf: Waiting\n",
      "Step #1: 4520767ffc08: Waiting\n",
      "Step #1: 09d837e2554d: Waiting\n",
      "Step #1: 6e3d09f63d7a: Waiting\n",
      "Step #1: d3135376200a: Waiting\n",
      "Step #1: e76fa06cba23: Waiting\n",
      "Step #1: b32920786550: Preparing\n",
      "Step #1: 0430b0b45ba7: Preparing\n",
      "Step #1: cd26331ad5b3: Preparing\n",
      "Step #1: 8e74dfc7859c: Preparing\n",
      "Step #1: b81e99c9fcc3: Preparing\n",
      "Step #1: 4e3c3f15a9b6: Preparing\n",
      "Step #1: 457986848246: Preparing\n",
      "Step #1: cbf3c905e2e1: Preparing\n",
      "Step #1: da817efd0bfb: Preparing\n",
      "Step #1: 2f41ef0e83a0: Preparing\n",
      "Step #1: 52248bbcc0bc: Preparing\n",
      "Step #1: 5f70bf18a086: Preparing\n",
      "Step #1: 537816d7f4e1: Preparing\n",
      "Step #1: f158d4b2b4b4: Preparing\n",
      "Step #1: e7bf000641e2: Preparing\n",
      "Step #1: d7d705e1decf: Preparing\n",
      "Step #1: 2227317d988c: Preparing\n",
      "Step #1: 50bceba2b2b7: Preparing\n",
      "Step #1: 40fc5e6cc198: Preparing\n",
      "Step #1: 889402d51413: Preparing\n",
      "Step #1: 284c466ee6ce: Preparing\n",
      "Step #1: 1ff8f721b9db: Preparing\n",
      "Step #1: 1eeecbd4dbae: Preparing\n",
      "Step #1: 35d40f4df845: Preparing\n",
      "Step #1: 2651516ff8de: Preparing\n",
      "Step #1: 6c3e7df31590: Preparing\n",
      "Step #1: 46b83560dec5: Waiting\n",
      "Step #1: 51029eb3efd6: Waiting\n",
      "Step #1: cbf3c905e2e1: Waiting\n",
      "Step #1: da817efd0bfb: Waiting\n",
      "Step #1: b32920786550: Waiting\n",
      "Step #1: 0430b0b45ba7: Waiting\n",
      "Step #1: cd26331ad5b3: Waiting\n",
      "Step #1: 8e74dfc7859c: Waiting\n",
      "Step #1: b81e99c9fcc3: Waiting\n",
      "Step #1: 4e3c3f15a9b6: Waiting\n",
      "Step #1: 457986848246: Waiting\n",
      "Step #1: 2f41ef0e83a0: Waiting\n",
      "Step #1: 52248bbcc0bc: Waiting\n",
      "Step #1: 537816d7f4e1: Waiting\n",
      "Step #1: f158d4b2b4b4: Waiting\n",
      "Step #1: e7bf000641e2: Waiting\n",
      "Step #1: d7d705e1decf: Waiting\n",
      "Step #1: 2227317d988c: Waiting\n",
      "Step #1: 1eeecbd4dbae: Waiting\n",
      "Step #1: 50bceba2b2b7: Waiting\n",
      "Step #1: 40fc5e6cc198: Waiting\n",
      "Step #1: 889402d51413: Waiting\n",
      "Step #1: 284c466ee6ce: Waiting\n",
      "Step #1: 1ff8f721b9db: Waiting\n",
      "Step #1: 35d40f4df845: Waiting\n",
      "Step #1: 2651516ff8de: Waiting\n",
      "Step #1: 6c3e7df31590: Waiting\n",
      "Step #1: 9deb6fc54da9: Layer already exists\n",
      "Step #1: 6931085b550f: Layer already exists\n",
      "Step #1: c230b525aedf: Layer already exists\n",
      "Step #1: 5f70bf18a086: Layer already exists\n",
      "Step #1: c57ef954d51d: Layer already exists\n",
      "Step #1: 27f92e708916: Pushed\n",
      "Step #1: b831d1fa39bf: Layer already exists\n",
      "Step #1: 9c2613b20f3b: Pushed\n",
      "Step #1: 57f59f3df7e0: Pushed\n",
      "Step #1: 4520767ffc08: Layer already exists\n",
      "Step #1: 09d837e2554d: Layer already exists\n",
      "Step #1: d3135376200a: Layer already exists\n",
      "Step #1: 6e3d09f63d7a: Layer already exists\n",
      "Step #1: e76fa06cba23: Layer already exists\n",
      "Step #1: 46b83560dec5: Layer already exists\n",
      "Step #1: 51029eb3efd6: Layer already exists\n",
      "Step #1: b32920786550: Layer already exists\n",
      "Step #1: 0430b0b45ba7: Layer already exists\n",
      "Step #1: cd26331ad5b3: Layer already exists\n",
      "Step #1: 4e3c3f15a9b6: Layer already exists\n",
      "Step #1: 8e74dfc7859c: Layer already exists\n",
      "Step #1: 457986848246: Layer already exists\n",
      "Step #1: b81e99c9fcc3: Layer already exists\n",
      "Step #1: 52248bbcc0bc: Layer already exists\n",
      "Step #1: cbf3c905e2e1: Layer already exists\n",
      "Step #1: da817efd0bfb: Layer already exists\n",
      "Step #1: 2f41ef0e83a0: Layer already exists\n",
      "Step #1: 537816d7f4e1: Layer already exists\n",
      "Step #1: f158d4b2b4b4: Layer already exists\n",
      "Step #1: e7bf000641e2: Layer already exists\n",
      "Step #1: d7d705e1decf: Layer already exists\n",
      "Step #1: 50bceba2b2b7: Layer already exists\n",
      "Step #1: 2227317d988c: Layer already exists\n",
      "Step #1: 889402d51413: Layer already exists\n",
      "Step #1: 284c466ee6ce: Layer already exists\n",
      "Step #1: 1ff8f721b9db: Layer already exists\n",
      "Step #1: 40fc5e6cc198: Layer already exists\n",
      "Step #1: 1eeecbd4dbae: Layer already exists\n",
      "Step #1: 35d40f4df845: Layer already exists\n",
      "Step #1: 6c3e7df31590: Layer already exists\n",
      "Step #1: 2651516ff8de: Layer already exists\n",
      "Step #1: 975785eb26a6: Pushed\n",
      "Step #1: latest: digest: sha256:97f99409e3c54926af75204d9d9ecbec53b8f0aaaf8abe8d72d31a6198357b9a size: 9326\n",
      "Finished Step #1\n",
      "PUSH\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                             IMAGES  STATUS\n",
      "4a00094f-dae3-40a4-9747-4c20656d476a  2024-03-18T16:17:00+00:00  19M22S    gs://able-analyst-416817_cloudbuild/source/1710778619.347698-7c84a8843d2644608120f44613f87572.tgz  -       SUCCESS\n"
     ]
    }
   ],
   "source": [
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "_KAGGLE_USERNAME={},\\\n",
    "_KAGGLE_KEY={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-fine-tunning\",\n",
    "           KAGGLE_USERNAME,\n",
    "           KAGGLE_KEY,\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n",
    "\n",
    "\n",
    "# Builds image\n",
    "!gcloud builds submit . --config \"components/fine_tunning/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e961b567-3239-4c10-915f-67fd98515c95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest' locally\n",
      "latest: Pulling from able-analyst-416817/gemma-chatbot-fine-tunning\n",
      "\n",
      "\u001b[1B4c3075c9: Pulling fs layer \n",
      "\u001b[1B535b54a3: Pulling fs layer \n",
      "\u001b[1B69e0a1e4: Pulling fs layer \n",
      "\u001b[1B27ca5e65: Pulling fs layer \n",
      "\u001b[1B7692a87e: Pulling fs layer \n",
      "\u001b[1Ba42e847a: Pulling fs layer \n",
      "\u001b[1Bb7cd68e5: Pulling fs layer \n",
      "\u001b[1B10701a5b: Pulling fs layer \n",
      "\u001b[1Ba9230f8f: Pulling fs layer \n",
      "\u001b[1Ba1861813: Pulling fs layer \n",
      "\u001b[1B3d7242f5: Pulling fs layer \n",
      "\u001b[1B5cca3a04: Pulling fs layer \n",
      "\u001b[1Be802b8d1: Pulling fs layer \n",
      "\u001b[11B7ca5e65: Waiting fs layer \n",
      "\u001b[1Bb700ef54: Pulling fs layer \n",
      "\u001b[1Bf6d9a8b1: Pulling fs layer \n",
      "\u001b[1B12e53c5d: Pulling fs layer \n",
      "\u001b[1B191d66bf: Pulling fs layer \n",
      "\u001b[11B9230f8f: Waiting fs layer \n",
      "\u001b[1Baf630b7f: Pulling fs layer \n",
      "\u001b[1B8c43ea0e: Pulling fs layer \n",
      "\u001b[10B802b8d1: Waiting fs layer \n",
      "\u001b[10Baacfed4: Waiting fs layer \n",
      "\u001b[18B7cd68e5: Waiting fs layer \n",
      "\u001b[16B1861813: Waiting fs layer \n",
      "\u001b[16Bd7242f5: Waiting fs layer \n",
      "\u001b[8Baf630b7f: Waiting fs layer \n",
      "\u001b[10B5867fa7: Waiting fs layer \n",
      "\u001b[9B8c43ea0e: Waiting fs layer \n",
      "\u001b[9B0cf75e3a: Waiting fs layer \n",
      "\u001b[1B8154ec1e: Pulling fs layer \n",
      "\u001b[10B5a5a8e5: Waiting fs layer \n",
      "\u001b[9B2d4b7a08: Waiting fs layer \n",
      "\u001b[18B2e53c5d: Waiting fs layer \n",
      "\u001b[4Bd4dfd950: Waiting fs layer \n",
      "\u001b[4B912a0f9a: Waiting fs layer \n",
      "\u001b[1B5501f24b: Pulling fs layer \n",
      "\u001b[10Bd49af3b: Waiting fs layer \n",
      "\u001b[1B54901c1c: Pulling fs layer \n",
      "\u001b[4B5501f24b: Waiting fs layer \n",
      "\u001b[3B54901c1c: Waiting fs layer \n",
      "\u001b[1BDigest: sha256:97f99409e3c54926af75204d9d9ecbec53b8f0aaaf8abe8d72d31a6198357b9a\u001b[2K\u001b[40A\u001b[2K\u001b[37A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[32A\u001b[2K\u001b[33A\u001b[2K\u001b[42A\u001b[2K\u001b[33A\u001b[2K\u001b[41A\u001b[2K\u001b[33A\u001b[2K\u001b[41A\u001b[2K\u001b[33A\u001b[2K\u001b[41A\u001b[2K\u001b[41A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[40A\u001b[2K\u001b[33A\u001b[2K\u001b[40A\u001b[2K\u001b[33A\u001b[2K\u001b[40A\u001b[2K\u001b[33A\u001b[2K\u001b[40A\u001b[2K\u001b[33A\u001b[2K\u001b[40A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[40A\u001b[2K\u001b[37A\u001b[2K\u001b[40A\u001b[2K\u001b[37A\u001b[2K\u001b[40A\u001b[2K\u001b[37A\u001b[2K\u001b[40A\u001b[2K\u001b[40A\u001b[2K\u001b[39A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[38A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[31A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[31A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[29A\u001b[2K\u001b[33A\u001b[2K\u001b[28A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[37A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[27A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[26A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[26A\u001b[2K\u001b[33A\u001b[2K\u001b[26A\u001b[2K\u001b[33A\u001b[2K\u001b[26A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[26A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[26A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[26A\u001b[2K\u001b[33A\u001b[2K\u001b[26A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[26A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[26A\u001b[2K\u001b[37A\u001b[2K\u001b[26A\u001b[2K\u001b[30A\u001b[2K\u001b[26A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[25A\u001b[2K\u001b[30A\u001b[2K\u001b[25A\u001b[2K\u001b[30A\u001b[2K\u001b[25A\u001b[2K\u001b[33A\u001b[2K\u001b[25A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[25A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[25A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[24A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[23A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[23A\u001b[2K\u001b[30A\u001b[2K\u001b[22A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[21A\u001b[2K\u001b[33A\u001b[2K\u001b[20A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[19A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[19A\u001b[2K\u001b[33A\u001b[2K\u001b[19A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[19A\u001b[2K\u001b[37A\u001b[2K\u001b[19A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[19A\u001b[2K\u001b[37A\u001b[2K\u001b[19A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[19A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[19A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[19A\u001b[2K\u001b[33A\u001b[2K\u001b[19A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[19A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[19A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[19A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[19A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[37A\u001b[2K\u001b[33A\u001b[2K\u001b[19A\u001b[2K\u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[19A\u001b[2K\u001b[30A\u001b[2K\u001b[33A\u001b[2K\u001b[19A\u001b[2K\u001b[37A\u001b[2K\u001b[19A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[19A\u001b[2K\u001b[17A\u001b[2K\u001b[19A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[16A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[30A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[9A\u001b[2K\u001b[30A\u001b[2K\u001b[7A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[5A\u001b[2K\u001b[37A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[5A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2KExtracting  588.3MB/1.291GB\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[37A\u001b[2K\u001b[5A\u001b[2K\u001b[37A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[5A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[3A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[30A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2KExtracting  749.8MB/1.291GB\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[8A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[2A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2KExtracting  633.4MB/1.642GB\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[29A\u001b[2K\u001b[29A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[21A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\n",
      "Status: Downloaded newer image for gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest\n",
      "2024-03-18 16:48:13.942487: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-18 16:48:14.004831: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 16:48:15.165231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_2b_en/2/download/config.json...\n",
      "<class 'list'> ['[\"Sender: FoooodddAndres Perez: Coming :)\", \"Sender: Can I maybe borrow your iron? Andres Perez: It\\'s not my iron But yeah haha Or is it?\"]']\n",
      "<class 'str'> {'finetuned_model_dir': './gemma_2b_en', 'finetuned_weights_path': './gemma_2b_en/model.weights.h5'}\n",
      "Hasta aqui jala\n",
      "andrehpereh1\n",
      "5859e39806d9456749dcbac685f04bc9\n",
      "100%|██████████| 555/555 [00:00<00:00, 1.91MB/s]\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_2b_en/2/download/model.weights.h5...\n",
      "100%|██████████| 4.67G/4.67G [00:49<00:00, 101MB/s] \n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_2b_en/2/download/tokenizer.json...\n",
      "100%|██████████| 401/401 [00:00<00:00, 1.15MB/s]\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_2b_en/2/download/assets/tokenizer/vocabulary.spm...\n",
      "100%|██████████| 4.04M/4.04M [00:00<00:00, 16.1MB/s]\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "Aqui ya no\n",
      "Preprocessor: \"gemma_causal_lm_preprocessor\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "┃ Tokenizer (type)                                   ┃                          \n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "│ gemma_tokenizer (GemmaTokenizer)                   │                          \n",
      "└────────────────────────────────────────────────────┴──────────────────────────\n",
      "Model: \"gemma_causal_lm\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━\n",
      "┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ \n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━\n",
      "│ padding_mask (InputLayer)     │ (None, None)              │               0 │ \n",
      "├───────────────────────────────┼───────────────────────────┼─────────────────┼─\n",
      "│ token_ids (InputLayer)        │ (None, None)              │               0 │ \n",
      "├───────────────────────────────┼───────────────────────────┼─────────────────┼─\n",
      "│ gemma_backbone                │ (None, None, 2048)        │   2,506,172,416 │ \n",
      "│ (GemmaBackbone)               │                           │                 │ \n",
      "├───────────────────────────────┼───────────────────────────┼─────────────────┼─\n",
      "│ token_embedding               │ (None, None, 256000)      │     524,288,000 │ \n",
      "│ (ReversibleEmbedding)         │                           │                 │ \n",
      "└───────────────────────────────┴───────────────────────────┴─────────────────┴─\n",
      " Total params: 2,506,172,416 (9.34 GB)\n",
      " Trainable params: 2,506,172,416 (9.34 GB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "Preprocessor: \"gemma_causal_lm_preprocessor\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "┃ Tokenizer (type)                                   ┃                          \n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "│ gemma_tokenizer (GemmaTokenizer)                   │                          \n",
      "└────────────────────────────────────────────────────┴──────────────────────────\n",
      "Model: \"gemma_causal_lm\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━\n",
      "┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ \n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━\n",
      "│ padding_mask (InputLayer)     │ (None, None)              │               0 │ \n",
      "├───────────────────────────────┼───────────────────────────┼─────────────────┼─\n",
      "│ token_ids (InputLayer)        │ (None, None)              │               0 │ \n",
      "├───────────────────────────────┼───────────────────────────┼─────────────────┼─\n",
      "│ gemma_backbone                │ (None, None, 2048)        │   2,508,218,368 │ \n",
      "│ (GemmaBackbone)               │                           │                 │ \n",
      "├───────────────────────────────┼───────────────────────────┼─────────────────┼─\n",
      "│ token_embedding               │ (None, None, 256000)      │     524,288,000 │ \n",
      "│ (ReversibleEmbedding)         │                           │                 │ \n",
      "└───────────────────────────────┴───────────────────────────┴─────────────────┴─\n",
      " Total params: 2,508,218,368 (9.34 GB)\n",
      " Trainable params: 2,045,952 (7.80 MB)\n",
      " Non-trainable params: 2,506,172,416 (9.34 GB)\n",
      "Epoch 1/2\n",
      "2024-03-18 16:49:51.191701: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT64 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710780613.826860      38 service.cc:145] XLA service 0x7f8770013960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1710780613.826908      38 service.cc:153]   StreamExecutor device (0): Host, Default Version\n",
      "2024-03-18 16:50:14.618130: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1710780616.532369      38 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1710780656.984836      38 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 75s/step - loss: 0.8387 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step - loss: 0.8370 - sparse_categorical_accuracy: 0.2750\n",
      "Saving model in  ./gemma_2b_en\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = '\"[\\\\\"Sender: FoooodddAndres Perez: Coming :)\\\\\", \\\\\"Sender: Can I maybe borrow your iron? Andres Perez: It\\'s not my iron But yeah haha Or is it?\\\\\"]\"'\n",
    "model_paths = \"\"\"{\"finetuned_model_dir\": \"./gemma_2b_en\", \"finetuned_weights_path\": \"./gemma_2b_en/model.weights.h5\"}\"\"\"\n",
    "\n",
    "#!docker run gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest import test_container \"test_container.add_test('[a, b]', {'a': \"b\"})\"\n",
    "\n",
    "!docker run gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest trainer.py --data {data} --model-paths {model_paths_json}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2d84c44-c65c-4ae1-9a4c-6d293f139495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinetuned_weights_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "model_paths['finetuned_weights_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e6404c6c-d998-4253-bbf3-3f83b29abe94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CONTAINER_IMAGE_NAME=gemma-chatbot-experimental,TAG_NAME=latest\n",
      "3\n",
      "experimental.py <class 'str'>\n",
      "\"[\\\"Sender: FoooodddAndres Perez: Coming :)\\\", \\\"Sender: Can I maybe borrow your iron? Andres Perez: It's not my iron But yeah haha Or is it?\\\"]\" <class 'str'>\n",
      "{\"finetuned_model_dir\": \"./gemma_2b_en\", \"finetuned_weights_path\": \"./gemma_2b_en/model.weights.h5\"} <class 'str'>\n",
      "This is type param1 <class 'str'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "Jalo todo bien\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-experimental\",\n",
    "           TAG_NAME,\n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n",
    "data = '\"[\\\\\"Sender: FoooodddAndres Perez: Coming :)\\\\\", \\\\\"Sender: Can I maybe borrow your iron? Andres Perez: It\\'s not my iron But yeah haha Or is it?\\\\\"]\"'\n",
    "model_paths = \"\"\"{\"finetuned_model_dir\": \"./gemma_2b_en\", \"finetuned_weights_path\": \"./gemma_2b_en/model.weights.h5\"}\"\"\"\n",
    "data_json = json.dumps(data)\n",
    "model_paths_json = json.dumps(model_paths)\n",
    "#!gcloud builds submit . --timeout=15m --config \"components/experimental/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n",
    "!docker run gcr.io/able-analyst-416817/gemma-chatbot-experimental:latest experimental.py {data_json} {model_paths_json}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff6c518-79e1-4ec6-a832-39ae6f364ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CONTAINER_IMAGE_NAME=gemma-chatbot-fine-tunning,_GCP_REGION=us-central1,TAG_NAME=latest\n"
     ]
    }
   ],
   "source": [
    "#Re-runs the image to restart the website, service account might be needed with this one.  (Development, when tested should be moved to the main cloudbuild in the project folder)\n",
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "_GCP_REGION={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-running-app\",\n",
    "           GCP_REGION,\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n",
    "!gcloud builds submit . --timeout=15m --config \"components/app_flask/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n",
    "!gcloud builds submit . --timeout=15m --config \"cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1cae7-c300-4cd1-aa97-c7fef2efaa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05aa3f-9a40-41db-8553-b65d7dee4352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "_GCP_REGION={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-running-app\",\n",
    "           GCP_REGION,\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n",
    "!gcloud builds submit . --timeout=15m --config \"components/app_flask/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n",
    "!gcloud builds submit . --timeout=15m --config \"cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb10f3c-b135-470b-a74b-0c825e0f0761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0aa1979-e2f1-41ce-a3f4-bab8465866e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_paths_and_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 63\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m finetuned_weights_path\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# @dsl.container_component\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# def container_with_artifact_output(\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#     num_epochs: int,  # built-in types are parsed as inputs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#             model_config_path,\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#         ])\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;129m@dsl\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpythagorean\u001b[39m(\n\u001b[1;32m     62\u001b[0m     bucket_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mable-analyst-416817-chatbot-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_data/andrehpereh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m---> 63\u001b[0m     model_paths: \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_paths_and_config\u001b[49m\n\u001b[1;32m     64\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     65\u001b[0m     whatup \u001b[38;5;241m=\u001b[39m process_whatsapp_chat_op(bucket_name \u001b[38;5;241m=\u001b[39m bucket_name, directory \u001b[38;5;241m=\u001b[39m directory)\n\u001b[1;32m     66\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m fine_tunning(dataset_path\u001b[38;5;241m=\u001b[39mwhatup\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_path\u001b[39m\u001b[38;5;124m'\u001b[39m], model_paths\u001b[38;5;241m=\u001b[39mmodel_paths)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_paths_and_config' is not defined"
     ]
    }
   ],
   "source": [
    "import kfp.dsl as dsl\n",
    "from typing import List\n",
    "from kfp import compiler\n",
    "\n",
    "@dsl.component(\n",
    "  base_image ='gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest'\n",
    ")\n",
    "def process_whatsapp_chat_op(\n",
    "  bucket_name: str,\n",
    "  directory: str,\n",
    "  output_path: dsl.OutputPath(List)\n",
    "):\n",
    "    import data_ingestion\n",
    "    formatted_messages = data_ingestion.process_whatsapp_chat(bucket_name, directory)\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(features, f)\n",
    "\n",
    "\n",
    "@dsl.component\n",
    "def fine_tunning(dataset: dsl.InputPath(List)):\n",
    "    with open(features_path, 'r') as f:\n",
    "        features = json.load(f)\n",
    "    print(features, type(features))\n",
    "\n",
    "@dsl.pipeline(name=\"whatsapp-chat\")\n",
    "def pipeline(\n",
    "    bucket_name: str,\n",
    "    directory: str,\n",
    "):\n",
    "    create_dataset_op = process_whatsapp_chat_op(\n",
    "        bucket_name=bucket_name,\n",
    "        directory=directory\n",
    "    )\n",
    "    fine_tunning(dataset=create_dataset_op.outputs['output_path'])\n",
    "    \n",
    "    \n",
    "    \n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"test-whatsapp.json\"\n",
    ")\n",
    "\n",
    "from google.cloud import aiplatform as vertexai\n",
    "GCS_BUCKET = f\"gs://{PROJECT_ID}-pipe_line/\"\n",
    "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)\n",
    "\n",
    "vertex_pipelines_job = vertexai.pipeline_jobs.PipelineJob(\n",
    "    display_name=\"test-whatsapp\",\n",
    "    template_path=\"test-whatsapp.json\",\n",
    "    parameter_values={\n",
    "        \"bucket_name\": \"able-analyst-416817-chatbot-v1\",\n",
    "        \"directory\": \"input_data/andrehpereh\"\n",
    "        # \"project\": PROJECT_ID,\n",
    "        # \"location\": REGION,\n",
    "        #\"staging_bucket\": GCS_BUCKET,\n",
    "        #\"display_name\": \"El name to displayed\",        \n",
    "        #\"container_uri\": IMAGE_URI,\n",
    "        #\"model_serving_container_image_uri\": SERVING_IMAGE_URI,        \n",
    "        #\"base_output_dir\": GCS_BASE_OUTPUT_DIR},,\n",
    "        #\"accelerator_type\": \"NVIDIA_L4\",\n",
    "        #\"accelerator_count\": 1,\n",
    "        #\"replica_count\": 1,\n",
    "        #\"machine_type\": \"g2-standard-8\"\n",
    "    },\n",
    "    enable_caching=True\n",
    ")\n",
    "vertex_pipelines_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53b974a3-cab2-425e-bfc5-dcb01d45b5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11402c19-d1b8-4b8c-a959-932ca09fcf18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cf7ac36-bc0e-4e00-928f-1c7247b9685e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09398956-e97e-411b-a1fe-9e05ff61e6d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafdfdea-c57b-4a26-ac5f-2775ff291bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed69c43-8407-460b-bd2d-1ac0ed39a610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m118"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
