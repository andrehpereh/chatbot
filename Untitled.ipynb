{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d1996b-53c3-4fd2-a962-fc267008a4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gemma_2b_en\n",
      "{'model_size': '2b', 'finetuned_model_dir': './gemma_2b_en', 'finetuned_weights_path': './gemma_2b_en/model.weights.h5', 'finetuned_vocab_path': './gemma_2b_en/vocabulary.spm', 'huggingface_model_dir': './gemma_2b_en_huggingface', 'deployed_model_blob': 'gemma_2b_en/20240322091040', 'deployed_model_uri': 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240322091040', 'fine_tuned_keras_blob': 'gemma_2b_en/keras/20240322091040', 'model_name_vllm': 'gemma_2b_en-vllm', 'machine_type': 'g2-standard-8', 'accelerator_type': 'NVIDIA_L4', 'accelerator_count': 1}\n"
     ]
    }
   ],
   "source": [
    "from config import Config\n",
    "from util import get_model_paths_and_config, upload2bs\n",
    "\n",
    "res = !gcloud config get core/project\n",
    "PROJECT_ID = res[0]\n",
    "SERVICE_ACCOUNT = 'gemma-vertexai-chatbot@able-analyst-416817.iam.gserviceaccount.com'\n",
    "from datetime import datetime\n",
    "CONTAINER_IMAGE_NAME=\"gemma-chatbot\"\n",
    "GCP_REGION='us-central1'\n",
    "IMAGE_NAME=\"gemma-chatbot\"\n",
    "TAG_NAME = 'latest'\n",
    "KAGGLE_USERNAME='andrehpereh1'\n",
    "KAGGLE_KEY='5859e39806d9456749dcbac685f04bc9'\n",
    "model_paths_and_config = get_model_paths_and_config(Config.MODEL_NAME)\n",
    "print(model_paths_and_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e02847f-0543-4190-9d14-08bb08bbacc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'able-analyst-416817'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0038c4-a645-4583-bf65-aaaae8d82f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!gsutil cp -r 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en_raw/gemma_2b_en/' ./gemma_2b_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55303381-9a0c-4754-9e55-2c2e6a083341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from components.fine_tunning import util\n",
    "bucket_name = 'able-analyst-416817-chatbot-v1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a1558c9-51a2-45fe-8412-ab197af7de2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This are the blobs <google.api_core.page_iterator.HTTPIterator object at 0x7fdbc28dbfd0>\n",
      "gemma_2b_en_raw/gemma_2b_en/model.weights.h5\n",
      "This is the file name model.weights.h5\n",
      "Downloaded gs://able-analyst-416817-chatbot-v1/gemma_2b_en_raw/gemma_2b_en/model.weights.h5 to ./gemma_2b_en/model.weights.h5\n",
      "gemma_2b_en_raw/gemma_2b_en/vocabulary.spm\n",
      "This is the file name vocabulary.spm\n",
      "Downloaded gs://able-analyst-416817-chatbot-v1/gemma_2b_en_raw/gemma_2b_en/vocabulary.spm to ./gemma_2b_en/vocabulary.spm\n"
     ]
    }
   ],
   "source": [
    "util.download_all_from_blob(bucket_name,'gemma_2b_en_raw/gemma_2b_en/', local_destination=model_paths_and_config['finetuned_model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5956136-237a-4a2d-a903-2d5de4da3833",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: Destination URL must name a directory, bucket, or bucket\n",
      "subdirectory for the multiple source form of the cp command.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511e065f-7132-49f6-9568-0b0f6b50c34f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_size': '2b',\n",
       " 'finetuned_model_dir': './gemma_2b_en',\n",
       " 'finetuned_weights_path': './gemma_2b_en/model.weights.h5',\n",
       " 'finetuned_vocab_path': './gemma_2b_en/vocabulary.spm',\n",
       " 'huggingface_model_dir': './gemma_2b_en_huggingface',\n",
       " 'deployed_model_blob': 'gemma_2b_en/20240321152510',\n",
       " 'deployed_model_uri': 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240321152510',\n",
       " 'fine_tuned_keras_blob': 'gemma_2b_en/keras/20240321152510',\n",
       " 'model_name_vllm': 'gemma_2b_en-vllm',\n",
       " 'machine_type': 'g2-standard-8',\n",
       " 'accelerator_type': 'NVIDIA_L4',\n",
       " 'accelerator_count': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths_and_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c342ca7-9377-4e5a-824a-d5223d06958f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able-analyst-416817-chatbot-v1', 'gemma_2b_en/keras']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths_and_config['finetuned_model_dir']\n",
    "import os\n",
    "os.path.dirname(\"gs://able-analyst-416817-chatbot-v1/gemma_2b_en/keras/20240321152510\").lstrip(\"gs://\").split(\"/\", 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884e8f48-5474-4aea-94e7-7c7ed1ad04ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded ./gemma_2b_en/model.weights.h5 to gs://able-analyst-416817-chatbot-v1/gemma_2b_en/keras/20240321221804/model.weights.h5\n",
      "Uploaded ./gemma_2b_en/vocabulary.spm to gs://able-analyst-416817-chatbot-v1/gemma_2b_en/keras/20240321221804/vocabulary.spm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/keras/20240321221804'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.upload2bs(\n",
    "    local_directory = model_paths_and_config['finetuned_model_dir'], bucket_name = bucket_name,\n",
    "    destination_subfolder = model_paths_and_config['fine_tuned_keras_blob']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ec7b9f-de03-49cd-9e08-22312fb9cd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able-analyst-416817-chatbot-v1', 'gemma_2b_en/keras']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.dirname(\"gs://able-analyst-416817-chatbot-v1/gemma_2b_en/keras/20240321221804\").lstrip(\"gs://\").split(\"/\", 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8cd43c-180b-4c8f-a2f1-d3fb99f20e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c4b92-ca80-44a7-a8ee-344f6d9b0ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_5132/2833041202.py:2: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  import kfp.v2 as kfp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma_2b_en\n",
      "./gemma_2b_en\n",
      "{'model_size': '2b', 'finetuned_model_dir': './gemma_2b_en', 'finetuned_weights_path': './gemma_2b_en/model.weights.h5', 'finetuned_vocab_path': './gemma_2b_en/vocabulary.spm', 'huggingface_model_dir': './gemma_2b_en_huggingface', 'deployed_model_blob': 'gemma_2b_en/20240322091040', 'deployed_model_uri': 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240322091040', 'fine_tuned_keras_blob': 'gemma_2b_en/keras/20240322091040', 'model_name_vllm': 'gemma_2b_en-vllm', 'machine_type': 'g2-standard-8', 'accelerator_type': 'NVIDIA_L4', 'accelerator_count': 1}\n",
      "./gemma_2b_en\n",
      "./gemma_2b_en\n",
      "This is the dictionary {'model_size': '2b', 'finetuned_model_dir': './gemma_2b_en', 'finetuned_weights_path': './gemma_2b_en/model.weights.h5', 'finetuned_vocab_path': './gemma_2b_en/vocabulary.spm', 'huggingface_model_dir': './gemma_2b_en_huggingface', 'deployed_model_blob': 'gemma_2b_en/20240322091040', 'deployed_model_uri': 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240322091040', 'fine_tuned_keras_blob': 'gemma_2b_en/keras/20240322091040', 'model_name_vllm': 'gemma_2b_en-vllm', 'machine_type': 'g2-standard-8', 'accelerator_type': 'NVIDIA_L4', 'accelerator_count': 1}\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240322091102\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240322091102')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/pythagorean-20240322091102?project=24796876098\n",
      "PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240322091102 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240322091102 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240322091102 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "from kfp import dsl\n",
    "import kfp.v2 as kfp\n",
    "from kfp.dsl import OutputPath, Artifact, InputPath\n",
    "from kfp import compiler\n",
    "VLLM_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240220_0936_RC01\"\n",
    "from config import Config\n",
    "print(Config.MODEL_NAME)\n",
    "model_paths_and_config = get_model_paths_and_config(Config.MODEL_NAME)\n",
    "print(model_paths_and_config)\n",
    "# from google_cloud_pipeline_components.v1.custom_job import create_custom_training_job_from_component\n",
    "# from google_cloud_pipeline_components.v1.custom_job import CustomTrainingJobOp\n",
    "accelerator_count = 1\n",
    "max_model_len = 512\n",
    "dtype = 'bfloat16'\n",
    "\n",
    "vllm_args = [\n",
    "    \"--host=0.0.0.0\",\n",
    "    \"--port=7080\",\n",
    "    f\"--tensor-parallel-size={accelerator_count}\",\n",
    "    \"--swap-space=16\",\n",
    "    \"--gpu-memory-utilization=0.95\",\n",
    "    f\"--max-model-len={max_model_len}\",\n",
    "    f\"--dtype={dtype}\",\n",
    "    \"--disable-log-stats\",\n",
    "]\n",
    "\n",
    "\n",
    "@dsl.component(\n",
    "  base_image ='gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest'\n",
    ")\n",
    "def process_whatsapp_chat_op(\n",
    "  bucket_name: str,\n",
    "  directory: str,\n",
    "  dataset_path: OutputPath('Dataset')\n",
    "):\n",
    "    import data_ingestion\n",
    "    import json\n",
    "    formatted_messages = data_ingestion.process_whatsapp_chat(bucket_name, directory)\n",
    "    with open(dataset_path, 'w') as f:\n",
    "        json.dump(formatted_messages, f)\n",
    "\n",
    "\n",
    "@dsl.component(\n",
    "  base_image = 'gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest'\n",
    ")\n",
    "def fine_tunning(\n",
    "  dataset_path: InputPath('Dataset'),\n",
    "  model_paths: dict,\n",
    "  #finetuned_weights_dir: OutputPath('Model'),\n",
    ") -> str:\n",
    "    # import test_container\n",
    "    import trainer\n",
    "    import json\n",
    "    import util\n",
    "    import os\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "    os.makedirs(model_paths['finetuned_model_dir'], exist_ok=True)\n",
    "    finetuned_weights_path = os.path.join(model_paths['finetuned_model_dir'], 'model.weights.h5') \n",
    "    \n",
    "    model = trainer.finetune_gemma(dataset, model_paths, False)\n",
    "    print(\"Its gonna save it here\", finetuned_weights_path)\n",
    "    #model.save_weights(finetuned_weights_path)\n",
    "    #model.preprocessor.tokenizer.save_assets(model_paths['finetuned_model_dir'])\n",
    "    bucket_name = 'able-analyst-416817-chatbot-v1' # move to parameter.\n",
    "    util.upload2bs(\n",
    "        local_directory = model_paths['finetuned_model_dir'], bucket_name = bucket_name,\n",
    "        destination_subfolder = model_paths['fine_tuned_keras_blob']\n",
    "    )\n",
    "    model_gcs = \"gs://{}/{}\".format(bucket_name, model_paths['fine_tuned_keras_blob'])  \n",
    "    print(\"This is the storage bucket\", model_gcs)\n",
    "    return model_gcs\n",
    "    \n",
    "\n",
    "@dsl.component(\n",
    "  base_image = 'gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest'\n",
    ")\n",
    "def convert_checkpoints_op(\n",
    "  keras_gcs_model: str,\n",
    "  model_paths: dict\n",
    ") -> str:\n",
    "    import conversion_function\n",
    "    import os\n",
    "    import util\n",
    "    bucket_name, blob_name = os.path.dirname(keras_gcs_model).lstrip(\"gs://\").split(\"/\", 1) \n",
    "    print(\"This is the keras passed\", keras_gcs_model)\n",
    "    util.download_all_from_blob(bucket_name, model_paths['fine_tuned_keras_blob'], local_destination=model_paths['finetuned_model_dir'])\n",
    "    if os.path.exists(\"./model.weights.h5\"):\n",
    "        print(\"File exists!\")\n",
    "    else:\n",
    "        print(\"File does not exist.\")\n",
    "    converted_fined_tuned_path = conversion_function.convert_checkpoints(\n",
    "        weights_file=model_paths['finetuned_weights_path'],\n",
    "        size=model_paths['model_size'],\n",
    "        output_dir=model_paths['huggingface_model_dir'],\n",
    "        vocab_path=model_paths['finetuned_vocab_path']\n",
    "    )\n",
    "    util.upload2bs(\n",
    "        local_directory = converted_fined_tuned_path, bucket_name = bucket_name,\n",
    "        destination_subfolder = model_paths['deployed_model_blob']\n",
    "    )\n",
    "    return model_paths['deployed_model_uri']\n",
    "\n",
    "\n",
    "\n",
    "@dsl.pipeline\n",
    "def pythagorean(\n",
    "    bucket_name: str = \"able-analyst-416817-chatbot-v1\", directory: str = \"input_data/andrehpereh\", \n",
    "    model_paths: dict=get_model_paths_and_config(Config.MODEL_NAME)\n",
    "):\n",
    "    # from google_cloud_pipeline_components import ModelUploadOp\n",
    "    model_paths = get_model_paths_and_config(Config.MODEL_NAME)\n",
    "    whatup = process_whatsapp_chat_op(bucket_name = bucket_name, directory = directory)\n",
    "\n",
    "    trainer = fine_tunning(dataset_path=whatup.outputs['dataset_path'], model_paths=model_paths)\n",
    "    trainer.set_memory_limit(\"40G\").set_cpu_limit('8.0m') .set_accelerator_limit(1).add_node_selector_constraint(\"NVIDIA_L4\")\n",
    "    \n",
    "    print(\"This is the dictionary\", model_paths)\n",
    "    converted = convert_checkpoints_op(\n",
    "        keras_gcs_model=trainer.output, model_paths=model_paths\n",
    "    ).set_memory_limit(\"40G\").set_cpu_limit('8.0m').set_accelerator_limit(1).add_node_selector_constraint(\"NVIDIA_L4\")\n",
    "\n",
    "    \n",
    "    \n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pythagorean, package_path=\"test-whatsapp.json\"\n",
    ")\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "vertex_pipelines_job = vertexai.pipeline_jobs.PipelineJob(\n",
    "    display_name=\"test-whatsapp\",\n",
    "    template_path=\"test-whatsapp.json\"\n",
    ")\n",
    "#vertex_pipelines_job.worker_pool_specs = worker_pool_specs \n",
    "vertex_pipelines_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec7859-6830-46ae-9e4d-4362a279e72c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google_cloud_pipeline_components\n",
    "google_cloud_pipeline_components.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50172f7-8917-426c-95f7-978d7646750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "model = ModelUploadOp(\n",
    "    project=PROJECT_ID,\n",
    "    display_name=\"Uploading model, ahuevito\",\n",
    "    artifact_uri=converted.output,\n",
    "    serving_container_image_uri=VLLM_DOCKER_URI,\n",
    "    serving_container_command=[\"python\", \"-m\", \"vllm.entrypoints.api_server\"],\n",
    "    serving_container_args=vllm_args,\n",
    "    serving_container_ports=[7080],\n",
    "    serving_container_predict_route=\"/generate\",\n",
    "    serving_container_health_route=\"/ping\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b346137-775d-42b8-94eb-36fb3a7cc3db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gemma_2b_en\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_size': '2b',\n",
       " 'finetuned_model_dir': './gemma_2b_en',\n",
       " 'finetuned_weights_path': './gemma_2b_en/model.weights.h5',\n",
       " 'finetuned_vocab_path': './gemma_2b_en/vocabulary.spm',\n",
       " 'huggingface_model_dir': './gemma_2b_en_huggingface',\n",
       " 'deployed_model_blob': 'gemma_2b_en/20240321152510',\n",
       " 'deployed_model_uri': 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240321152510',\n",
       " 'fine_tuned_keras_blob': 'gemma_2b_en/keras/20240321152510',\n",
       " 'model_name_vllm': 'gemma_2b_en-vllm',\n",
       " 'machine_type': 'g2-standard-8',\n",
       " 'accelerator_type': 'NVIDIA_L4',\n",
       " 'accelerator_count': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_paths_and_config(Config.MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4125113b-eee3-4ca4-bdf9-5f795b15fc31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_paths\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_paths' is not defined"
     ]
    }
   ],
   "source": [
    "model_paths['model_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d50ae2be-d6e3-4c74-bce1-667213a8e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp,\n",
    "                                                          ModelDeployOp)\n",
    "from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "from google_cloud_pipeline_components import aiplatform as aip_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1390fd2c-ba6d-4429-9ab5-b6238b027306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ContainerComponent in module kfp.dsl.container_component_class object:\n",
      "\n",
      "class ContainerComponent(kfp.dsl.base_component.BaseComponent)\n",
      " |  ContainerComponent(component_spec: kfp.dsl.structures.ComponentSpec, pipeline_func: Callable) -> None\n",
      " |  \n",
      " |  Component defined via pre-built container.\n",
      " |  \n",
      " |  Attribute:\n",
      " |      pipeline_func: The function that becomes the implementation of this component.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ContainerComponent\n",
      " |      kfp.dsl.base_component.BaseComponent\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, component_spec: kfp.dsl.structures.ComponentSpec, pipeline_func: Callable) -> None\n",
      " |      Init function for BaseComponent.\n",
      " |      \n",
      " |      Args:\n",
      " |        component_spec: The component definition.\n",
      " |  \n",
      " |  execute(self, **kwargs)\n",
      " |      Executes the component locally if implemented by the inheriting\n",
      " |      subclass.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from kfp.dsl.base_component.BaseComponent:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs) -> kfp.dsl.pipeline_task.PipelineTask\n",
      " |      Creates a PipelineTask object.\n",
      " |      \n",
      " |      The arguments are generated on the fly based on component input\n",
      " |      definitions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from kfp.dsl.base_component.BaseComponent:\n",
      " |  \n",
      " |  pipeline_spec\n",
      " |      Returns the pipeline spec of the component.\n",
      " |  \n",
      " |  platform_spec\n",
      " |      Returns the PlatformSpec of the component.\n",
      " |      \n",
      " |      Useful when the component is a GraphComponent, else will be\n",
      " |      empty per component_spec.platform_spec default.\n",
      " |  \n",
      " |  required_inputs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from kfp.dsl.base_component.BaseComponent:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ModelUploadOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ec7c1-1e80-4be7-9d73-043bbbb9b4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m118"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
