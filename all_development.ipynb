{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f178cfef-2782-4a77-b4f8-7d372a7c61f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CONTAINER_IMAGE_NAME_PIPELINE=gemma-chatbot-pipeline-app,TAG_NAME=masterv6,_BUCKET_NAME=able-analyst-416817-chatbot-v1,_FINE_TUNE_FLAG=False,_EPOCHS=12,_MODEL_NAME=gemma_2b_en\n",
      "Creating temporary tarball archive of 141 file(s) totalling 933.5 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://able-analyst-416817_cloudbuild/source/1712075595.902513-c03f0b1a20b34da2ab5574f2289c232b.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/able-analyst-416817/locations/us-central1/builds/b55fd38c-159e-41ab-b1f8-4e20ec798cb5].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds;region=us-central1/b55fd38c-159e-41ab-b1f8-4e20ec798cb5?project=24796876098 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"b55fd38c-159e-41ab-b1f8-4e20ec798cb5\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://able-analyst-416817_cloudbuild/source/1712075595.902513-c03f0b1a20b34da2ab5574f2289c232b.tgz#1712075596545356\n",
      "Copying gs://able-analyst-416817_cloudbuild/source/1712075595.902513-c03f0b1a20b34da2ab5574f2289c232b.tgz#1712075596545356...\n",
      "/ [1 files][482.9 KiB/482.9 KiB]                                                \n",
      "Operation completed over 1 objects/482.9 KiB.\n",
      "BUILD\n",
      "Starting Step #0 - \"P_A\"\n",
      "Step #0 - \"P_A\": Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0 - \"P_A\": Sending build context to Docker daemon  77.31kB\n",
      "Step #0 - \"P_A\": Step 1/10 : FROM python:3.9-slim\n",
      "Step #0 - \"P_A\": 3.9-slim: Pulling from library/python\n",
      "Step #0 - \"P_A\": 8a1e25ce7c4f: Already exists\n",
      "Step #0 - \"P_A\": 1103112ebfc4: Pulling fs layer\n",
      "Step #0 - \"P_A\": 6e52db3290c0: Pulling fs layer\n",
      "Step #0 - \"P_A\": 937bce5dbc70: Pulling fs layer\n",
      "Step #0 - \"P_A\": 05e63546fee1: Pulling fs layer\n",
      "Step #0 - \"P_A\": 05e63546fee1: Waiting\n",
      "Step #0 - \"P_A\": 1103112ebfc4: Verifying Checksum\n",
      "Step #0 - \"P_A\": 1103112ebfc4: Download complete\n",
      "Step #0 - \"P_A\": 937bce5dbc70: Verifying Checksum\n",
      "Step #0 - \"P_A\": 937bce5dbc70: Download complete\n",
      "Step #0 - \"P_A\": 6e52db3290c0: Download complete\n",
      "Step #0 - \"P_A\": 05e63546fee1: Verifying Checksum\n",
      "Step #0 - \"P_A\": 05e63546fee1: Download complete\n",
      "Step #0 - \"P_A\": 1103112ebfc4: Pull complete\n",
      "Step #0 - \"P_A\": 6e52db3290c0: Pull complete\n",
      "Step #0 - \"P_A\": 937bce5dbc70: Pull complete\n",
      "Step #0 - \"P_A\": 05e63546fee1: Pull complete\n",
      "Step #0 - \"P_A\": Digest: sha256:0b4b0801ae9ae61bb57bc738b1efbe4e16b927fd581774c8edfed90f0e0f01ad\n",
      "Step #0 - \"P_A\": Status: Downloaded newer image for python:3.9-slim\n",
      "Step #0 - \"P_A\":  ---> 04efcd1709fb\n",
      "Step #0 - \"P_A\": Step 2/10 : WORKDIR /pipeline\n",
      "Step #0 - \"P_A\":  ---> Running in 3f296742a537\n",
      "Step #0 - \"P_A\": Removing intermediate container 3f296742a537\n",
      "Step #0 - \"P_A\":  ---> 1fc172609495\n",
      "Step #0 - \"P_A\": Step 3/10 : RUN ls\n",
      "Step #0 - \"P_A\":  ---> Running in 6ee9e668cf78\n",
      "Step #0 - \"P_A\": Removing intermediate container 6ee9e668cf78\n",
      "Step #0 - \"P_A\":  ---> bdf7fbdaa7c4\n",
      "Step #0 - \"P_A\": Step 4/10 : COPY requirements.txt .\n",
      "Step #0 - \"P_A\":  ---> e2f0681c6be0\n",
      "Step #0 - \"P_A\": Step 5/10 : RUN pip install -U -r requirements.txt\n",
      "Step #0 - \"P_A\":  ---> Running in 74831b825a6c\n",
      "Step #0 - \"P_A\": Collecting kfp==2.7.0\n",
      "Step #0 - \"P_A\":   Downloading kfp-2.7.0.tar.gz (441 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 441.8/441.8 kB 3.8 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\":   Preparing metadata (setup.py): started\n",
      "Step #0 - \"P_A\":   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #0 - \"P_A\": Collecting google-cloud-aiplatform==1.45.0\n",
      "Step #0 - \"P_A\":   Downloading google_cloud_aiplatform-1.45.0-py2.py3-none-any.whl (4.3 MB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.3/4.3 MB 34.5 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting google-cloud-pipeline-components==2.11.0\n",
      "Step #0 - \"P_A\":   Downloading google_cloud_pipeline_components-2.11.0-py3-none-any.whl (1.4 MB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 60.0 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting google-cloud-bigquery\n",
      "Step #0 - \"P_A\":   Downloading google_cloud_bigquery-3.20.1-py2.py3-none-any.whl (233 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.4/233.4 kB 32.0 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting pyarrow==15.0.2\n",
      "Step #0 - \"P_A\":   Downloading pyarrow-15.0.2-cp39-cp39-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.3/38.3 MB 28.0 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting click<9,>=8.0.0\n",
      "Step #0 - \"P_A\":   Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 16.2 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting docstring-parser<1,>=0.7.3\n",
      "Step #0 - \"P_A\":   Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Step #0 - \"P_A\": Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "Step #0 - \"P_A\":   Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.3/138.3 kB 21.4 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting google-auth<3,>=1.6.1\n",
      "Step #0 - \"P_A\":   Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189.2/189.2 kB 2.6 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting google-cloud-storage<3,>=2.2.1\n",
      "Step #0 - \"P_A\":   Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.6/125.6 kB 19.3 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting kfp-pipeline-spec==0.3.0\n",
      "Step #0 - \"P_A\":   Downloading kfp_pipeline_spec-0.3.0-py3-none-any.whl (12 kB)\n",
      "Step #0 - \"P_A\": Collecting kfp-server-api<2.1.0,>=2.0.0\n",
      "Step #0 - \"P_A\":   Downloading kfp-server-api-2.0.5.tar.gz (63 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.4/63.4 kB 10.1 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\":   Preparing metadata (setup.py): started\n",
      "Step #0 - \"P_A\":   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #0 - \"P_A\": Collecting kubernetes<27,>=8.0.0\n",
      "Step #0 - \"P_A\":   Downloading kubernetes-26.1.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 64.0 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting protobuf<5,>=4.21.1\n",
      "Step #0 - \"P_A\":   Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 kB 36.0 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting PyYAML<7,>=5.3\n",
      "Step #0 - \"P_A\":   Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 738.9/738.9 kB 40.4 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting requests-toolbelt<1,>=0.8.0\n",
      "Step #0 - \"P_A\":   Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 9.5 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting tabulate<1,>=0.8.6\n",
      "Step #0 - \"P_A\":   Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Step #0 - \"P_A\": Collecting urllib3<2.0.0\n",
      "Step #0 - \"P_A\":   Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.8/143.8 kB 24.1 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting packaging>=14.3\n",
      "Step #0 - \"P_A\":   Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.5/53.5 kB 9.0 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "Step #0 - \"P_A\":   Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.8/48.8 kB 8.6 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting pydantic<3\n",
      "Step #0 - \"P_A\":   Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 394.9/394.9 kB 39.5 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "Step #0 - \"P_A\":   Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 333.7/333.7 kB 34.0 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting shapely<3.0.0dev\n",
      "Step #0 - \"P_A\":   Downloading shapely-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 76.1 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting Jinja2<4,>=3.1.2\n",
      "Step #0 - \"P_A\":   Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.2/133.2 kB 20.6 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting numpy<2,>=1.16.6\n",
      "Step #0 - \"P_A\":   Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 35.8 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting google-resumable-media<3.0dev,>=0.6.0\n",
      "Step #0 - \"P_A\":   Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.6/80.6 kB 13.2 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting google-cloud-core<3.0.0dev,>=1.6.0\n",
      "Step #0 - \"P_A\":   Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Step #0 - \"P_A\": Collecting python-dateutil<3.0dev,>=2.7.2\n",
      "Step #0 - \"P_A\":   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 30.7 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting requests<3.0.0dev,>=2.21.0\n",
      "Step #0 - \"P_A\":   Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 10.6 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "Step #0 - \"P_A\":   Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.1/229.1 kB 31.3 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting grpcio<2.0dev,>=1.33.2\n",
      "Step #0 - \"P_A\":   Downloading grpcio-1.62.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 51.1 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "Step #0 - \"P_A\":   Downloading grpcio_status-1.62.1-py3-none-any.whl (14 kB)\n",
      "Step #0 - \"P_A\": Collecting pyasn1-modules>=0.2.1\n",
      "Step #0 - \"P_A\":   Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.2/181.2 kB 25.4 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting cachetools<6.0,>=2.0.0\n",
      "Step #0 - \"P_A\":   Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Step #0 - \"P_A\": Collecting rsa<5,>=3.1.4\n",
      "Step #0 - \"P_A\":   Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Step #0 - \"P_A\": Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "Step #0 - \"P_A\":   Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Step #0 - \"P_A\": Collecting google-crc32c<2.0dev,>=1.0\n",
      "Step #0 - \"P_A\":   Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Step #0 - \"P_A\": Collecting MarkupSafe>=2.0\n",
      "Step #0 - \"P_A\":   Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Step #0 - \"P_A\": Collecting six>=1.10\n",
      "Step #0 - \"P_A\":   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Step #0 - \"P_A\": Collecting certifi\n",
      "Step #0 - \"P_A\":   Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 24.7 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting requests-oauthlib\n",
      "Step #0 - \"P_A\":   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Step #0 - \"P_A\": Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.9/site-packages (from kubernetes<27,>=8.0.0->kfp==2.7.0->-r requirements.txt (line 1)) (58.1.0)\n",
      "Step #0 - \"P_A\": Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "Step #0 - \"P_A\":   Downloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.5/58.5 kB 9.7 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting annotated-types>=0.4.0\n",
      "Step #0 - \"P_A\":   Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Step #0 - \"P_A\": Collecting pydantic-core==2.16.3\n",
      "Step #0 - \"P_A\":   Downloading pydantic_core-2.16.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 44.8 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting typing-extensions>=4.6.1\n",
      "Step #0 - \"P_A\":   Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Step #0 - \"P_A\": Collecting idna<4,>=2.5\n",
      "Step #0 - \"P_A\":   Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.6/61.6 kB 11.0 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting charset-normalizer<4,>=2\n",
      "Step #0 - \"P_A\":   Downloading charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.3/142.3 kB 22.8 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting pyasn1<0.7.0,>=0.4.6\n",
      "Step #0 - \"P_A\":   Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.3/85.3 kB 15.4 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Collecting oauthlib>=3.0.0\n",
      "Step #0 - \"P_A\":   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Step #0 - \"P_A\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 24.3 MB/s eta 0:00:00\n",
      "Step #0 - \"P_A\": Building wheels for collected packages: kfp, kfp-server-api\n",
      "Step #0 - \"P_A\":   Building wheel for kfp (setup.py): started\n",
      "Step #0 - \"P_A\":   Building wheel for kfp (setup.py): finished with status 'done'\n",
      "Step #0 - \"P_A\":   Created wheel for kfp: filename=kfp-2.7.0-py3-none-any.whl size=610438 sha256=6fd1cf00b21fb54e97b495cd6fa4c3a1a4a3f7c850924809a52a197109d5c32e\n",
      "Step #0 - \"P_A\":   Stored in directory: /root/.cache/pip/wheels/6b/21/04/3a90a57cfed7fb3b132d75ef1617fdeaa85916b04551d5369d\n",
      "Step #0 - \"P_A\":   Building wheel for kfp-server-api (setup.py): started\n",
      "Step #0 - \"P_A\":   Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "Step #0 - \"P_A\":   Created wheel for kfp-server-api: filename=kfp_server_api-2.0.5-py3-none-any.whl size=114750 sha256=8a5000386efeaa577eefb184585a909d1c000ea42fdf5d75f1827bdbca4f6daf\n",
      "Step #0 - \"P_A\":   Stored in directory: /root/.cache/pip/wheels/a6/c9/de/9f6964cdffc4d454c0a96d34f9b5ea5e51fc3224ec379222ff\n",
      "Step #0 - \"P_A\": Successfully built kfp kfp-server-api\n",
      "Step #0 - \"P_A\": Installing collected packages: websocket-client, urllib3, typing-extensions, tabulate, six, PyYAML, pyasn1, protobuf, packaging, oauthlib, numpy, MarkupSafe, idna, grpcio, google-crc32c, docstring-parser, click, charset-normalizer, certifi, cachetools, annotated-types, shapely, rsa, requests, python-dateutil, pydantic-core, pyasn1-modules, pyarrow, proto-plus, kfp-pipeline-spec, Jinja2, googleapis-common-protos, google-resumable-media, requests-toolbelt, requests-oauthlib, pydantic, kfp-server-api, grpcio-status, google-auth, kubernetes, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, kfp, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "Step #0 - \"P_A\": Successfully installed Jinja2-3.1.3 MarkupSafe-2.1.5 PyYAML-6.0.1 annotated-types-0.6.0 cachetools-5.3.3 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 docstring-parser-0.16 google-api-core-2.18.0 google-auth-2.29.0 google-cloud-aiplatform-1.45.0 google-cloud-bigquery-3.20.1 google-cloud-core-2.4.1 google-cloud-pipeline-components-2.11.0 google-cloud-resource-manager-1.12.3 google-cloud-storage-2.16.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.63.0 grpc-google-iam-v1-0.13.0 grpcio-1.62.1 grpcio-status-1.62.1 idna-3.6 kfp-2.7.0 kfp-pipeline-spec-0.3.0 kfp-server-api-2.0.5 kubernetes-26.1.0 numpy-1.26.4 oauthlib-3.2.2 packaging-24.0 proto-plus-1.23.0 protobuf-4.25.3 pyarrow-15.0.2 pyasn1-0.6.0 pyasn1-modules-0.4.0 pydantic-2.6.4 pydantic-core-2.16.3 python-dateutil-2.9.0.post0 requests-2.31.0 requests-oauthlib-2.0.0 requests-toolbelt-0.10.1 rsa-4.9 shapely-2.0.3 six-1.16.0 tabulate-0.9.0 typing-extensions-4.10.0 urllib3-1.26.18 websocket-client-1.7.0\n",
      "Step #0 - \"P_A\": \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Step #0 - \"P_A\": \u001b[0m\u001b[91m\n",
      "Step #0 - \"P_A\": [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "Step #0 - \"P_A\": [notice] To update, run: pip install --upgrade pip\n",
      "Step #0 - \"P_A\": \u001b[0mRemoving intermediate container 74831b825a6c\n",
      "Step #0 - \"P_A\":  ---> cd15036311b1\n",
      "Step #0 - \"P_A\": Step 6/10 : COPY . /pipeline\n",
      "Step #0 - \"P_A\":  ---> a4a19fbeb70f\n",
      "Step #0 - \"P_A\": Step 7/10 : WORKDIR /pipeline\n",
      "Step #0 - \"P_A\":  ---> Running in aa63bc280235\n",
      "Step #0 - \"P_A\": Removing intermediate container aa63bc280235\n",
      "Step #0 - \"P_A\":  ---> 25f899d99379\n",
      "Step #0 - \"P_A\": Step 8/10 : RUN ls\n",
      "Step #0 - \"P_A\":  ---> Running in 2ef68c686cfe\n",
      "Step #0 - \"P_A\": Dockerfile\n",
      "Step #0 - \"P_A\": __init__.py\n",
      "Step #0 - \"P_A\": __pycache__\n",
      "Step #0 - \"P_A\": app.py\n",
      "Step #0 - \"P_A\": cloudbuild.yaml\n",
      "Step #0 - \"P_A\": config.py\n",
      "Step #0 - \"P_A\": fine_tune_pipelineandrehpereh.json\n",
      "Step #0 - \"P_A\": pipeline.py\n",
      "Step #0 - \"P_A\": requirements.txt\n",
      "Step #0 - \"P_A\": util.py\n",
      "Step #0 - \"P_A\": Removing intermediate container 2ef68c686cfe\n",
      "Step #0 - \"P_A\":  ---> 338b4d906775\n",
      "Step #0 - \"P_A\": Step 9/10 : RUN pwd\n",
      "Step #0 - \"P_A\":  ---> Running in b5a7b6c49f31\n",
      "Step #0 - \"P_A\": /pipeline\n",
      "Step #0 - \"P_A\": Removing intermediate container b5a7b6c49f31\n",
      "Step #0 - \"P_A\":  ---> a6d4c00bfb5a\n",
      "Step #0 - \"P_A\": Step 10/10 : RUN pip list\n",
      "Step #0 - \"P_A\":  ---> Running in 71e52b0fb029\n",
      "Step #0 - \"P_A\": Package                          Version\n",
      "Step #0 - \"P_A\": -------------------------------- -----------\n",
      "Step #0 - \"P_A\": annotated-types                  0.6.0\n",
      "Step #0 - \"P_A\": cachetools                       5.3.3\n",
      "Step #0 - \"P_A\": certifi                          2024.2.2\n",
      "Step #0 - \"P_A\": charset-normalizer               3.3.2\n",
      "Step #0 - \"P_A\": click                            8.1.7\n",
      "Step #0 - \"P_A\": docstring_parser                 0.16\n",
      "Step #0 - \"P_A\": google-api-core                  2.18.0\n",
      "Step #0 - \"P_A\": google-auth                      2.29.0\n",
      "Step #0 - \"P_A\": google-cloud-aiplatform          1.45.0\n",
      "Step #0 - \"P_A\": google-cloud-bigquery            3.20.1\n",
      "Step #0 - \"P_A\": google-cloud-core                2.4.1\n",
      "Step #0 - \"P_A\": google-cloud-pipeline-components 2.11.0\n",
      "Step #0 - \"P_A\": google-cloud-resource-manager    1.12.3\n",
      "Step #0 - \"P_A\": google-cloud-storage             2.16.0\n",
      "Step #0 - \"P_A\": google-crc32c                    1.5.0\n",
      "Step #0 - \"P_A\": google-resumable-media           2.7.0\n",
      "Step #0 - \"P_A\": googleapis-common-protos         1.63.0\n",
      "Step #0 - \"P_A\": grpc-google-iam-v1               0.13.0\n",
      "Step #0 - \"P_A\": grpcio                           1.62.1\n",
      "Step #0 - \"P_A\": grpcio-status                    1.62.1\n",
      "Step #0 - \"P_A\": idna                             3.6\n",
      "Step #0 - \"P_A\": Jinja2                           3.1.3\n",
      "Step #0 - \"P_A\": kfp                              2.7.0\n",
      "Step #0 - \"P_A\": kfp-pipeline-spec                0.3.0\n",
      "Step #0 - \"P_A\": kfp-server-api                   2.0.5\n",
      "Step #0 - \"P_A\": kubernetes                       26.1.0\n",
      "Step #0 - \"P_A\": MarkupSafe                       2.1.5\n",
      "Step #0 - \"P_A\": numpy                            1.26.4\n",
      "Step #0 - \"P_A\": oauthlib                         3.2.2\n",
      "Step #0 - \"P_A\": packaging                        24.0\n",
      "Step #0 - \"P_A\": pip                              23.0.1\n",
      "Step #0 - \"P_A\": proto-plus                       1.23.0\n",
      "Step #0 - \"P_A\": protobuf                         4.25.3\n",
      "Step #0 - \"P_A\": pyarrow                          15.0.2\n",
      "Step #0 - \"P_A\": pyasn1                           0.6.0\n",
      "Step #0 - \"P_A\": pyasn1_modules                   0.4.0\n",
      "Step #0 - \"P_A\": pydantic                         2.6.4\n",
      "Step #0 - \"P_A\": pydantic_core                    2.16.3\n",
      "Step #0 - \"P_A\": python-dateutil                  2.9.0.post0\n",
      "Step #0 - \"P_A\": PyYAML                           6.0.1\n",
      "Step #0 - \"P_A\": requests                         2.31.0\n",
      "Step #0 - \"P_A\": requests-oauthlib                2.0.0\n",
      "Step #0 - \"P_A\": requests-toolbelt                0.10.1\n",
      "Step #0 - \"P_A\": rsa                              4.9\n",
      "Step #0 - \"P_A\": setuptools                       58.1.0\n",
      "Step #0 - \"P_A\": shapely                          2.0.3\n",
      "Step #0 - \"P_A\": six                              1.16.0\n",
      "Step #0 - \"P_A\": tabulate                         0.9.0\n",
      "Step #0 - \"P_A\": typing_extensions                4.10.0\n",
      "Step #0 - \"P_A\": urllib3                          1.26.18\n",
      "Step #0 - \"P_A\": websocket-client                 1.7.0\n",
      "Step #0 - \"P_A\": wheel                            0.43.0\n",
      "Step #0 - \"P_A\": \u001b[91m\n",
      "Step #0 - \"P_A\": [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "Step #0 - \"P_A\": [notice] To update, run: pip install --upgrade pip\n",
      "Step #0 - \"P_A\": \u001b[0mRemoving intermediate container 71e52b0fb029\n",
      "Step #0 - \"P_A\":  ---> 3169d08b94e2\n",
      "Step #0 - \"P_A\": Successfully built 3169d08b94e2\n",
      "Step #0 - \"P_A\": Successfully tagged gcr.io/able-analyst-416817/gemma-chatbot-pipeline-app:masterv6\n",
      "Finished Step #0 - \"P_A\"\n",
      "Starting Step #1 - \"P_B\"\n",
      "Step #1 - \"P_B\": Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #1 - \"P_B\": The push refers to repository [gcr.io/able-analyst-416817/gemma-chatbot-pipeline-app]\n",
      "Step #1 - \"P_B\": 895fc217e4e5: Preparing\n",
      "Step #1 - \"P_B\": a7db4ac51f29: Preparing\n",
      "Step #1 - \"P_B\": b180f08b4340: Preparing\n",
      "Step #1 - \"P_B\": d260146614fd: Preparing\n",
      "Step #1 - \"P_B\": 5eae32ccee60: Preparing\n",
      "Step #1 - \"P_B\": 5d78e4c3c132: Preparing\n",
      "Step #1 - \"P_B\": 9138b29cde77: Preparing\n",
      "Step #1 - \"P_B\": 4c8474755d1b: Preparing\n",
      "Step #1 - \"P_B\": c8f253aef560: Preparing\n",
      "Step #1 - \"P_B\": a483da8ab3e9: Preparing\n",
      "Step #1 - \"P_B\": 5d78e4c3c132: Waiting\n",
      "Step #1 - \"P_B\": 9138b29cde77: Waiting\n",
      "Step #1 - \"P_B\": 4c8474755d1b: Waiting\n",
      "Step #1 - \"P_B\": c8f253aef560: Waiting\n",
      "Step #1 - \"P_B\": a483da8ab3e9: Waiting\n",
      "Step #1 - \"P_B\": 895fc217e4e5: Pushed\n",
      "Step #1 - \"P_B\": 5eae32ccee60: Pushed\n",
      "Step #1 - \"P_B\": 9138b29cde77: Layer already exists\n",
      "Step #1 - \"P_B\": 5d78e4c3c132: Layer already exists\n",
      "Step #1 - \"P_B\": 4c8474755d1b: Layer already exists\n",
      "Step #1 - \"P_B\": c8f253aef560: Layer already exists\n",
      "Step #1 - \"P_B\": a7db4ac51f29: Pushed\n",
      "Step #1 - \"P_B\": a483da8ab3e9: Layer already exists\n",
      "Step #1 - \"P_B\": d260146614fd: Pushed\n",
      "Step #1 - \"P_B\": b180f08b4340: Pushed\n",
      "Step #1 - \"P_B\": masterv6: digest: sha256:3133414437e49277fc5a94706774c1ce40b77b30f2e7863d2a4a3dfcb3ec2475 size: 2415\n",
      "Finished Step #1 - \"P_B\"\n",
      "Starting Step #2\n",
      "Step #2: Already have image (with digest): gcr.io/able-analyst-416817/gemma-chatbot-pipeline-app:masterv6\n",
      "Step #2: ./gemma_2b_en\n",
      "Step #2: This is the dictionary {'model_size': '2b', 'bucket_name': 'able-analyst-416817-chatbot-v1', 'finetuned_model_dir': './gemma_2b_en', 'finetuned_weights_path': './gemma_2b_en/model.weights.h5', 'finetuned_vocab_path': './gemma_2b_en/vocabulary.spm', 'huggingface_model_dir': './gemma_2b_en_huggingface', 'deployed_model_blob': 'andrehpereh1/20240402163440/gemma_2b_en/huggingface', 'deployed_model_uri': 'gs://able-analyst-416817-chatbot-v1/andrehpereh1/20240402163440/gemma_2b_en/huggingface', 'fine_tuned_keras_blob': 'andrehpereh1/20240402163440/gemma_2b_en/keras', 'model_name_vllm': 'gemma_2b_en-vllm', 'machine_type': 'g2-standard-8', 'accelerator_type': 'NVIDIA_L4', 'accelerator_count': 1, 'memory': '40G', 'cpu': '12.0'}\n",
      "Step #2: This is the project {{channel:task=;name=project;type=String;}}\n",
      "Step #2: This is the model name gemma_2b_en Ahuevito\n",
      "Step #2: This is the directory input_data/andrehpereh Ahuevito\n",
      "Step #2: This is the BUCKET_NAME able-analyst-416817-chatbot-v1 Ahuevito\n",
      "Step #2: This is the FINE_TUNE_FLAG False Ahuevito\n",
      "Step #2: This is the EPOCHS 12 Ahuevito\n",
      "Step #2: Creating PipelineJob\n",
      "Step #2: PipelineJob created. Resource name: projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240402163442\n",
      "Step #2: To use this PipelineJob in another session:\n",
      "Step #2: pipeline_job = aiplatform.PipelineJob.get('projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240402163442')\n",
      "Step #2: View Pipeline Job:\n",
      "Step #2: https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/model-deployment-20240402163442?project=24796876098\n",
      "Step #2: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240402163442 current state:\n",
      "Step #2: PipelineState.PIPELINE_STATE_RUNNING\n",
      "Step #2: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240402163442 current state:\n",
      "Step #2: PipelineState.PIPELINE_STATE_RUNNING\n",
      "Step #2: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240402163442 current state:\n",
      "Step #2: PipelineState.PIPELINE_STATE_CANCELLING\n",
      "Step #2: PipelineJob run completed. Resource name: projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240402163442\n",
      "Finished Step #2\n",
      "PUSH\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                             IMAGES  STATUS\n",
      "b55fd38c-159e-41ab-b1f8-4e20ec798cb5  2024-04-02T16:33:16+00:00  2M47S     gs://able-analyst-416817_cloudbuild/source/1712075595.902513-c03f0b1a20b34da2ab5574f2289c232b.tgz  -       SUCCESS\n"
     ]
    }
   ],
   "source": [
    "res = !gcloud config get core/project\n",
    "PROJECT_ID = res[0]\n",
    "SERVICE_ACCOUNT = 'gemma-vertexai-chatbot@able-analyst-416817.iam.gserviceaccount.com'\n",
    "from datetime import datetime\n",
    "CONTAINER_IMAGE_NAME=\"gemma-chatbot\"\n",
    "GCP_REGION='us-central1'\n",
    "TAG_NAME = 'masterv6'\n",
    "KAGGLE_USERNAME='andrehpereh1'\n",
    "KAGGLE_KEY='5859e39806d9456749dcbac685f04bc9'\n",
    "CONTAINER_IMAGE_NAME_DATA_PREP = f\"{CONTAINER_IMAGE_NAME}-data-preparation\"\n",
    "CONTAINER_IMAGE_NAME_FINE_TUNE = f\"{CONTAINER_IMAGE_NAME}-fine-tunning\"\n",
    "CONTAINER_IMAGE_NAME_RUN_APP = f\"{CONTAINER_IMAGE_NAME}-running-app\"\n",
    "CONTAINER_IMAGE_NAME_PIPELINE = f\"{CONTAINER_IMAGE_NAME}-pipeline-app\"\n",
    "CONTAINER_IMAGE_RUNNING_APP = f\"{CONTAINER_IMAGE_NAME}-running-app\"\n",
    "BUCKET_NAME = 'able-analyst-416817-chatbot-v1'\n",
    "# BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "FINE_TUNE_FLAG=  False\n",
    "EPOCHS=12\n",
    "MODEL_NAME=\"gemma_2b_en\"\n",
    "\n",
    "substitutions=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME_PIPELINE={},\\\n",
    "TAG_NAME={},\\\n",
    "_BUCKET_NAME={},\\\n",
    "_FINE_TUNE_FLAG={},\\\n",
    "_EPOCHS={},\\\n",
    "_MODEL_NAME={}\n",
    "\"\"\".format(\n",
    "           CONTAINER_IMAGE_NAME_PIPELINE,\n",
    "           TAG_NAME,\n",
    "           BUCKET_NAME,\n",
    "           FINE_TUNE_FLAG,\n",
    "           EPOCHS,\n",
    "           MODEL_NAME\n",
    "           ).strip()\n",
    "print(substitutions)\n",
    "!gcloud builds submit . --config \"components/pipeline/cloudbuild.yaml\" --substitutions {substitutions} --region={GCP_REGION}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f946012-e7f1-4438-ad6e-d662efe3f040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b11ab-4f76-406e-87a8-5a7970c5fec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CONTAINER_IMAGE_NAME=\"gemma-chatbot\"\n",
    "GCP_REGION = 'us-central1'\n",
    "TAG_NAME = 'masterv4'\n",
    "\n",
    "CONTAINER_IMAGE_NAME_PIPELINE = f\"{CONTAINER_IMAGE_NAME}-pipeline-app\"\n",
    "CONTAINER_IMAGE_RUNNING_APP = f\"{CONTAINER_IMAGE_NAME}-running-app\"\n",
    "\n",
    "#,_CONTAINER_IMAGE_RUNNING_APP={CONTAINER_IMAGE_RUNNING_APP}\n",
    "substitutions=f\"_CONTAINER_IMAGE_NAME_PIPELINE={CONTAINER_IMAGE_NAME_PIPELINE},TAG_NAME={TAG_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f135a2-2060-418d-b9aa-98d86181abac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud builds submit . --config \"./cloudbuil_cloudrun.yaml\" --substitutions {substitutions} --region=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8ed60-33ed-4ea9-888b-e62721c8728c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!gcloud functions deploy hello_world_trigger \\\n",
    "--gen2 \\\n",
    "--region='us-central1' \\\n",
    "--runtime=python39 \\\n",
    "--source='./components/cloud_functions/' \\\n",
    "--entry-point='trigger_pipeline_cloud_function' \\\n",
    "--trigger-topic='your-pipeline-trigger-topic' \\\n",
    "--memory='2048MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b43c6-efab-4e39-b7a2-0cb7367badce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "kfp.__version__\n",
    "dir(kfp.dsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a7bfb-2182-44f1-a764-67e428f92352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from components.cloud_functions.main import trigger_pipeline_cloud_function\n",
    "import json\n",
    "\n",
    "data = {\n",
    "    \"user_name\": \"andrehpereh\",\n",
    "    \"files\": [\n",
    "        {\"file_path\": \"gs://personalize-chatbots-v1/andrehpereh/input_data/WhatsApp Chat with Anki.txt\", \"filename\": \"WhatsApp Chat with Anki.txt\"},\n",
    "        {\"file_path\": \"gs://personalize-chatbots-v1/andrehpereh/input_data/WhatsApp Chat with Ilse Flatmate.txt\", \"filename\": \"WhatsApp Chat with Ilse Flatmate.txt\"},\n",
    "        {\"file_path\": \"gs://personalize-chatbots-v1/andrehpereh/input_data/WhatsApp Chat with Michael.txt\", \"filename\": \"WhatsApp Chat with Michael.txt\"}\n",
    "    ],\n",
    "    \"blob_folder\": \"andrehpereh/input_data\",\n",
    "    \"model_name\": \"gemma_2b_en\",\n",
    "    \"epochs\": \"12\",\n",
    "    \"bucket_name\": \"personalize-chatbots-v1\",\n",
    "    \"project_id\": \"able-analyst-416817\"\n",
    "}\n",
    "\n",
    "# Convert dictionary to JSON string\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "# Encode JSON string to bytes\n",
    "data_bytes = json_data.encode('utf-8')\n",
    "\n",
    "# Pass the encoded bytes to the function\n",
    "trigger_pipeline_cloud_function()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da46322-3139-4427-b552-1f444750a378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"andrehpereh1\"\n",
    "os.environ['KAGGLE_KEY'] = \"5859e39806d9456749dcbac685f04bc9\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508aa69-1810-4fc2-9a3d-735e55e4ccf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import util\n",
    "importlib.reload(util)\n",
    "model_paths_and_config = util.get_model_paths_and_config(Config.MODEL_NAME)\n",
    "model_paths_and_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69027026-fb4f-4de3-9e5c-84f7ec881d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Config.TRAIN_DATA_DIR, Config.BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b737395-4d42-4a7e-becf-9fbc07a2580d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = process_whatsapp_chat(Config.BUCKET_NAME, Config.TRAIN_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc1897-d11a-4e8c-852c-af78ad7656cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04ebef-6bad-4c2d-aced-34083491afce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_paths_and_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67913c94-353d-43f3-8026-827aafdbbdbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetuned_weights_path = finetune_gemma(data=data[:50], model_paths=model_paths_and_config, fine_tune_flag=False, model_name=Config.MODEL_NAME, rank_lora=Config.SEQUENCE_LENGTH, sequence_length=Config.SEQUENCE_LENGTH, epochs=Config.EPOCHS, batch_size=Config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d2d38-4f7b-4eca-bf72-31027d060ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "cuda.select_device(device.id)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d8ec4-0a5c-4718-a599-34b74305715c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(finetuned_weights_path)\n",
    "print(model_paths_and_config['finetuned_weights_path'])\n",
    "print(model_paths_and_config['finetuned_model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d15a7-6344-4faf-8a22-69f203a74676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://able-analyst-416817-chatbot-v1/gemma_2b_en_raw/gemma_2b_en/model.weights.h5 ./test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca7dfb-6fde-4a9f-b879-9be138a35564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetuned_weights_path.save_weights(\"gs://able-analyst-416817-chatbot-v1/gemma_2b_en_raw/gemma_2b_en/test/model.weights.h5\")\n",
    "finetuned_weights_path.preprocessor.tokenizer.save_assets(\"gs://able-analyst-416817-chatbot-v1/gemma_2b_en_raw/gemma_2b_en/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c2ed7-d7fc-4c1b-a73f-e44940701a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = convert_checkpoints(\n",
    "    weights_file=model_paths_and_config['finetuned_weights_path'],\n",
    "    size=model_paths_and_config['model_size'],\n",
    "    output_dir=model_paths_and_config['huggingface_model_dir'],\n",
    "    vocab_path=model_paths_and_config['finetuned_vocab_path'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202aae46-9fdc-40f6-9d3e-d4f7cb50278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=model_paths_and_config['huggingface_model_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221ec4a-8da6-463b-943d-c4d66b9615df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_paths_and_config, Config.BUCKET_NAME\n",
    "bucket_name, blob_name = os.path.dirname(\"gs://able-analyst-416817-chatbot-v1/gemma_2b_en_raw/gemma_2b_en/model.weights.h5\").lstrip(\"gs://\").split(\"/\", 1) \n",
    "bucket_name, blob_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b7e0c-e4bd-4ed8-95a8-16eac527e81d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.path.basename(\"gs://able-analyst-416817-chatbot-v1/gemma_2b_en_raw/gemma_2b_en/model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad8c09-c59c-4424-8165-24e5716740e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = upload2bs(local_directory = output_dir, bucket_name = Config.BUCKET_NAME, destination_subfolder = model_paths_and_config['deployed_model_blob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac8551-f497-4b79-b6bd-41b5034c3011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import util\n",
    "importlib.reload(util)\n",
    "\n",
    "util.download_all_from_blob(Config.BUCKET_NAME, \"gemma_2b_en_raw/gemma_2b_en\", './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16877b-31ae-44c2-8b07-d90e5ad9e849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Config.BUCKET_NAME\n",
    "model_paths_and_config['huggingface_model_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9a6a6-9cf8-4fb4-a9e2-69f867cc31c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_paths_and_config['deployed_model_blob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea5a28-8c3c-44d7-87aa-1952de6c3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=Config.PROJECT_ID, location=Config.REGION, staging_bucket=Config.BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b32639-f0ac-459a-924b-db590770a837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "VLLM_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240220_0936_RC01\"\n",
    "\n",
    "\n",
    "def get_job_name_with_datetime(prefix: str) -> str:\n",
    "    suffix = datetime.datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "    return f\"{prefix}{suffix}\"\n",
    "\n",
    "\n",
    "def deploy_model_vllm(\n",
    "    model_name: str,\n",
    "    model_uri: str,\n",
    "    service_account: str,\n",
    "    machine_type: str = \"g2-standard-8\",\n",
    "    accelerator_type: str = \"NVIDIA_L4\",\n",
    "    accelerator_count: int = 1,\n",
    "    max_model_len: int = 8192,\n",
    "    dtype: str = \"bfloat16\",\n",
    ") -> tuple[aiplatform.Model, aiplatform.Endpoint]:\n",
    "    # Upload the model to \"Model Registry\"\n",
    "    job_name = get_job_name_with_datetime(model_name)\n",
    "    vllm_args = [\n",
    "        \"--host=0.0.0.0\",\n",
    "        \"--port=7080\",\n",
    "        f\"--tensor-parallel-size={accelerator_count}\",\n",
    "        \"--swap-space=16\",\n",
    "        \"--gpu-memory-utilization=0.95\",\n",
    "        f\"--max-model-len={max_model_len}\",\n",
    "        f\"--dtype={dtype}\",\n",
    "        \"--disable-log-stats\",\n",
    "    ]\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=job_name,\n",
    "        artifact_uri=model_uri,\n",
    "        serving_container_image_uri=VLLM_DOCKER_URI,\n",
    "        serving_container_command=[\"python\", \"-m\", \"vllm.entrypoints.api_server\"],\n",
    "        serving_container_args=vllm_args,\n",
    "        serving_container_ports=[7080],\n",
    "        serving_container_predict_route=\"/generate\",\n",
    "        serving_container_health_route=\"/ping\",\n",
    "    )\n",
    "\n",
    "    # Deploy the model to an endpoint to serve \"Online predictions\"\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-endpoint\")\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        deploy_request_timeout=1800,\n",
    "        service_account=service_account,\n",
    "    )\n",
    "\n",
    "    return model, endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07dfde0-7192-48af-9730-d3b692cf878a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up artificially since the model was already in a bucket\n",
    "model_paths_and_config['deployed_model_uri'] = 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240314162107'\n",
    "model_paths_and_config['model_name_vllm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251fc433-3657-434e-a64c-6b351bf143ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_model_len = 2048\n",
    "\n",
    "model, endpoint = deploy_model_vllm(\n",
    "    model_name=model_paths_and_config['model_name_vllm'],\n",
    "    model_uri=model_paths_and_config['deployed_model_uri'],\n",
    "    service_account=Config.SERVICE_ACCOUNT,\n",
    "    machine_type=model_paths_and_config['machine_type'],\n",
    "    accelerator_type=model_paths_and_config['accelerator_type'],\n",
    "    accelerator_count=model_paths_and_config['accelerator_count'],\n",
    "    max_model_len=max_model_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc40ff-d622-423b-8c43-f066e93907e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88520f0-174a-4cb7-97c4-41a1fbcaca81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2a926-dac3-4dfd-a184-515685b4b657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f329e-9925-42fe-8362-3ca5c97f1cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_EXAMPLES = [\n",
    "    \"What is the plan for tonight?\",\n",
    "    \"What would you like to drink?\",\n",
    "    \"Are you coming tonight?\"\n",
    "]\n",
    "\n",
    "# Prompt template for the training data and the finetuning tests\n",
    "PROMPT_TEMPLATE = \"Sender:\\n{instruction}\\n\\nAndres Perez:\\n{response}\"\n",
    "\n",
    "TEST_PROMPTS = [\n",
    "    PROMPT_TEMPLATE.format(instruction=example, response=\"\")\n",
    "    for example in TEST_EXAMPLES\n",
    "]\n",
    "\n",
    "def test_vertexai_endpoint(endpoint: aiplatform.Endpoint):\n",
    "    for question, prompt in zip(TEST_EXAMPLES, TEST_PROMPTS):\n",
    "        instance = {\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 56,\n",
    "            \"temperature\": 0.0,\n",
    "            \"top_p\": 1.0,\n",
    "            \"top_k\": 1,\n",
    "            \"raw_response\": True,\n",
    "        }\n",
    "        response = endpoint.predict(instances=[instance])\n",
    "        output = response.predictions[0]\n",
    "        print(f\"{question}\\n{output}\\n{'- '*40}\")\n",
    "\n",
    "\n",
    "test_vertexai_endpoint(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518bd694-aa5b-45f4-934a-894c33b2bf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = !gcloud config get core/project\n",
    "PROJECT_ID = res[0]\n",
    "SERVICE_ACCOUNT = 'gemma-vertexai-chatbot@able-analyst-416817.iam.gserviceaccount.com'\n",
    "from datetime import datetime\n",
    "CONTAINER_IMAGE_NAME=\"gemma-chatbot\"\n",
    "GCP_REGION='us-central1'\n",
    "IMAGE_NAME=\"gemma-chatbot\"\n",
    "TAG_NAME = 'latest'\n",
    "KAGGLE_USERNAME='andrehpereh1'\n",
    "KAGGLE_KEY='5859e39806d9456749dcbac685f04bc9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d98f42-6a85-4324-81a7-dd1c6b5bab4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CONTAINER_IMAGE_NAME=gemma-chatbot-data-preparation,TAG_NAME=masterv6\n"
     ]
    }
   ],
   "source": [
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-data-preparation\",\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd38dea-1f7f-486d-bf3e-1b3a1f69582c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 136 file(s) totalling 833.7 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://able-analyst-416817_cloudbuild/source/1712073585.685055-7509ca3bce1c47e2b6d07e60aee98439.tgz]\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.builds.submit) INVALID_ARGUMENT: generic::invalid_argument: key in the template \"_CONTAINER_IMAGE_NAME_DATA_PREP\" is not matched in the substitution data; substitutions = map[TAG_NAME:masterv6 _CONTAINER_IMAGE_NAME:gemma-chatbot-data-preparation];key in the template \"_CONTAINER_IMAGE_NAME_DATA_PREP\" is not matched in the substitution data; substitutions = map[TAG_NAME:masterv6 _CONTAINER_IMAGE_NAME:gemma-chatbot-data-preparation];key \"_CONTAINER_IMAGE_NAME\" in the substitution data is not matched in the template\n"
     ]
    }
   ],
   "source": [
    "# Runs the data_preparation component image. (Development, when tested should be moved to the main cloudbuild in the project folder)\n",
    "# Pay attention to the \".\" after summit. Might need some changes when move to the master pipeline.\n",
    "!gcloud builds submit . --timeout=15m --config \"components/data_preparation/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n",
    "# DO not forget the tag\n",
    "#!docker run gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest data_ingestion.py --bucket-name 'able-analyst-416817-chatbot-v1' --directory 'input_data/andrehpereh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d0f14-b406-4a5a-bc6b-fa4e8da5cc62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9250f9bf-5bf0-4bd2-8f5f-3f10daf9dc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "_KAGGLE_USERNAME={},\\\n",
    "_KAGGLE_KEY={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-fine-tunning\",\n",
    "           KAGGLE_USERNAME,\n",
    "           KAGGLE_KEY,\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n",
    "\n",
    "# Builds image\n",
    "!gcloud builds submit . --config \"components/fine_tunning/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef60c94-45b0-4cf2-a7d1-cf96b3f6ad6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452fcec-bd44-4ab8-801b-e6f804b5a432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961b567-3239-4c10-915f-67fd98515c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = [\"Sender: FoooodddAndres Perez: Coming :)\", \"Sender: Can I maybe borrow your iron? Andres Perez: It\\'s not my iron But yeah haha Or is it?\"]\n",
    "model_paths = \"\"\"{\"finetuned_model_dir\": \"./gemma_2b_en\", \"finetuned_weights_path\": \"./gemma_2b_en/model.weights.h5\"}\"\"\"\n",
    "print(len(data))\n",
    "model_paths = json.dumps(model_paths)\n",
    "#!docker run gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest trainer.py --data {data} --model-paths {model_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090fa27a-121a-4954-8ddc-973415226bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ./components/fine_tunning/trainer.py --data {data} --model-paths {model_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2aa69-a793-4a4f-b8e4-92731c92b6ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_paths_and_config['huggingface_model_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d84c44-c65c-4ae1-9a4c-6d293f139495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ./components/fine_tunning/conversion_function.py --weights-file {model_paths_and_config['finetuned_weights_path']} --size {model_paths_and_config['model_size']} --vocab-path {model_paths_and_config['finetuned_vocab_path']} --output-dir {model_paths_and_config['huggingface_model_dir']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6c134-bd9a-4fda-8e29-31ef6c8aea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = convert_checkpoints(\n",
    "    weights_file=model_paths_and_config['finetuned_weights_path'],\n",
    "    size=model_paths_and_config['model_size'],\n",
    "    output_dir=model_paths_and_config['huggingface_model_dir'],\n",
    "    vocab_path=model_paths_and_config['finetuned_vocab_path'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6404c6c-d998-4253-bbf3-3f83b29abe94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-experimental\",\n",
    "           TAG_NAME,\n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n",
    "data = '\"[\\\\\"Sender: FoooodddAndres Perez: Coming :)\\\\\", \\\\\"Sender: Can I maybe borrow your iron? Andres Perez: It\\'s not my iron But yeah haha Or is it?\\\\\"]\"'\n",
    "model_paths = \"\"\"{\"finetuned_model_dir\": \"./gemma_2b_en\", \"finetuned_weights_path\": \"./gemma_2b_en/model.weights.h5\"}\"\"\"\n",
    "data_json = json.dumps(data)\n",
    "model_paths_json = json.dumps(model_paths)\n",
    "#!gcloud builds submit . --timeout=15m --config \"components/experimental/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n",
    "!docker run gcr.io/able-analyst-416817/gemma-chatbot-experimental:latest experimental.py {data_json} {model_paths_json}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6c518-79e1-4ec6-a832-39ae6f364ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Re-runs the image to restart the website, service account might be needed with this one.  (Development, when tested should be moved to the main cloudbuild in the project folder)\n",
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "_GCP_REGION={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-running-app\",\n",
    "           GCP_REGION,\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n",
    "!gcloud builds submit . --timeout=15m --config \"components/app_flask/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n",
    "#!gcloud builds submit . --timeout=15m --config \"cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1cae7-c300-4cd1-aa97-c7fef2efaa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05aa3f-9a40-41db-8553-b65d7dee4352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SUBSTITUTIONS=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME={},\\\n",
    "_GCP_REGION={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           f\"{CONTAINER_IMAGE_NAME}-running-app\",\n",
    "           GCP_REGION,\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(SUBSTITUTIONS)\n",
    "!gcloud builds submit . --timeout=15m --config \"components/app_flask/cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}\n",
    "#!gcloud builds submit . --timeout=15m --config \"cloudbuild.yaml\" --substitutions {SUBSTITUTIONS} --region={GCP_REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb10f3c-b135-470b-a74b-0c825e0f0761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa1979-e2f1-41ce-a3f4-bab8465866e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b974a3-cab2-425e-bfc5-dcb01d45b5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config import Config\n",
    "from util import get_model_paths_and_config, upload2bs\n",
    "\n",
    "res = !gcloud config get core/project\n",
    "PROJECT_ID = res[0]\n",
    "from google.cloud import compute_v1\n",
    "\n",
    "project = PROJECT_ID  # Replace with your project ID\n",
    "\n",
    "# Regions to consider\n",
    "regions = [\"us-central1\", \"europe-west4\", \"asia-east1\"]  \n",
    "\n",
    "client = compute_v1.AcceleratorTypesClient()\n",
    "\n",
    "for region in regions:\n",
    "    zone_client = compute_v1.ZonesClient()\n",
    "    all_zones = zone_client.list(project=project)\n",
    "\n",
    "    zone_list = [zone for zone in all_zones if zone.region == f\"regions/{region}\"]\n",
    "\n",
    "    for zone in zone_list:\n",
    "        result = client.describe(\n",
    "            project=project, zone=zone.name, accelerator_type=\"nvidia-l4\"\n",
    "        )\n",
    "        # If the result isn't an error, the 'nvidia-l4' type is available\n",
    "        GCP_REGION = region  # Update your region variable\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11402c19-d1b8-4b8c-a959-932ca09fcf18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7ac36-bc0e-4e00-928f-1c7247b9685e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09398956-e97e-411b-a1fe-9e05ff61e6d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bq mk chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a52d27-b74b-4211-b650-7f16444fe8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "# Construct a BigQuery client object\n",
    "os.environ['PROJECT_ID'] = 'able-analyst-416817'\n",
    "client = bigquery.Client(os.environ.get('PROJECT_ID'))\n",
    "\n",
    "# Define your dataset and table information\n",
    "project_id = os.environ.get('PROJECT_ID')\n",
    "project = os.environ.get('PROJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dafdfdea-c57b-4a26-ac5f-2775ff291bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table able-analyst-416817.chatbot.users\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_id = \"chatbot\"\n",
    "table_id = \"users\" \n",
    "\n",
    "# Schema definition\n",
    "schema = [\n",
    "    # bigquery.SchemaField(\"user_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"email\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"password_hash\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"created_at\", \"TIMESTAMP\", description=\"Record creation timestamp\")  \n",
    "    #bigquery.SchemaField(\"salt\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    #bigquery.SchemaField(\"created_at\", \"TIMESTAMP\", mode=\"REQUIRED\"),\n",
    "    #bigquery.SchemaField(\"last_login\", \"TIMESTAMP\", mode=\"NULLABLE\") \n",
    "]\n",
    "\n",
    "# Create a table object\n",
    "table = bigquery.Table(project_id + \".\" + dataset_id + \".\" + table_id, schema=schema)\n",
    "\n",
    "# Create the table in BigQuery\n",
    "table = client.create_table(table)  \n",
    "print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b41c1b33-ba5a-4b0f-aef8-c7a872f1a6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_id = \"chatbot\"\n",
    "table_id = \"user_training_status\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fed69c43-8407-460b-bd2d-1ac0ed39a610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table able-analyst-416817.chatbot.user_training_status\n"
     ]
    }
   ],
   "source": [
    "# Schema definition\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"email\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"training_status\", \"BOOL\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"end_point\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"created_at\", \"TIMESTAMP\", description=\"Record creation timestamp\")  \n",
    "]\n",
    "\n",
    "# Create a table object\n",
    "table = bigquery.Table(project_id + \".\" + dataset_id + \".\" + table_id, schema=schema)\n",
    "\n",
    "# Create the table in BigQuery\n",
    "table = client.create_table(table)  \n",
    "print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319dab7-7bf8-4346-9d43-952f158d9fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_id = \"chatbot\"\n",
    "table_id = \"users_endpoints\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af8d90-a372-40a9-a08b-5284ad58321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\n",
    "    bigquery.SchemaField(\"email\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"training_status\", \"BOOL\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"end_point\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"created_at\", \"TIMESTAMP\", description=\"Record creation timestamp\")  \n",
    "]\n",
    "\n",
    "# Create a table object\n",
    "table = bigquery.Table(project_id + \".\" + dataset_id + \".\" + table_id, schema=schema)\n",
    "\n",
    "# Create the table in BigQuery\n",
    "table = client.create_table(table)  \n",
    "print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc4f405-127a-44db-8937-76a56866689a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b4e23-227e-40bb-9158-b4b5b5951a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "#This part can be wrapped in a function.\n",
    "query = f\"\"\"\n",
    "UPDATE `{os.environ.get('PROJECT_ID')}.{DATASET_ID}.{USER_TRAINING_STATUS}`\n",
    "SET end_point = '{endpoint_resource}'  \n",
    "WHERE email = '{email}' \n",
    "\"\"\"\n",
    "# Create a query job configuration\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "\n",
    "# Execute the update query\n",
    "query_job = client.query(query, job_config=job_config)\n",
    "query_job.result() \n",
    "\n",
    "print(\"End point has been stored.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9bed4-ff5d-4bc7-b8bf-dde6ec82ac09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0cca0-72a6-42d8-b738-328e0add6fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe300209-7695-45e5-8f3e-79f49969d4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eaf461-bbfa-467b-86e4-88e62caea3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "DATASET_ID = 'chatbot' # This should be moved to a config file\n",
    "USER_TRAINING_STATUS = 'user_training_status' # This should be moved to a config file\n",
    "#This part can be wrapped in a function\n",
    "email = 'andreshperesh@gmail.com'\n",
    "\n",
    "resource_uri = \"https://us-central1-aiplatform.googleapis.com/v1/projects/24796876098/locations/us-central1/endpoints/2572265671740096512/operations/6634221199406661632\"\n",
    "\n",
    "print(\"This is the passed end pooint\", resource_uri)\n",
    "\n",
    "print(\"This is the project\", project)\n",
    "\n",
    "client = bigquery.Client(project)\n",
    "print(\"This is the client\", client)\n",
    "table_ref = client.dataset(DATASET_ID).table(USER_TRAINING_STATUS)\n",
    "table = client.get_table(table_ref)\n",
    "row_to_insert = {\n",
    "    'email': email,\n",
    "    'end_point': resource_uri,\n",
    "    'training_status': True\n",
    "}\n",
    "client.insert_rows(table, [row_to_insert]) \n",
    "errors = client.insert_rows(table, [row_to_insert])\n",
    "if errors:  # Check if there were errors\n",
    "    print(\"The model has been trained, but error updating resource_uri for {}: {}\".format(email, errors))\n",
    "else:\n",
    "    print(\"User training has been updated\")\n",
    "print(\"End point has been stored.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee126b2-b9c1-4c46-93e1-4e92a861ce05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_info(url):\n",
    "    \"\"\"Extracts location, endpoint, and project information from a given AIPlatform URL.\n",
    "\n",
    "    Args:\n",
    "        url: The AIPlatform URL string.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the extracted values:\n",
    "            locations: The region.\n",
    "            endpoints: The endpoint ID.\n",
    "            projects: The project ID.\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = r\"\\/projects\\/([^\\/]+)\\/locations\\/([^\\/]+)\\/endpoints\\/([^\\/]+)\\/operations\\/([^\\/]+)\"\n",
    "    print(pattern)\n",
    "    match = re.search(pattern, url)\n",
    "    print(match)\n",
    "    if match:\n",
    "        return {\n",
    "            \"projects\": match.group(1),\n",
    "            \"locations\": match.group(2),\n",
    "            \"endpoints\": match.group(3)\n",
    "        }\n",
    "    else:\n",
    "        return None  # Or you could raise an exception if the URL is invalid\n",
    "\n",
    "# Example usage\n",
    "url = \"https://us-central1-aiplatform.googleapis.com/v1/projects/24796876098/locations/us-central1/endpoints/2572265671740096512/operations/6634221199406661632\"\n",
    "\n",
    "result = extract_info(url)\n",
    "if result:\n",
    "    print(result) \n",
    "else:\n",
    "    print(\"Invalid URL format\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf6c94-56d4-4e74-8364-00e2af0a26a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "string = \"https://us-central1-aiplatform.googleapis.com/v1/projects/24796876098/locations/us-central1/endpoints/2572265671740096512/operations/6634221199406661632\"\n",
    "\n",
    "pattern = r\"\\/projects\\/([^\\/]+)\\/locations\\/([^\\/]+)\\/endpoints\\/([^\\/]+)\\/operations\\/([^\\/]+)\"\n",
    "\n",
    "match = re.search(pattern, string)\n",
    "\n",
    "if match:\n",
    "    project_id = match.group(1)\n",
    "    location = match.group(2)\n",
    "    endpoint_id = match.group(3)\n",
    "    operation_id = match.group(4)\n",
    "\n",
    "    print(\"Project ID:\", project_id)\n",
    "    print(\"Location:\", location)\n",
    "    print(\"Endpoint ID:\", endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9eac52-5aa7-4fd9-8e16-a22323f5a2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('Wednesday at 12-33 AM.txt', 'r') as file:\n",
    "    contents = file.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da5fe5-1df8-4391-ba2c-f97b97b8cf1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ad00a-7aaf-4cb0-ad67-2bc700e1bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, ChatSession\n",
    "\n",
    "project_id = project_id\n",
    "location = \"us-central1\"\n",
    "vertexai.init(project=project_id, location=location)\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "chat = model.start_chat()\n",
    "\n",
    "def get_chat_response(chat: ChatSession, prompt: str) -> str:\n",
    "    text_response = []\n",
    "    responses = chat.send_message(prompt, stream=True)\n",
    "    for chunk in responses:\n",
    "        text_response.append(chunk.text)\n",
    "    return \"\".join(text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575c169-6b59-4256-b8de-4f51495dc5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c625f7a-95bb-4a0a-853e-ea3ef112482d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161b349-98e9-440a-95d0-9270c51add6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cf636-2c2a-4eb7-90ea-5f5f3684ead3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e265a5a-e531-4147-84b9-70c90210d0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pairs[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578fa6b-007b-4ba9-af66-b3ab9504469e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(res[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33e0bc-7044-4e8f-9517-df1e6ea2f506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53848f48-6d80-4935-bab2-2977757df7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318720a-a792-47c6-b23c-557866cf7d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b3e1f-5148-4bd7-9c80-950cf6991a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908ec1d-29eb-41fb-8b5e-48804e8b26d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e4e63-f4cb-4283-9d94-844d1d2efbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from components.data_preparation import data_ingestion\n",
    "res = data_ingestion.process_whatsapp_chat(bucket_name = 'personalize-chatbots-v1', directory = 'andrehpereh/input_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6f40d-7021-43e9-bbea-73ee1fa8d1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15c36ab-4718-4100-9bdc-eaaa7b65c664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket Name personalize-chatbots-v1\n",
      "Directory andrehpereh/input_data/\n",
      "personalize-chatbots-v1\n",
      "andrehpereh/input_data/\n",
      "<google.api_core.page_iterator.HTTPIterator object at 0x7f6414107a00>\n",
      "andrehpereh/input_data/13 march_transcript.txt\n",
      "andrehpereh/input_data/17 march_transcript.txt\n",
      "andrehpereh/input_data/21 march_transcript.txt\n",
      "andrehpereh/input_data/5 march 2024_transcript.txt\n",
      "andrehpereh/input_data/Barcelona_transcript.txt\n",
      "andrehpereh/input_data/Childhood_transcript.txt\n",
      "andrehpereh/input_data/Class - Sunday at 11-43 PM_transcript.txt\n",
      "andrehpereh/input_data/Introduction 2_transcript.txt\n",
      "andrehpereh/input_data/March 10_transcript.txt\n",
      "andrehpereh/input_data/March 22 2024_transcript.txt\n",
      "andrehpereh/input_data/March 4, 2024_transcript.txt\n",
      "andrehpereh/input_data/March 6 Wednesday_transcript.txt\n",
      "andrehpereh/input_data/Monday at 11-33 PM_transcript.txt\n",
      "andrehpereh/input_data/Overall description start_transcript.txt\n",
      "andrehpereh/input_data/Small comment_transcript.txt\n",
      "andrehpereh/input_data/Wednesday at 12-33 AM.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Anki.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Ilse Flatmate.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Michael.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Mike Haarlem.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Rosa Rosa Rosa.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Ruben Ewald Puijker.txt\n",
      "andrehpereh/input_data/childhood. Where did you grow up-_transcript.txt\n"
     ]
    }
   ],
   "source": [
    "from components.data_preparation import data_ingestion\n",
    "res_whats = data_ingestion.process_whatsapp_chat(bucket_name = 'personalize-chatbots-v1', directory = 'andrehpereh/input_data/', pair_count=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9dce9eb-38a0-43c6-8e9c-3f7215fc3262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "gemini_pro_model = GenerativeModel(\"gemini-1.0-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a975c8c6-c45e-45ea-8182-154365c00330",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertexai.preview.generative_models.GenerativeModel"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gemini_pro_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6721de39-1933-4f24-9ccd-563644559125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.46.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vertexai import generative_models \n",
    "import vertexai\n",
    "vertexai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fcf3411-a4c4-498a-83fb-267662f2288e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "# Construct a BigQuery client object\n",
    "os.environ['PROJECT_ID'] = 'able-analyst-416817'\n",
    "client = bigquery.Client(os.environ.get('PROJECT_ID'))\n",
    "\n",
    "# Define your dataset and table information\n",
    "project_id = os.environ.get('PROJECT_ID')\n",
    "project = os.environ.get('PROJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc327a85-1db9-4687-9b9e-918d7ca8e764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andrehpereh/input_data/13 march_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/17 march_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/21 march_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/5 march 2024_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Barcelona_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Childhood_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Class - Sunday at 11-43 PM_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Introduction 2_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/March 10_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/March 22 2024_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/March 4, 2024_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/March 6 Wednesday_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Monday at 11-33 PM_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Overall description start_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Small comment_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Wednesday at 12-33 AM.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Anki.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Ilse Flatmate.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Michael.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Mike Haarlem.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Rosa Rosa Rosa.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Ruben Ewald Puijker.txt\n",
      "andrehpereh/input_data/childhood. Where did you grow up-_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "Bucket Name personalize-chatbots-v1\n",
      "Directory andrehpereh/input_data/\n",
      "personalize-chatbots-v1\n",
      "andrehpereh/input_data/\n",
      "<google.api_core.page_iterator.HTTPIterator object at 0x7fdaae62ac50>\n",
      "andrehpereh/input_data/13 march_transcript.txt\n",
      "andrehpereh/input_data/17 march_transcript.txt\n",
      "andrehpereh/input_data/21 march_transcript.txt\n",
      "andrehpereh/input_data/5 march 2024_transcript.txt\n",
      "andrehpereh/input_data/Barcelona_transcript.txt\n",
      "andrehpereh/input_data/Childhood_transcript.txt\n",
      "andrehpereh/input_data/Class - Sunday at 11-43 PM_transcript.txt\n",
      "andrehpereh/input_data/Introduction 2_transcript.txt\n",
      "andrehpereh/input_data/March 10_transcript.txt\n",
      "andrehpereh/input_data/March 22 2024_transcript.txt\n",
      "andrehpereh/input_data/March 4, 2024_transcript.txt\n",
      "andrehpereh/input_data/March 6 Wednesday_transcript.txt\n",
      "andrehpereh/input_data/Monday at 11-33 PM_transcript.txt\n",
      "andrehpereh/input_data/Overall description start_transcript.txt\n",
      "andrehpereh/input_data/Small comment_transcript.txt\n",
      "andrehpereh/input_data/Wednesday at 12-33 AM.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Anki.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Ilse Flatmate.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Michael.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Mike Haarlem.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Rosa Rosa Rosa.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Ruben Ewald Puijker.txt\n",
      "andrehpereh/input_data/childhood. Where did you grow up-_transcript.txt\n"
     ]
    }
   ],
   "source": [
    "from components.data_preparation import data_ingestion\n",
    "yup = data_ingestion.data_preparation(\n",
    "    bucket_name = 'personalize-chatbots-v1', directory = 'andrehpereh/input_data/',\n",
    "    gemini_pro_model= gemini_pro_model, pair_count=6, data_augmentation_iter=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b1ac9d-c6af-4fa9-a9df-ce2d420868a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender:\n",
      "I think it's the 13th of March today, right?\n",
      "Andres Perez:\n",
      "Yeah, that's correct.\n",
      "\n",
      "Sender:\n",
      "So, yesterday, what happened?\n",
      "Andres Perez:\n",
      "You woke up feeling normal and worked the whole day.\n",
      "\n",
      "Sender:\n",
      "What did you study in the beginning?\n",
      "Andres Perez:\n",
      "You started studying Dodge again (vocabulary and grammar).\n",
      "\n",
      "\n",
      "1533\n"
     ]
    }
   ],
   "source": [
    "print(yup[0])\n",
    "print(len(yup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218769f5-1910-4424-b1e2-8d12b88a7bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andrehpereh/input_data/13 march_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/17 march_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/21 march_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/5 march 2024_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Barcelona_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Childhood_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Class - Sunday at 11-43 PM_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/First memory_transcript.txt\n",
      "An error occurred: Response has no candidates (and no text).. Skipping...\n",
      "An error occurred: Response has no candidates (and no text).. Skipping...\n",
      "An error occurred: Response has no candidates (and no text).. Skipping...\n",
      "andrehpereh/input_data/Introduction 2_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/March 10_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/March 22 2024_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/March 4, 2024_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/March 6 Wednesday_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Monday at 11-33 PM_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Overall description start_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Small comment_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "andrehpereh/input_data/Wednesday at 12-33 AM.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Anki.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Ilse Flatmate.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Michael.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Mike Haarlem.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Rosa Rosa Rosa.txt\n",
      "andrehpereh/input_data/WhatsApp Chat with Ruben Ewald Puijker.txt\n",
      "andrehpereh/input_data/childhood. Where did you grow up-_transcript.txt\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = data_ingestion.process_transcripts(\n",
    "    bucket_name = 'personalize-chatbots-v1', directory = 'andrehpereh/input_data/', gemini_pro_model= gemini_pro_model, pair_count=6, data_augmentation_iter=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec31999c-4215-43a8-848a-f15d3ed80b47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andres Perez:\n",
      "That's great! What were some of the highlights?\n",
      "\n",
      "Sender:\n",
      "Most of the storytellers were first-timers, which was cool to see.\n",
      "\n",
      "Andres Perez:\n",
      "I can imagine. It's inspiring to watch people overcome their fears.\n",
      "\n",
      "Sender:\n",
      "Exactly! Moraine, the host, was also very entertaining.\n",
      "\n",
      "\n",
      "159\n"
     ]
    }
   ],
   "source": [
    "print(res[150])\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f63c92-6014-4306-a4d0-2b91fbbf4cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andres Perez:\n",
      "Lets meet up there, Its closer to me\n",
      "\n",
      "Sender:\n",
      "Aight Hope you are ready Gotta impress\n",
      "\n",
      "Andres Perez:\n",
      "Haha My way As long as people don't feel pity is a win 😅😂\n",
      "\n",
      "Sender:\n",
      "Haha don't worry. We won't\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res_whats[1516])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa7829-e1ad-4435-b514-005e71d43370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d24a6e-306b-4dc7-81aa-c1a4cb30bf30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90787233-de02-41df-843c-6a92663236dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf887d-8c37-4a37-b643-304ed62d40bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d5bcc-09c0-494d-821a-1ddf56d2625b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45159c3-0189-4f20-9f5f-0e9dce92a8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
