{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78d1996b-53c3-4fd2-a962-fc267008a4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_size': '2b', 'finetuned_model_dir': './gemma_2b_en', 'finetuned_weights_path': './gemma_2b_en/model.weights.h5', 'finetuned_vocab_path': './gemma_2b_en/vocabulary.spm', 'huggingface_model_dir': './gemma_2b_en_huggingface', 'deployed_model_blob': 'gemma_2b_en/20240318142909', 'deployed_model_uri': 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240318142909', 'model_name_vllm': 'gemma_2b_en-vllm', 'machine_type': 'g2-standard-8', 'accelerator_type': 'NVIDIA_L4', 'accelerator_count': 1}\n"
     ]
    }
   ],
   "source": [
    "from config import Config\n",
    "from util import get_model_paths_and_config, upload2bs\n",
    "\n",
    "res = !gcloud config get core/project\n",
    "PROJECT_ID = res[0]\n",
    "SERVICE_ACCOUNT = 'gemma-vertexai-chatbot@able-analyst-416817.iam.gserviceaccount.com'\n",
    "from datetime import datetime\n",
    "CONTAINER_IMAGE_NAME=\"gemma-chatbot\"\n",
    "GCP_REGION='us-central1'\n",
    "IMAGE_NAME=\"gemma-chatbot\"\n",
    "TAG_NAME = 'latest'\n",
    "KAGGLE_USERNAME='andrehpereh1'\n",
    "KAGGLE_KEY='5859e39806d9456749dcbac685f04bc9'\n",
    "model_paths_and_config = get_model_paths_and_config(Config.MODEL_NAME)\n",
    "print(model_paths_and_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0038c4-a645-4583-bf65-aaaae8d82f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import kfp.dsl as dsl\n",
    "from typing import List\n",
    "from kfp import compiler\n",
    "\n",
    "@dsl.component(\n",
    "  base_image ='gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest'\n",
    ")\n",
    "def process_whatsapp_chat_op(\n",
    "  bucket_name: str,\n",
    "  directory: str,\n",
    "  output_path: dsl.OutputPath(str) \n",
    "):\n",
    "    import data_ingestion\n",
    "    import json\n",
    "    formatted_messages = data_ingestion.process_whatsapp_chat(bucket_name, directory)\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(formatted_messages, f)\n",
    "    print(\"This is the output path\", output_path)\n",
    "    with open(output_path, 'r') as f:\n",
    "        output_res = json.load(f)\n",
    "    print(\"Aqui los resultadis\", output_res[1:20])\n",
    "\n",
    "\n",
    "\n",
    "@dsl.component(\n",
    "    base_image ='gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest'\n",
    ")\n",
    "def analyze_whatsapp_messages(messages_path: dsl.InputPath(str)):\n",
    "    import json\n",
    "\n",
    "    with open(messages_path, 'r') as f:\n",
    "        messages = json.load(f)\n",
    "\n",
    "    # Do some message analysis here...\n",
    "    print(\"Analyzing Messages:\")\n",
    "    for message in messages:\n",
    "        # Example of possible analysis, adjust based on your needs\n",
    "        print('Message Text:', message['text'])  \n",
    "@dsl.pipeline(name=\"whatsapp-chat\")\n",
    "def pipeline(\n",
    "    bucket_name: str,\n",
    "    directory: str,\n",
    "):\n",
    "    create_dataset_op = process_whatsapp_chat_op(\n",
    "        bucket_name=bucket_name, directory=directory\n",
    "    )\n",
    "    analyze_messages_op = analyze_whatsapp_messages(\n",
    "        messages_path=create_dataset_op.output\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"test-whatsapp.json\"\n",
    ")\n",
    "\n",
    "from google.cloud import aiplatform as vertexai\n",
    "GCS_BUCKET = f\"gs://{PROJECT_ID}-pipe_line/\"\n",
    "vertexai.init(project=PROJECT_ID, location=GCP_REGION, staging_bucket=GCS_BUCKET)\n",
    "\n",
    "vertex_pipelines_job = vertexai.pipeline_jobs.PipelineJob(\n",
    "    display_name=\"test-whatsapp\",\n",
    "    template_path=\"test-whatsapp.json\",\n",
    "    parameter_values={\n",
    "        \"bucket_name\": \"able-analyst-416817-chatbot-v1\",\n",
    "        \"directory\": \"input_data/andrehpereh\"\n",
    "    }\n",
    ")\n",
    "vertex_pipelines_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1558c9-51a2-45fe-8412-ab197af7de2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5956136-237a-4a2d-a903-2d5de4da3833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e065f-7132-49f6-9568-0b0f6b50c34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae6c4b92-ca80-44a7-a8ee-344f6d9b0ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240318144727\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240318144727')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/pythagorean-20240318144727?project=24796876098\n",
      "PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240318144727 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240318144727 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240318144727 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240318144727 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240318144727 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240318144727 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/24796876098/locations/us-central1/pipelineJobs/pythagorean-20240318144727\n"
     ]
    }
   ],
   "source": [
    "from kfp import dsl\n",
    "from kfp.dsl import OutputPath, Artifact, InputPath\n",
    "\n",
    "\n",
    "\n",
    "@dsl.component(\n",
    "  base_image ='gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest'\n",
    ")\n",
    "def process_whatsapp_chat_op(\n",
    "  bucket_name: str,\n",
    "  directory: str,\n",
    "  dataset_path: OutputPath('Dataset')\n",
    "):\n",
    "    import data_ingestion\n",
    "    import json\n",
    "    formatted_messages = data_ingestion.process_whatsapp_chat(bucket_name, directory)\n",
    "    with open(dataset_path, 'w') as f:\n",
    "        json.dump(formatted_messages, f)\n",
    "#    print(\"This is the output path\", dataset_path)\n",
    "#   with open(dataset_path, 'r') as f:\n",
    "#        output_res = json.load(f)\n",
    "    print(\"Aqui los resultadis\", formatted_messages)\n",
    "\n",
    "@dsl.component(\n",
    "  base_image = 'gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest'\n",
    ")\n",
    "def fine_tunning(\n",
    "  dataset_path: InputPath('Dataset'),\n",
    "  model_paths: dict,\n",
    ") -> str:\n",
    "    import test_container\n",
    "    res = test_container.add_test(dataset_path, model_paths)\n",
    "    finetune_gemma\n",
    "    print(\"Si funciono este pedo\", res)\n",
    "    return res\n",
    "    \n",
    "\n",
    "@dsl.pipeline\n",
    "def pythagorean(\n",
    "    bucket_name: str = \"able-analyst-416817-chatbot-v1\", directory: str = \"input_data/andrehpereh\", \n",
    "    model_paths: dict=model_paths_and_config\n",
    ") -> str:\n",
    "    whatup = process_whatsapp_chat_op(bucket_name = bucket_name, directory = directory)\n",
    "    res = fine_tunning(dataset_path=whatup.outputs['dataset_path'], model_paths=model_paths)\n",
    "    return res.output\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pythagorean, package_path=\"test-whatsapp.json\"\n",
    ")\n",
    "\n",
    "vertex_pipelines_job = vertexai.pipeline_jobs.PipelineJob(\n",
    "    display_name=\"test-whatsapp\",\n",
    "    template_path=\"test-whatsapp.json\"\n",
    ")\n",
    "vertex_pipelines_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c37caf-34a4-46e3-8a47-2991c540c5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m118"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
