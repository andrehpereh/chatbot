{
  "components": {
    "comp-convert-checkpoints-op": {
      "executorLabel": "exec-convert-checkpoints-op",
      "inputDefinitions": {
        "parameters": {
          "keras_gcs_model": {
            "parameterType": "STRING"
          },
          "model_paths": {
            "parameterType": "STRUCT"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-fine-tunning": {
      "executorLabel": "exec-fine-tunning",
      "inputDefinitions": {
        "artifacts": {
          "dataset_path": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "model_paths": {
            "parameterType": "STRUCT"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-process-whatsapp-chat-op": {
      "executorLabel": "exec-process-whatsapp-chat-op",
      "inputDefinitions": {
        "parameters": {
          "bucket_name": {
            "parameterType": "STRING"
          },
          "directory": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "dataset_path": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-convert-checkpoints-op": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "convert_checkpoints_op"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef convert_checkpoints_op(\n  keras_gcs_model: str,\n  model_paths: dict\n) -> str:\n    import conversion_function\n    import os\n    import util\n    bucket_name, blob_name = os.path.dirname(keras_gcs_model).lstrip(\"gs://\").split(\"/\", 1) \n    print(\"This is the keras passed\", keras_gcs_model)\n    util.download_all_from_blob(bucket_name, model_paths['fine_tuned_keras_blob'], local_destination=model_paths['finetuned_model_dir'])\n    if os.path.exists(\"./model.weights.h5\"):\n        print(\"File exists!\")\n    else:\n        print(\"File does not exist.\")\n    converted_fined_tuned_path = conversion_function.convert_checkpoints(\n        weights_file=model_paths['finetuned_weights_path'],\n        size=model_paths['model_size'],\n        output_dir=model_paths['huggingface_model_dir'],\n        vocab_path=model_paths['finetuned_vocab_path']\n    )\n    util.upload2bs(\n        local_directory = converted_fined_tuned_path, bucket_name = bucket_name,\n        destination_subfolder = model_paths['deployed_model_blob']\n    )\n    return model_paths['deployed_model_uri']\n\n"
          ],
          "image": "gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest",
          "resources": {
            "accelerator": {
              "count": "1",
              "type": "NVIDIA_L4"
            },
            "cpuLimit": 0.008,
            "memoryLimit": 40.0
          }
        }
      },
      "exec-fine-tunning": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "fine_tunning"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef fine_tunning(\n  dataset_path: InputPath('Dataset'),\n  model_paths: dict,\n  #finetuned_weights_dir: OutputPath('Model'),\n) -> str:\n    # import test_container\n    import trainer\n    import json\n    import util\n    import os\n    with open(dataset_path, 'r') as f:\n        dataset = json.load(f)\n    os.makedirs(model_paths['finetuned_model_dir'], exist_ok=True)\n    finetuned_weights_path = os.path.join(model_paths['finetuned_model_dir'], 'model.weights.h5') \n\n    model = trainer.finetune_gemma(dataset, model_paths, False)\n    print(\"Its gonna save it here\", finetuned_weights_path)\n    #model.save_weights(finetuned_weights_path)\n    #model.preprocessor.tokenizer.save_assets(model_paths['finetuned_model_dir'])\n    bucket_name = 'able-analyst-416817-chatbot-v1' # move to parameter.\n    util.upload2bs(\n        local_directory = model_paths['finetuned_model_dir'], bucket_name = bucket_name,\n        destination_subfolder = model_paths['fine_tuned_keras_blob']\n    )\n    model_gcs = \"gs://{}/{}\".format(bucket_name, model_paths['fine_tuned_keras_blob'])  \n    print(\"This is the storage bucket\", model_gcs)\n    return model_gcs\n\n"
          ],
          "image": "gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest",
          "resources": {
            "accelerator": {
              "count": "1",
              "type": "NVIDIA_L4"
            },
            "cpuLimit": 0.008,
            "memoryLimit": 40.0
          }
        }
      },
      "exec-process-whatsapp-chat-op": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "process_whatsapp_chat_op"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef process_whatsapp_chat_op(\n  bucket_name: str,\n  directory: str,\n  dataset_path: OutputPath('Dataset')\n):\n    import data_ingestion\n    import json\n    formatted_messages = data_ingestion.process_whatsapp_chat(bucket_name, directory)\n    with open(dataset_path, 'w') as f:\n        json.dump(formatted_messages, f)\n\n"
          ],
          "image": "gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest"
        }
      }
    }
  },
  "pipelineInfo": {
    "name": "pythagorean"
  },
  "root": {
    "dag": {
      "tasks": {
        "convert-checkpoints-op": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-convert-checkpoints-op"
          },
          "dependentTasks": [
            "fine-tunning"
          ],
          "inputs": {
            "parameters": {
              "keras_gcs_model": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "fine-tunning"
                }
              },
              "model_paths": {
                "runtimeValue": {
                  "constant": {
                    "accelerator_count": 1.0,
                    "accelerator_type": "NVIDIA_L4",
                    "deployed_model_blob": "gemma_2b_en/20240322091040",
                    "deployed_model_uri": "gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240322091040",
                    "fine_tuned_keras_blob": "gemma_2b_en/keras/20240322091040",
                    "finetuned_model_dir": "./gemma_2b_en",
                    "finetuned_vocab_path": "./gemma_2b_en/vocabulary.spm",
                    "finetuned_weights_path": "./gemma_2b_en/model.weights.h5",
                    "huggingface_model_dir": "./gemma_2b_en_huggingface",
                    "machine_type": "g2-standard-8",
                    "model_name_vllm": "gemma_2b_en-vllm",
                    "model_size": "2b"
                  }
                }
              }
            }
          },
          "taskInfo": {
            "name": "convert-checkpoints-op"
          }
        },
        "fine-tunning": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-fine-tunning"
          },
          "dependentTasks": [
            "process-whatsapp-chat-op"
          ],
          "inputs": {
            "artifacts": {
              "dataset_path": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "dataset_path",
                  "producerTask": "process-whatsapp-chat-op"
                }
              }
            },
            "parameters": {
              "model_paths": {
                "runtimeValue": {
                  "constant": {
                    "accelerator_count": 1.0,
                    "accelerator_type": "NVIDIA_L4",
                    "deployed_model_blob": "gemma_2b_en/20240322091040",
                    "deployed_model_uri": "gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240322091040",
                    "fine_tuned_keras_blob": "gemma_2b_en/keras/20240322091040",
                    "finetuned_model_dir": "./gemma_2b_en",
                    "finetuned_vocab_path": "./gemma_2b_en/vocabulary.spm",
                    "finetuned_weights_path": "./gemma_2b_en/model.weights.h5",
                    "huggingface_model_dir": "./gemma_2b_en_huggingface",
                    "machine_type": "g2-standard-8",
                    "model_name_vllm": "gemma_2b_en-vllm",
                    "model_size": "2b"
                  }
                }
              }
            }
          },
          "taskInfo": {
            "name": "fine-tunning"
          }
        },
        "process-whatsapp-chat-op": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-process-whatsapp-chat-op"
          },
          "inputs": {
            "parameters": {
              "bucket_name": {
                "componentInputParameter": "bucket_name"
              },
              "directory": {
                "componentInputParameter": "directory"
              }
            }
          },
          "taskInfo": {
            "name": "process-whatsapp-chat-op"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "bucket_name": {
          "defaultValue": "able-analyst-416817-chatbot-v1",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "directory": {
          "defaultValue": "input_data/andrehpereh",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "model_paths": {
          "defaultValue": {
            "accelerator_count": 1.0,
            "accelerator_type": "NVIDIA_L4",
            "deployed_model_blob": "gemma_2b_en/20240322091040",
            "deployed_model_uri": "gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240322091040",
            "fine_tuned_keras_blob": "gemma_2b_en/keras/20240322091040",
            "finetuned_model_dir": "./gemma_2b_en",
            "finetuned_vocab_path": "./gemma_2b_en/vocabulary.spm",
            "finetuned_weights_path": "./gemma_2b_en/model.weights.h5",
            "huggingface_model_dir": "./gemma_2b_en_huggingface",
            "machine_type": "g2-standard-8",
            "model_name_vllm": "gemma_2b_en-vllm",
            "model_size": "2b"
          },
          "isOptional": true,
          "parameterType": "STRUCT"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.7.0"
}