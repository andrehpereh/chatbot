{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b5ec7c1-1e80-4be7-9d73-043bbbb9b4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "able-analyst-416817\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PROJECT_ID'] = 'able-analyst-416817'\n",
    "print(os.environ.get('PROJECT_ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56ea9444-bd83-44e8-8cd3-7fa40cae015e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = !gcloud config get core/project\n",
    "PROJECT_ID = res[0]\n",
    "SERVICE_ACCOUNT = 'gemma-vertexai-chatbot@able-analyst-416817.iam.gserviceaccount.com'\n",
    "from datetime import datetime\n",
    "CONTAINER_IMAGE_NAME=\"gemma-chatbot\"\n",
    "GCP_REGION='us-central1'\n",
    "TAG_NAME = 'latest'\n",
    "KAGGLE_USERNAME='andrehpereh1'\n",
    "KAGGLE_KEY='5859e39806d9456749dcbac685f04bc9'\n",
    "CONTAINER_IMAGE_NAME_DATA_PREP = f\"{CONTAINER_IMAGE_NAME}-data-preparation\"\n",
    "CONTAINER_IMAGE_NAME_FINE_TUNE = f\"{CONTAINER_IMAGE_NAME}-fine-tunning\"\n",
    "CONTAINER_IMAGE_NAME_RUN_APP = f\"{CONTAINER_IMAGE_NAME}-running-app\"\n",
    "CONTAINER_IMAGE_NAME_PIPELINE = f\"{CONTAINER_IMAGE_NAME}-pipeline-app\"\n",
    "CONTAINER_IMAGE_RUNNING_APP = f\"{CONTAINER_IMAGE_NAME}-running-app\"\n",
    "BUCKET_NAME = 'able-analyst-416817-chatbot-v1'\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "FINE_TUNE_FLAG=  True\n",
    "EPOCHS=12\n",
    "MODEL_NAME=\"gemma_2b_en\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f4acc04-293c-4e1f-889a-efd74f3e143f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma-chatbot-running-app'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTAINER_IMAGE_RUNNING_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb8fdb-fb38-41b2-adec-c23e82577771",
   "metadata": {},
   "outputs": [],
   "source": [
    "substitutions=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME_DATA_PREP={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           CONTAINER_IMAGE_NAME_DATA_PREP,\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(substitutions)\n",
    "\n",
    "# Runs the data_preparation component image. (Development, when tested should be moved to the main cloudbuild in the project folder)\n",
    "# Pay attention to the \".\" after summit. Might need some changes when move to the master pipeline.\n",
    "!gcloud builds submit . --timeout=15m --config \"components/data_preparation/cloudbuild.yaml\" --substitutions {substitutions} --region={GCP_REGION}\n",
    "# DO not forget the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e348a00-9742-41d7-b16f-3b1538dc6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker run gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest data_ingestion.py --bucket-name 'able-analyst-416817-chatbot-v1' --directory 'input_data/andrehpereh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92bc864-cf50-48d3-b50f-d781d6598660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb1a23-f805-4f92-9146-16cb101a4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "substitutions=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME_FINE_TUNE={},\\\n",
    "_KAGGLE_USERNAME={},\\\n",
    "_KAGGLE_KEY={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           CONTAINER_IMAGE_NAME_FINE_TUNE,\n",
    "           KAGGLE_USERNAME,\n",
    "           KAGGLE_KEY,\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(substitutions)\n",
    "\n",
    "# Builds image\n",
    "!gcloud builds submit . --config \"components/fine_tunning/cloudbuild.yaml\" --substitutions {substitutions} --region={GCP_REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd61e9c-6cc9-4b86-9c44-c15f620facfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = [\"Sender: FoooodddAndres Perez: Coming :)\", \"Sender: Can I maybe borrow your iron? Andres Perez: It\\'s not my iron But yeah haha Or is it?\"]\n",
    "model_paths = \"\"\"{\"finetuned_model_dir\": \"./gemma_2b_en\", \"finetuned_weights_path\": \"./gemma_2b_en/model.weights.h5\"}\"\"\"\n",
    "print(len(data))\n",
    "model_paths = json.dumps(model_paths)\n",
    "#!docker run gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest trainer.py --data {data} --model-paths {model_paths}\n",
    "#!python ./components/fine_tunning/trainer.py --data {data} --model-paths {model_paths}\n",
    "#!python ./components/fine_tunning/conversion_function.py --weights-file {model_paths_and_config['finetuned_weights_path']} --size {model_paths_and_config['model_size']} --vocab-path {model_paths_and_config['finetuned_vocab_path']} --output-dir {model_paths_and_config['huggingface_model_dir']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ed344-320c-4cb3-82b2-d94467dc5f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba87d49e-615a-475a-a9e8-6e53760d9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "substitutions=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME_RUN_APP={},\\\n",
    "_GCP_REGION={},\\\n",
    "TAG_NAME={}\\\n",
    "\"\"\".format(\n",
    "           CONTAINER_IMAGE_NAME_RUN_APP,\n",
    "           GCP_REGION,\n",
    "           TAG_NAME, \n",
    "           ).strip()\n",
    "print(substitutions)\n",
    "!gcloud builds submit . --timeout=15m --config \"components/app_flask/cloudbuild.yaml\" --substitutions {substitutions} --region={GCP_REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e1e4f3e-2dd2-4b7c-9218-3b48ee2d2afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gemma_2b_en\n",
      "This is the dictionary {'model_size': '2b', 'finetuned_model_dir': './gemma_2b_en', 'finetuned_weights_path': './gemma_2b_en/model.weights.h5', 'finetuned_vocab_path': './gemma_2b_en/vocabulary.spm', 'huggingface_model_dir': './gemma_2b_en_huggingface', 'deployed_model_blob': 'gemma_2b_en/20240323192751', 'deployed_model_uri': 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240323192751', 'fine_tuned_keras_blob': 'gemma_2b_en/keras/20240323192751', 'model_name_vllm': 'gemma_2b_en-vllm', 'machine_type': 'g2-standard-8', 'accelerator_type': 'NVIDIA_L4', 'accelerator_count': 1}\n",
      "/home/jupyter/chatbot/fine_tune_pipeline_test.json\n"
     ]
    }
   ],
   "source": [
    "!kfp dsl compile --py './components/pipeline/pipeline/pipeline.py' --output \"fine_tune_pipeline_test.json\" --function fine_tune_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12ad583b-7665-46ff-86a0-480e3895161e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/chatbot\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f671c3e-7269-4712-8adc-c5831e4bcc95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "substitutions=\"\"\"\n",
    "_CONTAINER_IMAGE_NAME_PIPELINE={},\\\n",
    "TAG_NAME={},\\\n",
    "_BUCKET_NAME={},\\\n",
    "_FINE_TUNE_FLAG={},\\\n",
    "_EPOCHS={},\\\n",
    "_MODEL_NAME={},\\\n",
    "_BUCKET_URI={},\\\n",
    "\"\"\".format(\n",
    "           CONTAINER_IMAGE_NAME_PIPELINE,\n",
    "           TAG_NAME,\n",
    "           BUCKET_NAME,\n",
    "           FINE_TUNE_FLAG,\n",
    "           EPOCHS,\n",
    "           MODEL_NAME,\n",
    "           BUCKET_URI\n",
    "           ).strip()\n",
    "print(substitutions)\n",
    "!gcloud builds submit . --timeout=15m --config \"components/pipeline/cloudbuild.yaml\" --substitutions {substitutions} --region={GCP_REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290781a-2b70-4823-8668-ebd8ce3022b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python \"./components/pipeline/pipeline.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7ad76d7-5a6b-4b27-ad0e-633679ee2fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CONTAINER_IMAGE_RUNNING_APP=gemma-chatbot-pipeline-app,TAG_NAME=latest\n",
      "Creating temporary tarball archive of 94 file(s) totalling 2.1 MiB before compression.\n",
      "Uploading tarball of [.] to [gs://able-analyst-416817_cloudbuild/source/1711384728.193524-025882457dc947f0a060ca38319f132a.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/able-analyst-416817/locations/us-central1/builds/ddcf5e77-9e59-4b89-9b52-fbca666043eb].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds;region=us-central1/ddcf5e77-9e59-4b89-9b52-fbca666043eb?project=24796876098 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"ddcf5e77-9e59-4b89-9b52-fbca666043eb\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://able-analyst-416817_cloudbuild/source/1711384728.193524-025882457dc947f0a060ca38319f132a.tgz#1711384728960581\n",
      "Copying gs://able-analyst-416817_cloudbuild/source/1711384728.193524-025882457dc947f0a060ca38319f132a.tgz#1711384728960581...\n",
      "/ [1 files][753.9 KiB/753.9 KiB]                                                \n",
      "Operation completed over 1 objects/753.9 KiB.\n",
      "BUILD\n",
      "Starting Step #0\n",
      "Step #0: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0: Sending build context to Docker daemon  369.2kB\n",
      "Step #0: Step 1/13 : FROM python:3.9-slim\n",
      "Step #0: 3.9-slim: Pulling from library/python\n",
      "Step #0: 8a1e25ce7c4f: Already exists\n",
      "Step #0: 1103112ebfc4: Pulling fs layer\n",
      "Step #0: 6e52db3290c0: Pulling fs layer\n",
      "Step #0: 937bce5dbc70: Pulling fs layer\n",
      "Step #0: 05e63546fee1: Pulling fs layer\n",
      "Step #0: 05e63546fee1: Waiting\n",
      "Step #0: 937bce5dbc70: Verifying Checksum\n",
      "Step #0: 937bce5dbc70: Download complete\n",
      "Step #0: 1103112ebfc4: Verifying Checksum\n",
      "Step #0: 1103112ebfc4: Download complete\n",
      "Step #0: 05e63546fee1: Verifying Checksum\n",
      "Step #0: 05e63546fee1: Download complete\n",
      "Step #0: 6e52db3290c0: Verifying Checksum\n",
      "Step #0: 6e52db3290c0: Download complete\n",
      "Step #0: 1103112ebfc4: Pull complete\n",
      "Step #0: 6e52db3290c0: Pull complete\n",
      "Step #0: 937bce5dbc70: Pull complete\n",
      "Step #0: 05e63546fee1: Pull complete\n",
      "Step #0: Digest: sha256:df78d66895cd3b12ec57c451f9776192a535688e27ab8a72c03896b17dbb4b98\n",
      "Step #0: Status: Downloaded newer image for python:3.9-slim\n",
      "Step #0:  ---> 500c1b793e9d\n",
      "Step #0: Step 2/13 : WORKDIR /root\n",
      "Step #0:  ---> Running in 40f87dc2a74b\n",
      "Step #0: Removing intermediate container 40f87dc2a74b\n",
      "Step #0:  ---> 198f886cbd78\n",
      "Step #0: Step 3/13 : RUN pwd\n",
      "Step #0:  ---> Running in 90ccc96a1cc0\n",
      "Step #0: /root\n",
      "Step #0: Removing intermediate container 90ccc96a1cc0\n",
      "Step #0:  ---> 9ae1ef905871\n",
      "Step #0: Step 4/13 : RUN ls\n",
      "Step #0:  ---> Running in 8c2f8f79de15\n",
      "Step #0: Removing intermediate container 8c2f8f79de15\n",
      "Step #0:  ---> d3dacde5eb4b\n",
      "Step #0: Step 5/13 : COPY requirements.txt .\n",
      "Step #0:  ---> e272dac8cace\n",
      "Step #0: Step 6/13 : RUN pip install -U -r requirements.txt\n",
      "Step #0:  ---> Running in 912b50e91095\n",
      "Step #0: Collecting flask\n",
      "Step #0:   Downloading flask-3.0.2-py3-none-any.whl (101 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.3/101.3 kB 1.4 MB/s eta 0:00:00\n",
      "Step #0: Collecting google-cloud-aiplatform\n",
      "Step #0:   Downloading google_cloud_aiplatform-1.44.0-py2.py3-none-any.whl (4.2 MB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.2/4.2 MB 19.9 MB/s eta 0:00:00\n",
      "Step #0: Collecting protobuf\n",
      "Step #0:   Downloading protobuf-5.26.0-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.8/302.8 kB 35.5 MB/s eta 0:00:00\n",
      "Step #0: Collecting click>=8.1.3\n",
      "Step #0:   Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 1.9 MB/s eta 0:00:00\n",
      "Step #0: Collecting blinker>=1.6.2\n",
      "Step #0:   Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Step #0: Collecting importlib-metadata>=3.6.0\n",
      "Step #0:   Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Step #0: Collecting Werkzeug>=3.0.0\n",
      "Step #0:   Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.7/226.7 kB 34.2 MB/s eta 0:00:00\n",
      "Step #0: Collecting Jinja2>=3.1.2\n",
      "Step #0:   Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.2/133.2 kB 22.3 MB/s eta 0:00:00\n",
      "Step #0: Collecting itsdangerous>=2.1.2\n",
      "Step #0:   Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Step #0: Collecting google-cloud-bigquery<4.0.0dev,>=1.15.0\n",
      "Step #0:   Downloading google_cloud_bigquery-3.19.0-py2.py3-none-any.whl (232 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.6/232.6 kB 31.3 MB/s eta 0:00:00\n",
      "Step #0: Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "Step #0:   Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 333.7/333.7 kB 38.0 MB/s eta 0:00:00\n",
      "Step #0: Collecting protobuf\n",
      "Step #0:   Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 kB 36.7 MB/s eta 0:00:00\n",
      "Step #0: Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1\n",
      "Step #0:   Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.3/138.3 kB 23.3 MB/s eta 0:00:00\n",
      "Step #0: Collecting google-cloud-storage<3.0.0dev,>=1.32.0\n",
      "Step #0:   Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.6/125.6 kB 20.1 MB/s eta 0:00:00\n",
      "Step #0: Collecting google-auth<3.0.0dev,>=2.14.1\n",
      "Step #0:   Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189.2/189.2 kB 26.7 MB/s eta 0:00:00\n",
      "Step #0: Collecting packaging>=14.3\n",
      "Step #0:   Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.5/53.5 kB 8.5 MB/s eta 0:00:00\n",
      "Step #0: Collecting shapely<3.0.0dev\n",
      "Step #0:   Downloading shapely-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 56.4 MB/s eta 0:00:00\n",
      "Step #0: Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "Step #0:   Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.8/48.8 kB 9.2 MB/s eta 0:00:00\n",
      "Step #0: Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "Step #0:   Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.1/229.1 kB 34.1 MB/s eta 0:00:00\n",
      "Step #0: Collecting requests<3.0.0.dev0,>=2.18.0\n",
      "Step #0:   Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 12.3 MB/s eta 0:00:00\n",
      "Step #0: Collecting grpcio<2.0dev,>=1.33.2\n",
      "Step #0:   Downloading grpcio-1.62.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 59.9 MB/s eta 0:00:00\n",
      "Step #0: Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "Step #0:   Downloading grpcio_status-1.62.1-py3-none-any.whl (14 kB)\n",
      "Step #0: Collecting pyasn1-modules>=0.2.1\n",
      "Step #0:   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 1.9 MB/s eta 0:00:00\n",
      "Step #0: Collecting rsa<5,>=3.1.4\n",
      "Step #0:   Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Step #0: Collecting cachetools<6.0,>=2.0.0\n",
      "Step #0:   Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Step #0: Collecting google-cloud-core<3.0.0dev,>=1.6.0\n",
      "Step #0:   Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Step #0: Collecting google-resumable-media<3.0dev,>=0.6.0\n",
      "Step #0:   Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.6/80.6 kB 15.9 MB/s eta 0:00:00\n",
      "Step #0: Collecting python-dateutil<3.0dev,>=2.7.2\n",
      "Step #0:   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 33.8 MB/s eta 0:00:00\n",
      "Step #0: Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "Step #0:   Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Step #0: Collecting google-crc32c<2.0dev,>=1.0\n",
      "Step #0:   Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Step #0: Collecting zipp>=0.5\n",
      "Step #0:   Downloading zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Step #0: Collecting MarkupSafe>=2.0\n",
      "Step #0:   Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Step #0: Collecting numpy<2,>=1.14\n",
      "Step #0:   Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 37.1 MB/s eta 0:00:00\n",
      "Step #0: Collecting pyasn1<0.6.0,>=0.4.6\n",
      "Step #0:   Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.9/84.9 kB 15.3 MB/s eta 0:00:00\n",
      "Step #0: Collecting six>=1.5\n",
      "Step #0:   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Step #0: Collecting charset-normalizer<4,>=2\n",
      "Step #0:   Downloading charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.3/142.3 kB 25.2 MB/s eta 0:00:00\n",
      "Step #0: Collecting certifi>=2017.4.17\n",
      "Step #0:   Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 27.4 MB/s eta 0:00:00\n",
      "Step #0: Collecting idna<4,>=2.5\n",
      "Step #0:   Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.6/61.6 kB 12.3 MB/s eta 0:00:00\n",
      "Step #0: Collecting urllib3<3,>=1.21.1\n",
      "Step #0:   Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.1/121.1 kB 21.2 MB/s eta 0:00:00\n",
      "Step #0: Installing collected packages: zipp, urllib3, six, pyasn1, protobuf, packaging, numpy, MarkupSafe, itsdangerous, idna, grpcio, google-crc32c, click, charset-normalizer, certifi, cachetools, blinker, Werkzeug, shapely, rsa, requests, python-dateutil, pyasn1-modules, proto-plus, Jinja2, importlib-metadata, googleapis-common-protos, google-resumable-media, grpcio-status, google-auth, flask, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "Step #0: Successfully installed Jinja2-3.1.3 MarkupSafe-2.1.5 Werkzeug-3.0.1 blinker-1.7.0 cachetools-5.3.3 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 flask-3.0.2 google-api-core-2.18.0 google-auth-2.29.0 google-cloud-aiplatform-1.44.0 google-cloud-bigquery-3.19.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.3 google-cloud-storage-2.16.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.63.0 grpc-google-iam-v1-0.13.0 grpcio-1.62.1 grpcio-status-1.62.1 idna-3.6 importlib-metadata-7.1.0 itsdangerous-2.1.2 numpy-1.26.4 packaging-24.0 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 python-dateutil-2.9.0.post0 requests-2.31.0 rsa-4.9 shapely-2.0.3 six-1.16.0 urllib3-2.2.1 zipp-3.18.1\n",
      "Step #0: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Step #0: \u001b[0m\u001b[91m\n",
      "Step #0: [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "Step #0: [notice] To update, run: pip install --upgrade pip\n",
      "Step #0: \u001b[0mRemoving intermediate container 912b50e91095\n",
      "Step #0:  ---> a8b1200e3e1b\n",
      "Step #0: Step 7/13 : RUN ls\n",
      "Step #0:  ---> Running in bf7f59f57851\n",
      "Step #0: requirements.txt\n",
      "Step #0: Removing intermediate container bf7f59f57851\n",
      "Step #0:  ---> cc9c1e0b28b8\n",
      "Step #0: Step 8/13 : COPY . /app\n",
      "Step #0:  ---> 9d56f5909d12\n",
      "Step #0: Step 9/13 : WORKDIR /app\n",
      "Step #0:  ---> Running in 482b4b443495\n",
      "Step #0: Removing intermediate container 482b4b443495\n",
      "Step #0:  ---> 2e91535dfa67\n",
      "Step #0: Step 10/13 : EXPOSE 5000\n",
      "Step #0:  ---> Running in 52363a7cdecf\n",
      "Step #0: Removing intermediate container 52363a7cdecf\n",
      "Step #0:  ---> 3520880d0e10\n",
      "Step #0: Step 11/13 : RUN pwd\n",
      "Step #0:  ---> Running in 2d0e424000ed\n",
      "Step #0: /app\n",
      "Step #0: Removing intermediate container 2d0e424000ed\n",
      "Step #0:  ---> 2300200ad679\n",
      "Step #0: Step 12/13 : RUN ls\n",
      "Step #0:  ---> Running in 9dc2e186b7f1\n",
      "Step #0: Dockerfile\n",
      "Step #0: app\n",
      "Step #0: cloudbuild.yaml\n",
      "Step #0: requirements.txt\n",
      "Step #0: Removing intermediate container 9dc2e186b7f1\n",
      "Step #0:  ---> 061a15466e39\n",
      "Step #0: Step 13/13 : CMD [\"python\", \"-m\", \"app.app\"]\n",
      "Step #0:  ---> Running in 5ac251211dc0\n",
      "Step #0: Removing intermediate container 5ac251211dc0\n",
      "Step #0:  ---> 032ed093cea5\n",
      "Step #0: Successfully built 032ed093cea5\n",
      "Step #0: Successfully tagged gcr.io/able-analyst-416817/gemma-chatbot-pipeline-app:latest\n",
      "Finished Step #0\n",
      "Starting Step #1\n",
      "Step #1: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #1: The push refers to repository [gcr.io/able-analyst-416817/gemma-chatbot-pipeline-app]\n",
      "Step #1: 4b65333dc13a: Preparing\n",
      "Step #1: 9c967c63fd31: Preparing\n",
      "Step #1: 582fed62fa93: Preparing\n",
      "Step #1: 5d78e4c3c132: Preparing\n",
      "Step #1: 9138b29cde77: Preparing\n",
      "Step #1: 4c8474755d1b: Preparing\n",
      "Step #1: c8f253aef560: Preparing\n",
      "Step #1: a483da8ab3e9: Preparing\n",
      "Step #1: 4c8474755d1b: Waiting\n",
      "Step #1: c8f253aef560: Waiting\n",
      "Step #1: a483da8ab3e9: Waiting\n",
      "Step #1: 5d78e4c3c132: Layer already exists\n",
      "Step #1: 9138b29cde77: Layer already exists\n",
      "Step #1: 4c8474755d1b: Layer already exists\n",
      "Step #1: c8f253aef560: Layer already exists\n",
      "Step #1: a483da8ab3e9: Layer already exists\n",
      "Step #1: 582fed62fa93: Pushed\n",
      "Step #1: 4b65333dc13a: Pushed\n",
      "Step #1: 9c967c63fd31: Pushed\n",
      "Step #1: latest: digest: sha256:69b40bf83eed01e0c30e7125672e0fba06e4ab156634eb175e65bcfc881b5b0e size: 1999\n",
      "Finished Step #1\n",
      "Starting Step #2\n",
      "Step #2: Already have image (with digest): gcr.io/cloud-builders/gcloud\n",
      "Step #2: Deploying container to Cloud Run service [chattingwithandreh] in project [able-analyst-416817] region [us-central1]\n",
      "Step #2: Deploying new service...\n",
      "Step #2: Setting IAM Policy..........done\n",
      "Step #2: Creating Revision........................................................................................................................................................................................................................................................................................................................................................................................done\n",
      "Step #2: Routing traffic.....done\n",
      "Step #2: Done.\n",
      "Step #2: Service [chattingwithandreh] revision [chattingwithandreh-00001-jzn] has been deployed and is serving 100 percent of traffic.\n",
      "Step #2: Service URL: https://chattingwithandreh-gqf6v2rlha-uc.a.run.app\n",
      "Finished Step #2\n",
      "PUSH\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                             IMAGES  STATUS\n",
      "ddcf5e77-9e59-4b89-9b52-fbca666043eb  2024-03-25T16:38:49+00:00  1M37S     gs://able-analyst-416817_cloudbuild/source/1711384728.193524-025882457dc947f0a060ca38319f132a.tgz  -       SUCCESS\n"
     ]
    }
   ],
   "source": [
    "substitutions=f\"_CONTAINER_IMAGE_RUNNING_APP={CONTAINER_IMAGE_RUNNING_APP},TAG_NAME={TAG_NAME}\"\n",
    "print(substitutions)\n",
    "!gcloud builds submit . --config \"./components/app_flask/cloudbuild.yaml\" --substitutions {substitutions} --region={GCP_REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e6a1251-caa0-4f0c-b3e1-b4ff0f46c4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma-chatbot-pipeline-app'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTAINER_IMAGE_RUNNING_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "538bc302-ec53-432b-a9fd-7dec88d6cf87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is all {'steps': [{'name': 'gcr.io/cloud-builders/docker', 'args': ['build', '-t', 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_NAME_DATA_PREP:$TAG_NAME', '.'], 'dir': './components/data_preparation'}, {'name': 'gcr.io/cloud-builders/docker', 'args': ['push', 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_NAME_DATA_PREP:$TAG_NAME']}, {'name': 'gcr.io/cloud-builders/docker', 'args': ['build', '-t', 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_NAME_FINE_TUNE:$TAG_NAME', '--build-arg', 'KAGGLE_KEY=$_KAGGLE_KEY', '--build-arg', 'KAGGLE_USERNAME=$_KAGGLE_USERNAME', '.'], 'dir': './components/fine_tunning'}, {'name': 'gcr.io/cloud-builders/docker', 'args': ['push', 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_NAME_FINE_TUNE:$TAG_NAME']}, {'name': 'gcr.io/cloud-builders/docker', 'args': ['build', '-t', 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_NAME_PIPELINE:$TAG_NAME', '.'], 'dir': './components/pipeline'}, {'name': 'gcr.io/cloud-builders/docker', 'args': ['push', 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_NAME_PIPELINE:$TAG_NAME']}, {'name': 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_NAME_PIPELINE:$TAG_NAME', 'dir': './components/pipeline', 'args': ['python', 'pipeline.py'], 'env': ['BUCKET_NAME=$_BUCKET_NAME', 'BUCKET_URI=$_BUCKET_URI', 'FINE_TUNE_FLAG=$_FINE_TUNE_FLAG', 'EPOCHS=$_EPOCHS', 'MODEL_NAME=$_MODEL_NAME']}, {'name': 'gcr.io/cloud-builders/docker', 'args': ['build', '-t', 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_RUNNING_APP:$TAG_NAME', '.'], 'dir': './components/app_flask'}, {'name': 'gcr.io/cloud-builders/docker', 'args': ['push', 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_RUNNING_APP:$TAG_NAME']}, {'name': 'gcr.io/cloud-builders/gcloud', 'args': ['run', 'deploy', 'chattingwithandreh', '--image', 'gcr.io/$PROJECT_ID/$_CONTAINER_IMAGE_RUNNING_APP:$TAG_NAME', '--region', '$LOCATION', '--platform', 'managed', '--allow-unauthenticated', '--port', '5000']}]}\n"
     ]
    }
   ],
   "source": [
    "from cluodbuild_compiler import merge_cloudbuild_files, find_missing_elements\n",
    "child_files = [ \n",
    "    \"./components/data_preparation/cloudbuild.yaml\", \n",
    "    \"./components/fine_tunning/cloudbuild.yaml\", \n",
    "    \"./components/pipeline/cloudbuild.yaml\",\n",
    "    \"./components/app_flask/cloudbuild.yaml\"\n",
    "]\n",
    "\n",
    "descriptions = [ \n",
    "    \"Data Preparation\",\n",
    "    \"Model Training\", \n",
    "    \"Vertex AI Pipeline Deployment\",\n",
    "    \"App flask application (Cloud Run)\"\n",
    "]\n",
    "all_variables = merge_cloudbuild_files(child_files, descriptions, timeout_hours = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30b93d85-e688-4360-bb2f-dc880b6c98fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "substitutions=f\"\"\"\n",
    "_CONTAINER_IMAGE_NAME_DATA_PREP={CONTAINER_IMAGE_NAME_DATA_PREP},\\\n",
    "_CONTAINER_IMAGE_NAME_FINE_TUNE={CONTAINER_IMAGE_NAME_FINE_TUNE},\\\n",
    "_CONTAINER_IMAGE_NAME_PIPELINE={CONTAINER_IMAGE_NAME_PIPELINE},\\\n",
    "_CONTAINER_IMAGE_RUNNING_APP={CONTAINER_IMAGE_RUNNING_APP},\\\n",
    "_BUCKET_NAME={BUCKET_NAME},\\\n",
    "_BUCKET_URI={BUCKET_URI},\\\n",
    "_KAGGLE_USERNAME={KAGGLE_USERNAME},\\\n",
    "_KAGGLE_KEY={KAGGLE_KEY},\\\n",
    "_FINE_TUNE_FLAG={FINE_TUNE_FLAG},\\\n",
    "_EPOCHS={EPOCHS},\\\n",
    "_MODEL_NAME={MODEL_NAME},\\\n",
    "TAG_NAME={TAG_NAME}\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb7fca8a-cd28-4bc5-943d-bffb1615ab42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "missing_elements = find_missing_elements(all_variables, substitutions)\n",
    "print(missing_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d0666-b0e6-4926-b830-7c2e62518110",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 93 file(s) totalling 2.0 MiB before compression.\n",
      "Uploading tarball of [.] to [gs://able-analyst-416817_cloudbuild/source/1711354634.966782-746784c32b4549d78d0817a52de0705a.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/able-analyst-416817/locations/us-central1/builds/7e09f065-c9b8-4963-9a22-40bdf464d931].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds;region=us-central1/7e09f065-c9b8-4963-9a22-40bdf464d931?project=24796876098 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"7e09f065-c9b8-4963-9a22-40bdf464d931\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://able-analyst-416817_cloudbuild/source/1711354634.966782-746784c32b4549d78d0817a52de0705a.tgz#1711354635636390\n",
      "Copying gs://able-analyst-416817_cloudbuild/source/1711354634.966782-746784c32b4549d78d0817a52de0705a.tgz#1711354635636390...\n",
      "/ [1 files][737.2 KiB/737.2 KiB]                                                \n",
      "Operation completed over 1 objects/737.2 KiB.\n",
      "BUILD\n",
      "Starting Step #0\n",
      "Step #0: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0: Sending build context to Docker daemon  24.58kB\n",
      "Step #0: Step 1/10 : FROM python:3.9-slim\n",
      "Step #0: 3.9-slim: Pulling from library/python\n",
      "Step #0: 8a1e25ce7c4f: Already exists\n",
      "Step #0: 1103112ebfc4: Pulling fs layer\n",
      "Step #0: 6e52db3290c0: Pulling fs layer\n",
      "Step #0: 937bce5dbc70: Pulling fs layer\n",
      "Step #0: 05e63546fee1: Pulling fs layer\n",
      "Step #0: 05e63546fee1: Waiting\n",
      "Step #0: 1103112ebfc4: Verifying Checksum\n",
      "Step #0: 1103112ebfc4: Download complete\n",
      "Step #0: 937bce5dbc70: Verifying Checksum\n",
      "Step #0: 937bce5dbc70: Download complete\n",
      "Step #0: 6e52db3290c0: Download complete\n",
      "Step #0: 05e63546fee1: Verifying Checksum\n",
      "Step #0: 05e63546fee1: Download complete\n",
      "Step #0: 1103112ebfc4: Pull complete\n",
      "Step #0: 6e52db3290c0: Pull complete\n",
      "Step #0: 937bce5dbc70: Pull complete\n",
      "Step #0: 05e63546fee1: Pull complete\n",
      "Step #0: Digest: sha256:df78d66895cd3b12ec57c451f9776192a535688e27ab8a72c03896b17dbb4b98\n",
      "Step #0: Status: Downloaded newer image for python:3.9-slim\n",
      "Step #0:  ---> 500c1b793e9d\n",
      "Step #0: Step 2/10 : WORKDIR /app\n",
      "Step #0:  ---> Running in ff905a5ab8a2\n",
      "Step #0: Removing intermediate container ff905a5ab8a2\n",
      "Step #0:  ---> b1d9031fec98\n",
      "Step #0: Step 3/10 : COPY requirements.txt .\n",
      "Step #0:  ---> 7a69543d68b6\n",
      "Step #0: Step 4/10 : RUN pip install -U -r requirements.txt\n",
      "Step #0:  ---> Running in 96b7a173718f\n",
      "Step #0: Collecting google-cloud-storage==2.14.0\n",
      "Step #0:   Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 kB 1.4 MB/s eta 0:00:00\n",
      "Step #0: Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "Step #0:   Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.3/138.3 kB 3.7 MB/s eta 0:00:00\n",
      "Step #0: Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "Step #0:   Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Step #0: Collecting google-resumable-media>=2.6.0\n",
      "Step #0:   Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.6/80.6 kB 12.4 MB/s eta 0:00:00\n",
      "Step #0: Collecting google-auth<3.0dev,>=2.23.3\n",
      "Step #0:   Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189.2/189.2 kB 14.7 MB/s eta 0:00:00\n",
      "Step #0: Collecting requests<3.0.0dev,>=2.18.0\n",
      "Step #0:   Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 10.6 MB/s eta 0:00:00\n",
      "Step #0: Collecting google-crc32c<2.0dev,>=1.0\n",
      "Step #0:   Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Step #0: Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5\n",
      "Step #0:   Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 kB 18.7 MB/s eta 0:00:00\n",
      "Step #0: Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "Step #0:   Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.1/229.1 kB 27.4 MB/s eta 0:00:00\n",
      "Step #0: Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "Step #0:   Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.8/48.8 kB 6.9 MB/s eta 0:00:00\n",
      "Step #0: Collecting pyasn1-modules>=0.2.1\n",
      "Step #0:   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 21.4 MB/s eta 0:00:00\n",
      "Step #0: Collecting rsa<5,>=3.1.4\n",
      "Step #0:   Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Step #0: Collecting cachetools<6.0,>=2.0.0\n",
      "Step #0:   Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Step #0: Collecting charset-normalizer<4,>=2\n",
      "Step #0:   Downloading charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.3/142.3 kB 23.4 MB/s eta 0:00:00\n",
      "Step #0: Collecting idna<4,>=2.5\n",
      "Step #0:   Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.6/61.6 kB 9.9 MB/s eta 0:00:00\n",
      "Step #0: Collecting certifi>=2017.4.17\n",
      "Step #0:   Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 22.0 MB/s eta 0:00:00\n",
      "Step #0: Collecting urllib3<3,>=1.21.1\n",
      "Step #0:   Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.1/121.1 kB 20.7 MB/s eta 0:00:00\n",
      "Step #0: Collecting pyasn1<0.6.0,>=0.4.6\n",
      "Step #0:   Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Step #0:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.9/84.9 kB 15.0 MB/s eta 0:00:00\n",
      "Step #0: Installing collected packages: urllib3, pyasn1, protobuf, idna, google-crc32c, charset-normalizer, certifi, cachetools, rsa, requests, pyasn1-modules, proto-plus, googleapis-common-protos, google-resumable-media, google-auth, google-api-core, google-cloud-core, google-cloud-storage\n",
      "Step #0: Successfully installed cachetools-5.3.3 certifi-2024.2.2 charset-normalizer-3.3.2 google-api-core-2.18.0 google-auth-2.29.0 google-cloud-core-2.4.1 google-cloud-storage-2.14.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.63.0 idna-3.6 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-2.31.0 rsa-4.9 urllib3-2.2.1\n",
      "Step #0: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Step #0: \u001b[0m\u001b[91m\n",
      "Step #0: [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "Step #0: [notice] To update, run: pip install --upgrade pip\n",
      "Step #0: \u001b[0mRemoving intermediate container 96b7a173718f\n",
      "Step #0:  ---> e6c775de0c5b\n",
      "Step #0: Step 5/10 : COPY data_ingestion.py /app\n",
      "Step #0:  ---> 4ee181e7b5ed\n",
      "Step #0: Step 6/10 : WORKDIR /app\n",
      "Step #0:  ---> Running in ea5340a80948\n",
      "Step #0: Removing intermediate container ea5340a80948\n",
      "Step #0:  ---> 8e73e18630a8\n",
      "Step #0: Step 7/10 : RUN ls\n",
      "Step #0:  ---> Running in d01698a18eec\n",
      "Step #0: data_ingestion.py\n",
      "Step #0: requirements.txt\n",
      "Step #0: Removing intermediate container d01698a18eec\n",
      "Step #0:  ---> e54777b43be9\n",
      "Step #0: Step 8/10 : RUN pwd\n",
      "Step #0:  ---> Running in 9f3fa67573cf\n",
      "Step #0: /app\n",
      "Step #0: Removing intermediate container 9f3fa67573cf\n",
      "Step #0:  ---> 530a85b57d52\n",
      "Step #0: Step 9/10 : RUN pip list\n",
      "Step #0:  ---> Running in 7cf6073df620\n",
      "Step #0: Package                  Version\n",
      "Step #0: ------------------------ --------\n",
      "Step #0: cachetools               5.3.3\n",
      "Step #0: certifi                  2024.2.2\n",
      "Step #0: charset-normalizer       3.3.2\n",
      "Step #0: google-api-core          2.18.0\n",
      "Step #0: google-auth              2.29.0\n",
      "Step #0: google-cloud-core        2.4.1\n",
      "Step #0: google-cloud-storage     2.14.0\n",
      "Step #0: google-crc32c            1.5.0\n",
      "Step #0: google-resumable-media   2.7.0\n",
      "Step #0: googleapis-common-protos 1.63.0\n",
      "Step #0: idna                     3.6\n",
      "Step #0: pip                      23.0.1\n",
      "Step #0: proto-plus               1.23.0\n",
      "Step #0: protobuf                 4.25.3\n",
      "Step #0: pyasn1                   0.5.1\n",
      "Step #0: pyasn1-modules           0.3.0\n",
      "Step #0: requests                 2.31.0\n",
      "Step #0: rsa                      4.9\n",
      "Step #0: setuptools               58.1.0\n",
      "Step #0: urllib3                  2.2.1\n",
      "Step #0: wheel                    0.43.0\n",
      "Step #0: \u001b[91m\n",
      "Step #0: [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "Step #0: [notice] To update, run: pip install --upgrade pip\n",
      "Step #0: \u001b[0mRemoving intermediate container 7cf6073df620\n",
      "Step #0:  ---> f64ca21793d3\n",
      "Step #0: Step 10/10 : ENTRYPOINT [\"python\"]\n",
      "Step #0:  ---> Running in c6e3df4f6e53\n",
      "Step #0: Removing intermediate container c6e3df4f6e53\n",
      "Step #0:  ---> 79dc95e490a2\n",
      "Step #0: Successfully built 79dc95e490a2\n",
      "Step #0: Successfully tagged gcr.io/able-analyst-416817/gemma-chatbot-data-preparation:latest\n",
      "Finished Step #0\n",
      "Starting Step #1\n",
      "Step #1: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #1: The push refers to repository [gcr.io/able-analyst-416817/gemma-chatbot-data-preparation]\n",
      "Step #1: 08cdb9ddf850: Preparing\n",
      "Step #1: 24e9fabe9d8c: Preparing\n",
      "Step #1: 66aa0a34f30d: Preparing\n",
      "Step #1: e6518b1ff7cc: Preparing\n",
      "Step #1: c8691fa5f753: Preparing\n",
      "Step #1: 5d78e4c3c132: Preparing\n",
      "Step #1: 9138b29cde77: Preparing\n",
      "Step #1: 4c8474755d1b: Preparing\n",
      "Step #1: c8f253aef560: Preparing\n",
      "Step #1: a483da8ab3e9: Preparing\n",
      "Step #1: 5d78e4c3c132: Waiting\n",
      "Step #1: 9138b29cde77: Waiting\n",
      "Step #1: 4c8474755d1b: Waiting\n",
      "Step #1: c8f253aef560: Waiting\n",
      "Step #1: a483da8ab3e9: Waiting\n",
      "Step #1: c8691fa5f753: Pushed\n",
      "Step #1: 08cdb9ddf850: Pushed\n",
      "Step #1: 24e9fabe9d8c: Pushed\n",
      "Step #1: e6518b1ff7cc: Pushed\n",
      "Step #1: 9138b29cde77: Layer already exists\n",
      "Step #1: 5d78e4c3c132: Layer already exists\n",
      "Step #1: 4c8474755d1b: Layer already exists\n",
      "Step #1: c8f253aef560: Layer already exists\n",
      "Step #1: a483da8ab3e9: Layer already exists\n",
      "Step #1: 66aa0a34f30d: Pushed\n",
      "Step #1: latest: digest: sha256:e1d3c297a3452c9f2cc3e10532f9eb859217f9641937d0f083797877ccde3e06 size: 2412\n",
      "Finished Step #1\n",
      "Starting Step #2\n",
      "Step #2: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #2: Sending build context to Docker daemon  71.17kB\n",
      "Step #2: Step 1/12 : FROM us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121.py310\n",
      "Step #2: latest: Pulling from deeplearning-platform-release/gcr.io/base-cu121.py310\n",
      "Step #2: 96d54c3075c9: Already exists\n",
      "Step #2: 755e535b54a3: Pulling fs layer\n",
      "Step #2: 24ff69e0a1e4: Pulling fs layer\n",
      "Step #2: 76a627ca5e65: Pulling fs layer\n",
      "Step #2: 35817692a87e: Pulling fs layer\n",
      "Step #2: 84b6a42e847a: Pulling fs layer\n",
      "Step #2: 4639b7cd68e5: Pulling fs layer\n",
      "Step #2: a7bc10701a5b: Pulling fs layer\n",
      "Step #2: 7d32a9230f8f: Pulling fs layer\n",
      "Step #2: 8c35a1861813: Pulling fs layer\n",
      "Step #2: e3f63d7242f5: Pulling fs layer\n",
      "Step #2: afa75cca3a04: Pulling fs layer\n",
      "Step #2: c1f9e802b8d1: Pulling fs layer\n",
      "Step #2: c6b53aacfed4: Pulling fs layer\n",
      "Step #2: 4f4fb700ef54: Pulling fs layer\n",
      "Step #2: 10fcf6d9a8b1: Pulling fs layer\n",
      "Step #2: bd5512e53c5d: Pulling fs layer\n",
      "Step #2: 50d7191d66bf: Pulling fs layer\n",
      "Step #2: 180a65867fa7: Pulling fs layer\n",
      "Step #2: 7a1daf630b7f: Pulling fs layer\n",
      "Step #2: 20208c43ea0e: Pulling fs layer\n",
      "Step #2: ea960cf75e3a: Pulling fs layer\n",
      "Step #2: dfc4f5a5a8e5: Pulling fs layer\n",
      "Step #2: 3ebdd0bf63e9: Pulling fs layer\n",
      "Step #2: b19c2d4b7a08: Pulling fs layer\n",
      "Step #2: f9c0f83d4666: Pulling fs layer\n",
      "Step #2: d8cb5f186edc: Pulling fs layer\n",
      "Step #2: 7195b2f69d30: Pulling fs layer\n",
      "Step #2: 84f4ed49af3b: Pulling fs layer\n",
      "Step #2: 754279d31ba2: Pulling fs layer\n",
      "Step #2: e5fd8154ec1e: Pulling fs layer\n",
      "Step #2: 064dd4dfd950: Pulling fs layer\n",
      "Step #2: 7ce4912a0f9a: Pulling fs layer\n",
      "Step #2: 2873af0a7328: Pulling fs layer\n",
      "Step #2: 06676754b8b3: Pulling fs layer\n",
      "Step #2: d625375a5d42: Pulling fs layer\n",
      "Step #2: e7c45501f24b: Pulling fs layer\n",
      "Step #2: b4614282a05d: Pulling fs layer\n",
      "Step #2: 35817692a87e: Waiting\n",
      "Step #2: 84b6a42e847a: Waiting\n",
      "Step #2: 4639b7cd68e5: Waiting\n",
      "Step #2: a7bc10701a5b: Waiting\n",
      "Step #2: 7d32a9230f8f: Waiting\n",
      "Step #2: 8c35a1861813: Waiting\n",
      "Step #2: e3f63d7242f5: Waiting\n",
      "Step #2: afa75cca3a04: Waiting\n",
      "Step #2: c1f9e802b8d1: Waiting\n",
      "Step #2: c6b53aacfed4: Waiting\n",
      "Step #2: 4f4fb700ef54: Waiting\n",
      "Step #2: 10fcf6d9a8b1: Waiting\n",
      "Step #2: bd5512e53c5d: Waiting\n",
      "Step #2: 50d7191d66bf: Waiting\n",
      "Step #2: 180a65867fa7: Waiting\n",
      "Step #2: 7a1daf630b7f: Waiting\n",
      "Step #2: 20208c43ea0e: Waiting\n",
      "Step #2: ea960cf75e3a: Waiting\n",
      "Step #2: dfc4f5a5a8e5: Waiting\n",
      "Step #2: 3ebdd0bf63e9: Waiting\n",
      "Step #2: b19c2d4b7a08: Waiting\n",
      "Step #2: f9c0f83d4666: Waiting\n",
      "Step #2: d8cb5f186edc: Waiting\n",
      "Step #2: 7195b2f69d30: Waiting\n",
      "Step #2: 84f4ed49af3b: Waiting\n",
      "Step #2: 754279d31ba2: Waiting\n",
      "Step #2: e5fd8154ec1e: Waiting\n",
      "Step #2: 064dd4dfd950: Waiting\n",
      "Step #2: 7ce4912a0f9a: Waiting\n",
      "Step #2: 2873af0a7328: Waiting\n",
      "Step #2: 06676754b8b3: Waiting\n",
      "Step #2: d625375a5d42: Waiting\n",
      "Step #2: e7c45501f24b: Waiting\n",
      "Step #2: b4614282a05d: Waiting\n",
      "Step #2: 76a627ca5e65: Verifying Checksum\n",
      "Step #2: 76a627ca5e65: Download complete\n",
      "Step #2: 755e535b54a3: Verifying Checksum\n",
      "Step #2: 755e535b54a3: Download complete\n",
      "Step #2: 35817692a87e: Verifying Checksum\n",
      "Step #2: 35817692a87e: Download complete\n",
      "Step #2: 4639b7cd68e5: Verifying Checksum\n",
      "Step #2: 4639b7cd68e5: Download complete\n",
      "Step #2: a7bc10701a5b: Verifying Checksum\n",
      "Step #2: a7bc10701a5b: Download complete\n",
      "Step #2: 24ff69e0a1e4: Verifying Checksum\n",
      "Step #2: 24ff69e0a1e4: Download complete\n",
      "Step #2: 7d32a9230f8f: Verifying Checksum\n",
      "Step #2: 7d32a9230f8f: Download complete\n",
      "Step #2: e3f63d7242f5: Verifying Checksum\n",
      "Step #2: e3f63d7242f5: Download complete\n",
      "Step #2: 755e535b54a3: Pull complete\n",
      "Step #2: 24ff69e0a1e4: Pull complete\n",
      "Step #2: 76a627ca5e65: Pull complete\n",
      "Step #2: 35817692a87e: Pull complete\n",
      "Step #2: 84b6a42e847a: Download complete\n",
      "Step #2: afa75cca3a04: Verifying Checksum\n",
      "Step #2: afa75cca3a04: Download complete\n",
      "Step #2: c6b53aacfed4: Verifying Checksum\n",
      "Step #2: c6b53aacfed4: Download complete\n",
      "Step #2: 4f4fb700ef54: Verifying Checksum\n",
      "Step #2: 4f4fb700ef54: Download complete\n",
      "Step #2: 10fcf6d9a8b1: Verifying Checksum\n",
      "Step #2: 10fcf6d9a8b1: Download complete\n",
      "Step #2: bd5512e53c5d: Verifying Checksum\n",
      "Step #2: bd5512e53c5d: Download complete\n",
      "Step #2: 50d7191d66bf: Verifying Checksum\n",
      "Step #2: 50d7191d66bf: Download complete\n",
      "Step #2: 180a65867fa7: Verifying Checksum\n",
      "Step #2: 180a65867fa7: Download complete\n",
      "Step #2: 7a1daf630b7f: Verifying Checksum\n",
      "Step #2: 7a1daf630b7f: Download complete\n",
      "Step #2: 20208c43ea0e: Download complete\n",
      "Step #2: ea960cf75e3a: Verifying Checksum\n",
      "Step #2: ea960cf75e3a: Download complete\n",
      "Step #2: dfc4f5a5a8e5: Download complete\n",
      "Step #2: 3ebdd0bf63e9: Verifying Checksum\n",
      "Step #2: 3ebdd0bf63e9: Download complete\n",
      "Step #2: 8c35a1861813: Verifying Checksum\n",
      "Step #2: 8c35a1861813: Download complete\n",
      "Step #2: b19c2d4b7a08: Verifying Checksum\n",
      "Step #2: b19c2d4b7a08: Download complete\n",
      "Step #2: d8cb5f186edc: Verifying Checksum\n",
      "Step #2: d8cb5f186edc: Download complete\n",
      "Step #2: f9c0f83d4666: Verifying Checksum\n",
      "Step #2: f9c0f83d4666: Download complete\n",
      "Step #2: 7195b2f69d30: Verifying Checksum\n",
      "Step #2: 7195b2f69d30: Download complete\n",
      "Step #2: 84f4ed49af3b: Verifying Checksum\n",
      "Step #2: 84f4ed49af3b: Download complete\n",
      "Step #2: 754279d31ba2: Verifying Checksum\n",
      "Step #2: 754279d31ba2: Download complete\n",
      "Step #2: e5fd8154ec1e: Verifying Checksum\n",
      "Step #2: e5fd8154ec1e: Download complete\n",
      "Step #2: 064dd4dfd950: Verifying Checksum\n",
      "Step #2: 064dd4dfd950: Download complete\n",
      "Step #2: 7ce4912a0f9a: Verifying Checksum\n",
      "Step #2: 7ce4912a0f9a: Download complete\n",
      "Step #2: 2873af0a7328: Verifying Checksum\n",
      "Step #2: 2873af0a7328: Download complete\n",
      "Step #2: d625375a5d42: Verifying Checksum\n",
      "Step #2: d625375a5d42: Download complete\n",
      "Step #2: e7c45501f24b: Verifying Checksum\n",
      "Step #2: e7c45501f24b: Download complete\n",
      "Step #2: b4614282a05d: Verifying Checksum\n",
      "Step #2: b4614282a05d: Download complete\n",
      "Step #2: c1f9e802b8d1: Verifying Checksum\n",
      "Step #2: c1f9e802b8d1: Download complete\n",
      "Step #2: 06676754b8b3: Verifying Checksum\n",
      "Step #2: 06676754b8b3: Download complete\n",
      "Step #2: 84b6a42e847a: Pull complete\n",
      "Step #2: 4639b7cd68e5: Pull complete\n",
      "Step #2: a7bc10701a5b: Pull complete\n",
      "Step #2: 7d32a9230f8f: Pull complete\n",
      "Step #2: 8c35a1861813: Pull complete\n",
      "Step #2: e3f63d7242f5: Pull complete\n",
      "Step #2: afa75cca3a04: Pull complete\n",
      "Step #2: c1f9e802b8d1: Pull complete\n",
      "Step #2: c6b53aacfed4: Pull complete\n",
      "Step #2: 4f4fb700ef54: Pull complete\n",
      "Step #2: 10fcf6d9a8b1: Pull complete\n",
      "Step #2: bd5512e53c5d: Pull complete\n",
      "Step #2: 50d7191d66bf: Pull complete\n",
      "Step #2: 180a65867fa7: Pull complete\n",
      "Step #2: 7a1daf630b7f: Pull complete\n",
      "Step #2: 20208c43ea0e: Pull complete\n",
      "Step #2: ea960cf75e3a: Pull complete\n",
      "Step #2: dfc4f5a5a8e5: Pull complete\n",
      "Step #2: 3ebdd0bf63e9: Pull complete\n",
      "Step #2: b19c2d4b7a08: Pull complete\n",
      "Step #2: f9c0f83d4666: Pull complete\n",
      "Step #2: d8cb5f186edc: Pull complete\n",
      "Step #2: 7195b2f69d30: Pull complete\n",
      "Step #2: 84f4ed49af3b: Pull complete\n",
      "Step #2: 754279d31ba2: Pull complete\n",
      "Step #2: e5fd8154ec1e: Pull complete\n",
      "Step #2: 064dd4dfd950: Pull complete\n",
      "Step #2: 7ce4912a0f9a: Pull complete\n",
      "Step #2: 2873af0a7328: Pull complete\n",
      "Step #2: 06676754b8b3: Pull complete\n",
      "Step #2: d625375a5d42: Pull complete\n",
      "Step #2: e7c45501f24b: Pull complete\n",
      "Step #2: b4614282a05d: Pull complete\n",
      "Step #2: Digest: sha256:a0d3c16c924fdda8134fb4a29a3f491208189d99590a04643abb34e72108752a\n",
      "Step #2: Status: Downloaded newer image for us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121.py310:latest\n",
      "Step #2:  ---> f04ebe26fc76\n",
      "Step #2: Step 2/12 : WORKDIR /trainer\n",
      "Step #2:  ---> Running in b7515d4ecf4c\n",
      "Step #2: Removing intermediate container b7515d4ecf4c\n",
      "Step #2:  ---> 1b66fd40c7d9\n",
      "Step #2: Step 3/12 : COPY requirements.txt .\n",
      "Step #2:  ---> 49eef3273d7f\n",
      "Step #2: Step 4/12 : RUN pip install -U -r requirements.txt\n",
      "Step #2:  ---> Running in d300deafce09\n",
      "Step #2: Collecting keras-nlp==0.8.2 (from -r requirements.txt (line 3))\n",
      "Step #2:   Downloading keras_nlp-0.8.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Step #2: Collecting keras==3.0.5 (from -r requirements.txt (line 4))\n",
      "Step #2:   Downloading keras-3.0.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "Step #2: Collecting accelerate (from -r requirements.txt (line 5))\n",
      "Step #2:   Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Step #2: Collecting sentencepiece (from -r requirements.txt (line 6))\n",
      "Step #2:   Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Step #2: Collecting transformers==4.38 (from -r requirements.txt (line 7))\n",
      "Step #2:   Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
      "Step #2:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.1/131.1 kB 1.7 MB/s eta 0:00:00\n",
      "Step #2: Collecting fire==0.6.0 (from -r requirements.txt (line 8))\n",
      "Step #2:   Downloading fire-0.6.0.tar.gz (88 kB)\n",
      "Step #2:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.4/88.4 kB 7.3 MB/s eta 0:00:00\n",
      "Step #2:   Preparing metadata (setup.py): started\n",
      "Step #2:   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #2: Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (2.14.0)\n",
      "Step #2: Collecting google-cloud-storage (from -r requirements.txt (line 9))\n",
      "Step #2:   Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Step #2: Collecting keras-core (from keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
      "Step #2: Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (2.1.0)\n",
      "Step #2: Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (1.25.2)\n",
      "Step #2: Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (23.2)\n",
      "Step #2: Collecting regex (from keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Step #2:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 3.9 MB/s eta 0:00:00\n",
      "Step #2: Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (13.7.1)\n",
      "Step #2: Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-nlp==0.8.2->-r requirements.txt (line 3)) (0.1.8)\n",
      "Step #2: Collecting kagglehub (from keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading kagglehub-0.2.1-py3-none-any.whl.metadata (18 kB)\n",
      "Step #2: Collecting tensorflow-text (from keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Step #2: Collecting namex (from keras==3.0.5->-r requirements.txt (line 4))\n",
      "Step #2:   Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Step #2: Collecting h5py (from keras==3.0.5->-r requirements.txt (line 4))\n",
      "Step #2:   Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Step #2: Collecting ml-dtypes (from keras==3.0.5->-r requirements.txt (line 4))\n",
      "Step #2:   Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Step #2: Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38->-r requirements.txt (line 7)) (3.13.1)\n",
      "Step #2: Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.38->-r requirements.txt (line 7))\n",
      "Step #2:   Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Step #2: Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38->-r requirements.txt (line 7)) (6.0.1)\n",
      "Step #2: Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38->-r requirements.txt (line 7)) (2.31.0)\n",
      "Step #2: Collecting tokenizers<0.19,>=0.14 (from transformers==4.38->-r requirements.txt (line 7))\n",
      "Step #2:   Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Step #2: Collecting safetensors>=0.4.1 (from transformers==4.38->-r requirements.txt (line 7))\n",
      "Step #2:   Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Step #2: Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38->-r requirements.txt (line 7)) (4.66.2)\n",
      "Step #2: Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire==0.6.0->-r requirements.txt (line 8)) (1.16.0)\n",
      "Step #2: Collecting termcolor (from fire==0.6.0->-r requirements.txt (line 8))\n",
      "Step #2:   Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Step #2: Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 5)) (5.9.3)\n",
      "Step #2: Collecting torch>=1.10.0 (from accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Step #2: Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r requirements.txt (line 9)) (2.28.1)\n",
      "Step #2: Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage->-r requirements.txt (line 9))\n",
      "Step #2:   Downloading google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Step #2: Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r requirements.txt (line 9)) (2.4.1)\n",
      "Step #2: Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r requirements.txt (line 9)) (2.7.0)\n",
      "Step #2: Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r requirements.txt (line 9)) (1.5.0)\n",
      "Step #2: Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->-r requirements.txt (line 9)) (1.62.0)\n",
      "Step #2: Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->-r requirements.txt (line 9)) (3.20.3)\n",
      "Step #2: Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->-r requirements.txt (line 9)) (1.23.0)\n",
      "Step #2: Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r requirements.txt (line 9)) (5.3.3)\n",
      "Step #2: Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r requirements.txt (line 9)) (0.3.0)\n",
      "Step #2: Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r requirements.txt (line 9)) (4.9)\n",
      "Step #2: Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38->-r requirements.txt (line 7)) (2024.2.0)\n",
      "Step #2: Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38->-r requirements.txt (line 7)) (4.10.0)\n",
      "Step #2: Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38->-r requirements.txt (line 7)) (3.3.2)\n",
      "Step #2: Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38->-r requirements.txt (line 7)) (3.6)\n",
      "Step #2: Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38->-r requirements.txt (line 7)) (1.26.18)\n",
      "Step #2: Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38->-r requirements.txt (line 7)) (2024.2.2)\n",
      "Step #2: Collecting sympy (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Step #2: Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 5)) (3.2.1)\n",
      "Step #2: Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 5)) (3.1.3)\n",
      "Step #2: Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Step #2: Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Step #2: Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Step #2: Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Step #2: Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Step #2: Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Step #2: Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Step #2: Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Step #2: Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Step #2: Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Step #2: Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Step #2: Collecting triton==2.2.0 (from torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Step #2: Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Step #2: Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp==0.8.2->-r requirements.txt (line 3)) (3.0.0)\n",
      "Step #2: Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp==0.8.2->-r requirements.txt (line 3)) (2.17.2)\n",
      "Step #2: Collecting tensorflow<2.17,>=2.16.1 (from tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Step #2: Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-nlp==0.8.2->-r requirements.txt (line 3)) (0.1.2)\n",
      "Step #2: Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r requirements.txt (line 9)) (0.5.1)\n",
      "Step #2: Collecting astunparse>=1.6.0 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Step #2: Collecting flatbuffers>=23.5.26 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading flatbuffers-24.3.7-py2.py3-none-any.whl.metadata (849 bytes)\n",
      "Step #2: Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Step #2: Collecting google-pasta>=0.1.1 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Step #2: Collecting libclang>=13.0.0 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Step #2: Collecting opt-einsum>=2.3.2 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Step #2: Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (69.1.1)\n",
      "Step #2: Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (1.16.0)\n",
      "Step #2: Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (1.62.0)\n",
      "Step #2: Collecting tensorboard<2.17,>=2.16 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Step #2: Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Step #2: Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate->-r requirements.txt (line 5)) (2.1.5)\n",
      "Step #2: Collecting mpmath>=0.19 (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 5))\n",
      "Step #2:   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Step #2: Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3)) (0.42.0)\n",
      "Step #2: Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Step #2: Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Step #2: Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp==0.8.2->-r requirements.txt (line 3))\n",
      "Step #2:   Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Step #2: Downloading keras_nlp-0.8.2-py3-none-any.whl (465 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 465.3/465.3 kB 7.4 MB/s eta 0:00:00\n",
      "Step #2: Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 20.6 MB/s eta 0:00:00\n",
      "Step #2: Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 48.8 MB/s eta 0:00:00\n",
      "Step #2: Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 290.1/290.1 kB 29.4 MB/s eta 0:00:00\n",
      "Step #2: Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 68.0 MB/s eta 0:00:00\n",
      "Step #2: Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.6/125.6 kB 14.1 MB/s eta 0:00:00\n",
      "Step #2: Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.3/138.3 kB 14.8 MB/s eta 0:00:00\n",
      "Step #2: Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 346.4/346.4 kB 31.3 MB/s eta 0:00:00\n",
      "Step #2: Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 774.0/774.0 kB 45.7 MB/s eta 0:00:00\n",
      "Step #2: Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 60.5 MB/s eta 0:00:00\n",
      "Step #2: Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 66.7 MB/s eta 0:00:00\n",
      "Step #2: Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 755.5/755.5 MB 1.4 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 2.2 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 2.9 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 3.9 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 3.9 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 731.7/731.7 MB 1.5 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 3.1 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 3.9 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 2.6 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 1.9 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 166.0/166.0 MB 2.9 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 kB 3.3 MB/s eta 0:00:00\n",
      "Step #2: Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.9/167.9 MB 2.2 MB/s eta 0:00:00\n",
      "Step #2: Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 2.9 MB/s eta 0:00:00\n",
      "Step #2: Downloading kagglehub-0.2.1-py3-none-any.whl (32 kB)\n",
      "Step #2: Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 950.8/950.8 kB 2.8 MB/s eta 0:00:00\n",
      "Step #2: Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 3.1 MB/s eta 0:00:00\n",
      "Step #2: Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Step #2: Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 3.8 MB/s eta 0:00:00\n",
      "Step #2: Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Step #2: Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 589.8/589.8 MB 1.6 MB/s eta 0:00:00\n",
      "Step #2: Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 3.1 MB/s eta 0:00:00\n",
      "Step #2: Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Step #2: Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Step #2: Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Step #2: Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 2.6 MB/s eta 0:00:00\n",
      "Step #2: Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.5/24.5 MB 3.0 MB/s eta 0:00:00\n",
      "Step #2: Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 3.4 MB/s eta 0:00:00\n",
      "Step #2: Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 2.8 MB/s eta 0:00:00\n",
      "Step #2: Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 3.7 MB/s eta 0:00:00\n",
      "Step #2: Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 3.8 MB/s eta 0:00:00\n",
      "Step #2: Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 4.1 MB/s eta 0:00:00\n",
      "Step #2: Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.4/105.4 kB 4.4 MB/s eta 0:00:00\n",
      "Step #2: Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 5.2 MB/s eta 0:00:00\n",
      "Step #2: Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Step #2:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.7/226.7 kB 4.7 MB/s eta 0:00:00\n",
      "Step #2: Building wheels for collected packages: fire\n",
      "Step #2:   Building wheel for fire (setup.py): started\n",
      "Step #2:   Building wheel for fire (setup.py): finished with status 'done'\n",
      "Step #2:   Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=7971b84d11dca654b9701b8c208f7a5eddabf3a880f23ccb46279fcf1cf07221\n",
      "Step #2:   Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
      "Step #2: Successfully built fire\n",
      "Step #2: Installing collected packages: sentencepiece, namex, mpmath, libclang, flatbuffers, werkzeug, triton, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, sympy, safetensors, regex, opt-einsum, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, markdown, h5py, google-pasta, gast, astunparse, tensorboard, nvidia-cusparse-cu12, nvidia-cudnn-cu12, kagglehub, huggingface-hub, fire, tokenizers, nvidia-cusolver-cu12, keras-core, keras, google-api-core, transformers, torch, tensorflow, tensorflow-text, google-cloud-storage, accelerate, keras-nlp\n",
      "Step #2:   Attempting uninstall: google-api-core\n",
      "Step #2:     Found existing installation: google-api-core 1.34.1\n",
      "Step #2:     Uninstalling google-api-core-1.34.1:\n",
      "Step #2:       Successfully uninstalled google-api-core-1.34.1\n",
      "Step #2:   Attempting uninstall: google-cloud-storage\n",
      "Step #2:     Found existing installation: google-cloud-storage 2.14.0\n",
      "Step #2:     Uninstalling google-cloud-storage-2.14.0:\n",
      "Step #2:       Successfully uninstalled google-cloud-storage-2.14.0\n",
      "Step #2: \u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "Step #2: google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.18.0 which is incompatible.\n",
      "Step #2: \u001b[0mSuccessfully installed accelerate-0.28.0 astunparse-1.6.3 fire-0.6.0 flatbuffers-24.3.7 gast-0.5.4 google-api-core-2.18.0 google-cloud-storage-2.16.0 google-pasta-0.2.0 h5py-3.10.0 huggingface-hub-0.21.4 kagglehub-0.2.1 keras-3.0.5 keras-core-0.1.7 keras-nlp-0.8.2 libclang-18.1.1 markdown-3.6 ml-dtypes-0.3.2 mpmath-1.3.0 namex-0.0.7 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 opt-einsum-3.3.0 regex-2023.12.25 safetensors-0.4.2 sentencepiece-0.2.0 sympy-1.12 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 tensorflow-text-2.16.1 termcolor-2.4.0 tokenizers-0.15.2 torch-2.2.1 transformers-4.38.0 triton-2.2.0 werkzeug-3.0.1\n",
      "Step #2: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Step #2: \u001b[0mRemoving intermediate container d300deafce09\n",
      "Step #2:  ---> 73a9a84780c3\n",
      "Step #2: Step 5/12 : ARG KAGGLE_USERNAME\n",
      "Step #2:  ---> Running in e53193711aee\n",
      "Step #2: Removing intermediate container e53193711aee\n",
      "Step #2:  ---> 8996d1c63e93\n",
      "Step #2: Step 6/12 : ENV KAGGLE_USERNAME=$KAGGLE_USERNAME\n",
      "Step #2:  ---> Running in 30696689b094\n",
      "Step #2: Removing intermediate container 30696689b094\n",
      "Step #2:  ---> 8be3abfcbe6d\n",
      "Step #2: Step 7/12 : ARG KAGGLE_KEY\n",
      "Step #2:  ---> Running in 9d6bfc2d96a0\n",
      "Step #2: Removing intermediate container 9d6bfc2d96a0\n",
      "Step #2:  ---> 1d0f739edc42\n",
      "Step #2: Step 8/12 : ENV KAGGLE_KEY=$KAGGLE_KEY\n",
      "Step #2:  ---> Running in ad8405bea086\n",
      "Step #2: Removing intermediate container ad8405bea086\n",
      "Step #2:  ---> 2cb9959455ed\n",
      "Step #2: Step 9/12 : COPY . /trainer\n",
      "Step #2:  ---> 6ed82eba81bf\n",
      "Step #2: Step 10/12 : WORKDIR /trainer\n",
      "Step #2:  ---> Running in c7d9a30c5407\n",
      "Step #2: Removing intermediate container c7d9a30c5407\n",
      "Step #2:  ---> 3156ebd99930\n",
      "Step #2: Step 11/12 : RUN ls\n",
      "Step #2:  ---> Running in 0f7238e87f16\n",
      "Step #2: Dockerfile\n",
      "Step #2: __pycache__\n",
      "Step #2: cloudbuild.yaml\n",
      "Step #2: conversion_function.py\n",
      "Step #2: export_gemma_to_hf.py\n",
      "Step #2: requirements.txt\n",
      "Step #2: trainer.py\n",
      "Step #2: util.py\n",
      "Step #2: Removing intermediate container 0f7238e87f16\n",
      "Step #2:  ---> 1d400f49b44a\n",
      "Step #2: Step 12/12 : ENTRYPOINT [\"python\"]\n",
      "Step #2:  ---> Running in 873ef0f226b1\n",
      "Step #2: Removing intermediate container 873ef0f226b1\n",
      "Step #2:  ---> 263361a7c721\n",
      "Step #2: Successfully built 263361a7c721\n",
      "Step #2: Successfully tagged gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning:latest\n",
      "Finished Step #2\n",
      "Starting Step #3\n",
      "Step #3: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #3: The push refers to repository [gcr.io/able-analyst-416817/gemma-chatbot-fine-tunning]\n",
      "Step #3: 397279667c9e: Preparing\n",
      "Step #3: fa48e6ce4298: Preparing\n",
      "Step #3: ba9ee641cb91: Preparing\n",
      "Step #3: 5c12a6f8e5cd: Preparing\n",
      "Step #3: 9deb6fc54da9: Preparing\n",
      "Step #3: 6931085b550f: Preparing\n",
      "Step #3: c230b525aedf: Preparing\n",
      "Step #3: 5f70bf18a086: Preparing\n",
      "Step #3: c57ef954d51d: Preparing\n",
      "Step #3: b831d1fa39bf: Preparing\n",
      "Step #3: 4520767ffc08: Preparing\n",
      "Step #3: 09d837e2554d: Preparing\n",
      "Step #3: 6e3d09f63d7a: Preparing\n",
      "Step #3: d3135376200a: Preparing\n",
      "Step #3: e76fa06cba23: Preparing\n",
      "Step #3: 46b83560dec5: Preparing\n",
      "Step #3: 51029eb3efd6: Preparing\n",
      "Step #3: b32920786550: Preparing\n",
      "Step #3: 0430b0b45ba7: Preparing\n",
      "Step #3: cd26331ad5b3: Preparing\n",
      "Step #3: 8e74dfc7859c: Preparing\n",
      "Step #3: b81e99c9fcc3: Preparing\n",
      "Step #3: 4e3c3f15a9b6: Preparing\n",
      "Step #3: 457986848246: Preparing\n",
      "Step #3: cbf3c905e2e1: Preparing\n",
      "Step #3: da817efd0bfb: Preparing\n",
      "Step #3: 2f41ef0e83a0: Preparing\n",
      "Step #3: 52248bbcc0bc: Preparing\n",
      "Step #3: 5f70bf18a086: Preparing\n",
      "Step #3: 537816d7f4e1: Preparing\n",
      "Step #3: f158d4b2b4b4: Preparing\n",
      "Step #3: e7bf000641e2: Preparing\n",
      "Step #3: d7d705e1decf: Preparing\n",
      "Step #3: 2227317d988c: Preparing\n",
      "Step #3: 50bceba2b2b7: Preparing\n",
      "Step #3: 40fc5e6cc198: Preparing\n",
      "Step #3: 889402d51413: Preparing\n",
      "Step #3: 284c466ee6ce: Preparing\n",
      "Step #3: 1ff8f721b9db: Preparing\n",
      "Step #3: 1eeecbd4dbae: Preparing\n",
      "Step #3: 35d40f4df845: Preparing\n",
      "Step #3: 2651516ff8de: Preparing\n",
      "Step #3: 6c3e7df31590: Preparing\n",
      "Step #3: 4e3c3f15a9b6: Waiting\n",
      "Step #3: 457986848246: Waiting\n",
      "Step #3: cbf3c905e2e1: Waiting\n",
      "Step #3: da817efd0bfb: Waiting\n",
      "Step #3: 2f41ef0e83a0: Waiting\n",
      "Step #3: 52248bbcc0bc: Waiting\n",
      "Step #3: 537816d7f4e1: Waiting\n",
      "Step #3: f158d4b2b4b4: Waiting\n",
      "Step #3: e7bf000641e2: Waiting\n",
      "Step #3: d7d705e1decf: Waiting\n",
      "Step #3: 2227317d988c: Waiting\n",
      "Step #3: 50bceba2b2b7: Waiting\n",
      "Step #3: 40fc5e6cc198: Waiting\n",
      "Step #3: 889402d51413: Waiting\n",
      "Step #3: 284c466ee6ce: Waiting\n",
      "Step #3: 6931085b550f: Waiting\n",
      "Step #3: c230b525aedf: Waiting\n",
      "Step #3: 5f70bf18a086: Waiting\n",
      "Step #3: c57ef954d51d: Waiting\n",
      "Step #3: b831d1fa39bf: Waiting\n",
      "Step #3: 4520767ffc08: Waiting\n",
      "Step #3: 09d837e2554d: Waiting\n",
      "Step #3: 6e3d09f63d7a: Waiting\n",
      "Step #3: d3135376200a: Waiting\n",
      "Step #3: e76fa06cba23: Waiting\n",
      "Step #3: 46b83560dec5: Waiting\n",
      "Step #3: 51029eb3efd6: Waiting\n",
      "Step #3: b32920786550: Waiting\n",
      "Step #3: 0430b0b45ba7: Waiting\n",
      "Step #3: cd26331ad5b3: Waiting\n",
      "Step #3: 8e74dfc7859c: Waiting\n",
      "Step #3: b81e99c9fcc3: Waiting\n",
      "Step #3: 1ff8f721b9db: Waiting\n",
      "Step #3: 1eeecbd4dbae: Waiting\n",
      "Step #3: 35d40f4df845: Waiting\n",
      "Step #3: 2651516ff8de: Waiting\n",
      "Step #3: 6c3e7df31590: Waiting\n",
      "Step #3: 9deb6fc54da9: Layer already exists\n",
      "Step #3: 6931085b550f: Layer already exists\n",
      "Step #3: c230b525aedf: Layer already exists\n",
      "Step #3: ba9ee641cb91: Pushed\n",
      "Step #3: 5c12a6f8e5cd: Pushed\n",
      "Step #3: 5f70bf18a086: Layer already exists\n",
      "Step #3: 397279667c9e: Pushed\n",
      "Step #3: c57ef954d51d: Layer already exists\n",
      "Step #3: 4520767ffc08: Layer already exists\n",
      "Step #3: b831d1fa39bf: Layer already exists\n",
      "Step #3: 09d837e2554d: Layer already exists\n",
      "Step #3: d3135376200a: Layer already exists\n",
      "Step #3: 6e3d09f63d7a: Layer already exists\n",
      "Step #3: e76fa06cba23: Layer already exists\n",
      "Step #3: 46b83560dec5: Layer already exists\n",
      "Step #3: 0430b0b45ba7: Layer already exists\n",
      "Step #3: b32920786550: Layer already exists\n",
      "Step #3: 51029eb3efd6: Layer already exists\n",
      "Step #3: cd26331ad5b3: Layer already exists\n",
      "Step #3: b81e99c9fcc3: Layer already exists\n",
      "Step #3: 8e74dfc7859c: Layer already exists\n",
      "Step #3: 4e3c3f15a9b6: Layer already exists\n",
      "Step #3: 457986848246: Layer already exists\n",
      "Step #3: cbf3c905e2e1: Layer already exists\n",
      "Step #3: da817efd0bfb: Layer already exists\n",
      "Step #3: 52248bbcc0bc: Layer already exists\n",
      "Step #3: 2f41ef0e83a0: Layer already exists\n",
      "Step #3: 537816d7f4e1: Layer already exists\n",
      "Step #3: e7bf000641e2: Layer already exists\n",
      "Step #3: d7d705e1decf: Layer already exists\n",
      "Step #3: f158d4b2b4b4: Layer already exists\n",
      "Step #3: 40fc5e6cc198: Layer already exists\n",
      "Step #3: 50bceba2b2b7: Layer already exists\n",
      "Step #3: 2227317d988c: Layer already exists\n",
      "Step #3: 889402d51413: Layer already exists\n",
      "Step #3: 284c466ee6ce: Layer already exists\n",
      "Step #3: 1ff8f721b9db: Layer already exists\n",
      "Step #3: 35d40f4df845: Layer already exists\n",
      "Step #3: 1eeecbd4dbae: Layer already exists\n",
      "Step #3: 2651516ff8de: Layer already exists\n",
      "Step #3: 6c3e7df31590: Layer already exists\n",
      "Step #3: fa48e6ce4298: Pushed\n",
      "Step #3: latest: digest: sha256:a69e24cd752ce39f7097755744ce4f425e0ec3cfafb9fc953fe035bf35470fb2 size: 9326\n",
      "Finished Step #3\n",
      "Starting Step #4\n",
      "Step #4: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #4: Sending build context to Docker daemon  44.03kB\n",
      "Step #4: Step 1/10 : FROM python:3.9-slim\n",
      "Step #4:  ---> 500c1b793e9d\n",
      "Step #4: Step 2/10 : WORKDIR /pipeline\n",
      "Step #4:  ---> Running in b92dddef8a6c\n",
      "Step #4: Removing intermediate container b92dddef8a6c\n",
      "Step #4:  ---> 487ff186af76\n",
      "Step #4: Step 3/10 : RUN ls\n",
      "Step #4:  ---> Running in 80494394d417\n",
      "Step #4: Removing intermediate container 80494394d417\n",
      "Step #4:  ---> db4d5c91e847\n",
      "Step #4: Step 4/10 : COPY requirements.txt .\n",
      "Step #4:  ---> e836d12fe0f1\n",
      "Step #4: Step 5/10 : RUN pip install -U -r requirements.txt\n",
      "Step #4:  ---> Running in 4a103408dc5a\n",
      "Step #4: Collecting kfp\n",
      "Step #4:   Downloading kfp-2.7.0.tar.gz (441 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 441.8/441.8 kB 3.2 MB/s eta 0:00:00\n",
      "Step #4:   Preparing metadata (setup.py): started\n",
      "Step #4:   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #4: Collecting google-cloud-aiplatform\n",
      "Step #4:   Downloading google_cloud_aiplatform-1.44.0-py2.py3-none-any.whl (4.2 MB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.2/4.2 MB 26.9 MB/s eta 0:00:00\n",
      "Step #4: Collecting google-cloud-pipeline-components\n",
      "Step #4:   Downloading google_cloud_pipeline_components-2.11.0-py3-none-any.whl (1.4 MB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 62.1 MB/s eta 0:00:00\n",
      "Step #4: Collecting click<9,>=8.0.0\n",
      "Step #4:   Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 12.3 MB/s eta 0:00:00\n",
      "Step #4: Collecting docstring-parser<1,>=0.7.3\n",
      "Step #4:   Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Step #4: Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "Step #4:   Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.3/138.3 kB 17.8 MB/s eta 0:00:00\n",
      "Step #4: Collecting google-auth<3,>=1.6.1\n",
      "Step #4:   Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189.2/189.2 kB 25.8 MB/s eta 0:00:00\n",
      "Step #4: Collecting google-cloud-storage<3,>=2.2.1\n",
      "Step #4:   Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.6/125.6 kB 18.6 MB/s eta 0:00:00\n",
      "Step #4: Collecting kfp-pipeline-spec==0.3.0\n",
      "Step #4:   Downloading kfp_pipeline_spec-0.3.0-py3-none-any.whl (12 kB)\n",
      "Step #4: Collecting kfp-server-api<2.1.0,>=2.0.0\n",
      "Step #4:   Downloading kfp-server-api-2.0.5.tar.gz (63 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.4/63.4 kB 10.4 MB/s eta 0:00:00\n",
      "Step #4:   Preparing metadata (setup.py): started\n",
      "Step #4:   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #4: Collecting kubernetes<27,>=8.0.0\n",
      "Step #4:   Downloading kubernetes-26.1.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 60.4 MB/s eta 0:00:00\n",
      "Step #4: Collecting protobuf<5,>=4.21.1\n",
      "Step #4:   Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 kB 36.4 MB/s eta 0:00:00\n",
      "Step #4: Collecting PyYAML<7,>=5.3\n",
      "Step #4:   Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 738.9/738.9 kB 48.0 MB/s eta 0:00:00\n",
      "Step #4: Collecting requests-toolbelt<1,>=0.8.0\n",
      "Step #4:   Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 9.5 MB/s eta 0:00:00\n",
      "Step #4: Collecting tabulate<1,>=0.8.6\n",
      "Step #4:   Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Step #4: Collecting urllib3<2.0.0\n",
      "Step #4:   Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.8/143.8 kB 3.0 MB/s eta 0:00:00\n",
      "Step #4: Collecting packaging>=14.3\n",
      "Step #4:   Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.5/53.5 kB 7.7 MB/s eta 0:00:00\n",
      "Step #4: Collecting shapely<3.0.0dev\n",
      "Step #4:   Downloading shapely-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 70.6 MB/s eta 0:00:00\n",
      "Step #4: Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "Step #4:   Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.8/48.8 kB 8.1 MB/s eta 0:00:00\n",
      "Step #4: Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "Step #4:   Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 333.7/333.7 kB 36.1 MB/s eta 0:00:00\n",
      "Step #4: Collecting google-cloud-bigquery<4.0.0dev,>=1.15.0\n",
      "Step #4:   Downloading google_cloud_bigquery-3.19.0-py2.py3-none-any.whl (232 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.6/232.6 kB 30.1 MB/s eta 0:00:00\n",
      "Step #4: Collecting Jinja2<4,>=3.1.2\n",
      "Step #4:   Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.2/133.2 kB 16.7 MB/s eta 0:00:00\n",
      "Step #4: Collecting requests<3.0.0.dev0,>=2.18.0\n",
      "Step #4:   Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 10.1 MB/s eta 0:00:00\n",
      "Step #4: Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "Step #4:   Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.1/229.1 kB 28.2 MB/s eta 0:00:00\n",
      "Step #4: Collecting grpcio<2.0dev,>=1.33.2\n",
      "Step #4:   Downloading grpcio-1.62.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 54.5 MB/s eta 0:00:00\n",
      "Step #4: Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "Step #4:   Downloading grpcio_status-1.62.1-py3-none-any.whl (14 kB)\n",
      "Step #4: Collecting cachetools<6.0,>=2.0.0\n",
      "Step #4:   Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Step #4: Collecting rsa<5,>=3.1.4\n",
      "Step #4:   Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Step #4: Collecting pyasn1-modules>=0.2.1\n",
      "Step #4:   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 20.3 MB/s eta 0:00:00\n",
      "Step #4: Collecting python-dateutil<3.0dev,>=2.7.2\n",
      "Step #4:   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 30.0 MB/s eta 0:00:00\n",
      "Step #4: Collecting google-cloud-core<3.0.0dev,>=1.6.0\n",
      "Step #4:   Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Step #4: Collecting google-resumable-media<3.0dev,>=0.6.0\n",
      "Step #4:   Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.6/80.6 kB 13.5 MB/s eta 0:00:00\n",
      "Step #4: Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "Step #4:   Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Step #4: Collecting google-crc32c<2.0dev,>=1.0\n",
      "Step #4:   Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Step #4: Collecting MarkupSafe>=2.0\n",
      "Step #4:   Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Step #4: Collecting six>=1.10\n",
      "Step #4:   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Step #4: Collecting certifi\n",
      "Step #4:   Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 23.3 MB/s eta 0:00:00\n",
      "Step #4: Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.9/site-packages (from kubernetes<27,>=8.0.0->kfp->-r requirements.txt (line 1)) (58.1.0)\n",
      "Step #4: Collecting requests-oauthlib\n",
      "Step #4:   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Step #4: Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "Step #4:   Downloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.5/58.5 kB 8.8 MB/s eta 0:00:00\n",
      "Step #4: Collecting numpy<2,>=1.14\n",
      "Step #4:   Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 44.4 MB/s eta 0:00:00\n",
      "Step #4: Collecting pyasn1<0.6.0,>=0.4.6\n",
      "Step #4:   Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.9/84.9 kB 13.0 MB/s eta 0:00:00\n",
      "Step #4: Collecting idna<4,>=2.5\n",
      "Step #4:   Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.6/61.6 kB 10.3 MB/s eta 0:00:00\n",
      "Step #4: Collecting charset-normalizer<4,>=2\n",
      "Step #4:   Downloading charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.3/142.3 kB 21.5 MB/s eta 0:00:00\n",
      "Step #4: Collecting oauthlib>=3.0.0\n",
      "Step #4:   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Step #4:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 21.7 MB/s eta 0:00:00\n",
      "Step #4: Building wheels for collected packages: kfp, kfp-server-api\n",
      "Step #4:   Building wheel for kfp (setup.py): started\n",
      "Step #4:   Building wheel for kfp (setup.py): finished with status 'done'\n",
      "Step #4:   Created wheel for kfp: filename=kfp-2.7.0-py3-none-any.whl size=610438 sha256=4abd35e8fcd78c220b64f98880c2faab17710618f10c2139e0c0d9c2667d05e0\n",
      "Step #4:   Stored in directory: /root/.cache/pip/wheels/6b/21/04/3a90a57cfed7fb3b132d75ef1617fdeaa85916b04551d5369d\n",
      "Step #4:   Building wheel for kfp-server-api (setup.py): started\n",
      "Step #4:   Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "Step #4:   Created wheel for kfp-server-api: filename=kfp_server_api-2.0.5-py3-none-any.whl size=114750 sha256=5b9e2e85b400c284a2180a42d1906d13a6e6bb85f3c0bfd47fb30e8a7f06b125\n",
      "Step #4:   Stored in directory: /root/.cache/pip/wheels/a6/c9/de/9f6964cdffc4d454c0a96d34f9b5ea5e51fc3224ec379222ff\n",
      "Step #4: Successfully built kfp kfp-server-api\n",
      "Step #4: Installing collected packages: websocket-client, urllib3, tabulate, six, PyYAML, pyasn1, protobuf, packaging, oauthlib, numpy, MarkupSafe, idna, grpcio, google-crc32c, docstring-parser, click, charset-normalizer, certifi, cachetools, shapely, rsa, requests, python-dateutil, pyasn1-modules, proto-plus, kfp-pipeline-spec, Jinja2, googleapis-common-protos, google-resumable-media, requests-toolbelt, requests-oauthlib, kfp-server-api, grpcio-status, google-auth, kubernetes, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, kfp, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "Step #4: Successfully installed Jinja2-3.1.3 MarkupSafe-2.1.5 PyYAML-6.0.1 cachetools-5.3.3 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 docstring-parser-0.16 google-api-core-2.18.0 google-auth-2.29.0 google-cloud-aiplatform-1.44.0 google-cloud-bigquery-3.19.0 google-cloud-core-2.4.1 google-cloud-pipeline-components-2.11.0 google-cloud-resource-manager-1.12.3 google-cloud-storage-2.16.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.63.0 grpc-google-iam-v1-0.13.0 grpcio-1.62.1 grpcio-status-1.62.1 idna-3.6 kfp-2.7.0 kfp-pipeline-spec-0.3.0 kfp-server-api-2.0.5 kubernetes-26.1.0 numpy-1.26.4 oauthlib-3.2.2 packaging-24.0 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 python-dateutil-2.9.0.post0 requests-2.31.0 requests-oauthlib-2.0.0 requests-toolbelt-0.10.1 rsa-4.9 shapely-2.0.3 six-1.16.0 tabulate-0.9.0 urllib3-1.26.18 websocket-client-1.7.0\n",
      "Step #4: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Step #4: \u001b[0m\u001b[91m\n",
      "Step #4: [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "Step #4: [notice] To update, run: pip install --upgrade pip\n",
      "Step #4: \u001b[0mRemoving intermediate container 4a103408dc5a\n",
      "Step #4:  ---> 9aaf0e36ebb6\n",
      "Step #4: Step 6/10 : COPY . /pipeline\n",
      "Step #4:  ---> cae959d2b998\n",
      "Step #4: Step 7/10 : WORKDIR /pipeline\n",
      "Step #4:  ---> Running in ae77f5de49d7\n",
      "Step #4: Removing intermediate container ae77f5de49d7\n",
      "Step #4:  ---> 900f40d46183\n",
      "Step #4: Step 8/10 : RUN ls\n",
      "Step #4:  ---> Running in 62ecf34791af\n",
      "Step #4: Dockerfile\n",
      "Step #4: __init__.py\n",
      "Step #4: cloudbuild.yaml\n",
      "Step #4: config.py\n",
      "Step #4: pipeline.py\n",
      "Step #4: requirements.txt\n",
      "Step #4: util.py\n",
      "Step #4: Removing intermediate container 62ecf34791af\n",
      "Step #4:  ---> ac2a5c03be08\n",
      "Step #4: Step 9/10 : RUN pwd\n",
      "Step #4:  ---> Running in 8638ee046b50\n",
      "Step #4: /pipeline\n",
      "Step #4: Removing intermediate container 8638ee046b50\n",
      "Step #4:  ---> cd510b66d4d6\n",
      "Step #4: Step 10/10 : RUN pip list\n",
      "Step #4:  ---> Running in 2642f65eadc8\n",
      "Step #4: Package                          Version\n",
      "Step #4: -------------------------------- -----------\n",
      "Step #4: cachetools                       5.3.3\n",
      "Step #4: certifi                          2024.2.2\n",
      "Step #4: charset-normalizer               3.3.2\n",
      "Step #4: click                            8.1.7\n",
      "Step #4: docstring_parser                 0.16\n",
      "Step #4: google-api-core                  2.18.0\n",
      "Step #4: google-auth                      2.29.0\n",
      "Step #4: google-cloud-aiplatform          1.44.0\n",
      "Step #4: google-cloud-bigquery            3.19.0\n",
      "Step #4: google-cloud-core                2.4.1\n",
      "Step #4: google-cloud-pipeline-components 2.11.0\n",
      "Step #4: google-cloud-resource-manager    1.12.3\n",
      "Step #4: google-cloud-storage             2.16.0\n",
      "Step #4: google-crc32c                    1.5.0\n",
      "Step #4: google-resumable-media           2.7.0\n",
      "Step #4: googleapis-common-protos         1.63.0\n",
      "Step #4: grpc-google-iam-v1               0.13.0\n",
      "Step #4: grpcio                           1.62.1\n",
      "Step #4: grpcio-status                    1.62.1\n",
      "Step #4: idna                             3.6\n",
      "Step #4: Jinja2                           3.1.3\n",
      "Step #4: kfp                              2.7.0\n",
      "Step #4: kfp-pipeline-spec                0.3.0\n",
      "Step #4: kfp-server-api                   2.0.5\n",
      "Step #4: kubernetes                       26.1.0\n",
      "Step #4: MarkupSafe                       2.1.5\n",
      "Step #4: numpy                            1.26.4\n",
      "Step #4: oauthlib                         3.2.2\n",
      "Step #4: packaging                        24.0\n",
      "Step #4: pip                              23.0.1\n",
      "Step #4: proto-plus                       1.23.0\n",
      "Step #4: protobuf                         4.25.3\n",
      "Step #4: pyasn1                           0.5.1\n",
      "Step #4: pyasn1-modules                   0.3.0\n",
      "Step #4: python-dateutil                  2.9.0.post0\n",
      "Step #4: PyYAML                           6.0.1\n",
      "Step #4: requests                         2.31.0\n",
      "Step #4: requests-oauthlib                2.0.0\n",
      "Step #4: requests-toolbelt                0.10.1\n",
      "Step #4: rsa                              4.9\n",
      "Step #4: setuptools                       58.1.0\n",
      "Step #4: shapely                          2.0.3\n",
      "Step #4: six                              1.16.0\n",
      "Step #4: tabulate                         0.9.0\n",
      "Step #4: urllib3                          1.26.18\n",
      "Step #4: websocket-client                 1.7.0\n",
      "Step #4: wheel                            0.43.0\n",
      "Step #4: \u001b[91m\n",
      "Step #4: [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "Step #4: [notice] To update, run: pip install --upgrade pip\n",
      "Step #4: \u001b[0mRemoving intermediate container 2642f65eadc8\n",
      "Step #4:  ---> ab795ecbc30e\n",
      "Step #4: Successfully built ab795ecbc30e\n",
      "Step #4: Successfully tagged gcr.io/able-analyst-416817/gemma-chatbot-pipeline-app:latest\n",
      "Finished Step #4\n",
      "Starting Step #5\n",
      "Step #5: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #5: The push refers to repository [gcr.io/able-analyst-416817/gemma-chatbot-pipeline-app]\n",
      "Step #5: ff436591e34a: Preparing\n",
      "Step #5: 8e63c0fd81f5: Preparing\n",
      "Step #5: 0746b8d94cc3: Preparing\n",
      "Step #5: ae9fee204e0b: Preparing\n",
      "Step #5: 16c6d7436f6a: Preparing\n",
      "Step #5: 5d78e4c3c132: Preparing\n",
      "Step #5: 9138b29cde77: Preparing\n",
      "Step #5: 4c8474755d1b: Preparing\n",
      "Step #5: c8f253aef560: Preparing\n",
      "Step #5: a483da8ab3e9: Preparing\n",
      "Step #5: 5d78e4c3c132: Waiting\n",
      "Step #5: 9138b29cde77: Waiting\n",
      "Step #5: 4c8474755d1b: Waiting\n",
      "Step #5: c8f253aef560: Waiting\n",
      "Step #5: a483da8ab3e9: Waiting\n",
      "Step #5: ff436591e34a: Pushed\n",
      "Step #5: 16c6d7436f6a: Pushed\n",
      "Step #5: 8e63c0fd81f5: Pushed\n",
      "Step #5: ae9fee204e0b: Pushed\n",
      "Step #5: 5d78e4c3c132: Layer already exists\n",
      "Step #5: 9138b29cde77: Layer already exists\n",
      "Step #5: 4c8474755d1b: Layer already exists\n",
      "Step #5: c8f253aef560: Layer already exists\n",
      "Step #5: a483da8ab3e9: Layer already exists\n",
      "Step #5: 0746b8d94cc3: Pushed\n",
      "Step #5: latest: digest: sha256:e96620619353245e254ab8828e3a97c9a85169d0c54a5f01ffdca35c2fae718f size: 2413\n",
      "Finished Step #5\n",
      "Starting Step #6\n",
      "Step #6: Already have image (with digest): gcr.io/able-analyst-416817/gemma-chatbot-pipeline-app:latest\n",
      "Step #6: ./gemma_2b_en\n",
      "Step #6: This is the dictionary {'model_size': '2b', 'finetuned_model_dir': './gemma_2b_en', 'finetuned_weights_path': './gemma_2b_en/model.weights.h5', 'finetuned_vocab_path': './gemma_2b_en/vocabulary.spm', 'huggingface_model_dir': './gemma_2b_en_huggingface', 'deployed_model_blob': 'gemma_2b_en/20240325085241', 'deployed_model_uri': 'gs://able-analyst-416817-chatbot-v1/gemma_2b_en/20240325085241', 'fine_tuned_keras_blob': 'gemma_2b_en/keras/20240325085241', 'model_name_vllm': 'gemma_2b_en-vllm', 'machine_type': 'g2-standard-8', 'accelerator_type': 'NVIDIA_L4', 'accelerator_count': 1}\n",
      "Step #6: ./gemma_2b_en\n",
      "Step #6: Creating PipelineJob\n",
      "Step #6: PipelineJob created. Resource name: projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240325085243\n",
      "Step #6: To use this PipelineJob in another session:\n",
      "Step #6: pipeline_job = aiplatform.PipelineJob.get('projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240325085243')\n",
      "Step #6: View Pipeline Job:\n",
      "Step #6: https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/model-deployment-20240325085243?project=24796876098\n",
      "Step #6: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240325085243 current state:\n",
      "Step #6: PipelineState.PIPELINE_STATE_RUNNING\n",
      "Step #6: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240325085243 current state:\n",
      "Step #6: PipelineState.PIPELINE_STATE_RUNNING\n",
      "Step #6: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240325085243 current state:\n",
      "Step #6: PipelineState.PIPELINE_STATE_RUNNING\n",
      "Step #6: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240325085243 current state:\n",
      "Step #6: PipelineState.PIPELINE_STATE_RUNNING\n",
      "Step #6: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240325085243 current state:\n",
      "Step #6: PipelineState.PIPELINE_STATE_RUNNING\n",
      "Step #6: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240325085243 current state:\n",
      "Step #6: PipelineState.PIPELINE_STATE_RUNNING\n",
      "Step #6: PipelineJob projects/24796876098/locations/us-central1/pipelineJobs/model-deployment-20240325085243 current state:\n",
      "Step #6: PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit . --config \"./master_cloudbuild.json\" --substitutions {substitutions} --region={GCP_REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7829947f-513a-4c2a-87c2-c0644cd417af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from werkzeug.datastructures import FileStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3449a7-6c22-4f74-a1dc-695b3454d526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b16b58-4948-4ac3-8e62-4bf44a276f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bae1df-efbf-408e-b9d3-89aa40b8e148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428edba-6c98-49dc-a6c7-e2cfe63daf15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
